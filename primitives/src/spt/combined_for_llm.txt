=========================================================== 
===== START fqc.py ===== 
```python 
"""
fqc.py
----------------

Complete forensic evaluation suite for distinguishing synthetic images
from real laboratory photos or scans using reference-free methods.

Focus:
  - No metadata or RAW processing
  - Works on:
        - file path (PNG or JPEG)
        - OpenCV BGR ndarray
  - Provides:
        - noise residual & PRNU-like metrics
        - per-channel noise statistics
        - noise spectral slope (1/f^beta)
        - FFT radial / angular energy profiles
        - JPEG block grid detection for any input
        - patch-based variance + kurtosis maps
        - edge profile consistency metrics
        - row/column banding detection
        - color correlation statistics
        - local self-consistency tests

Dependencies:
    numpy
    opencv-python
    scipy
    scikit-image

All output is returned as a Python dict.
"""

from __future__ import annotations

import os
import cv2
import numpy as np
from typing import Optional, Dict, Any, Tuple

from scipy.signal import convolve2d
from scipy.ndimage import gaussian_filter
from scipy.fft import fft2, fftshift
from skimage.filters import sobel, scharr, laplace
from skimage.util import view_as_blocks, img_as_float
from skimage.restoration import estimate_sigma


# ---------------------------------------------------------------------------
# Utility
# ---------------------------------------------------------------------------

def _load_image(img_input: Any) -> np.ndarray:
    """
    Accepts:
        - path to file (jpg/png)
        - OpenCV ndarray (BGR)
    Returns:
        float32 RGB in [0,1]
    """
    if isinstance(img_input, str):
        if not os.path.exists(img_input):
            raise FileNotFoundError(img_input)
        img = cv2.imread(img_input, cv2.IMREAD_COLOR)
        if img is None:
            raise ValueError(f"Failed to load image: {img_input}")
    else:
        # assume OpenCV BGR ndarray
        img = img_input

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img_as_float(img.astype(np.float32))


# ---------------------------------------------------------------------------
# A. Noise Residual / PRNU-like analysis
# ---------------------------------------------------------------------------

def analyze_noise_residual(img: np.ndarray) -> Dict[str, Any]:
    """
    Extracts a denoised baseline and computes noise residual.
    Provides PRNU-like metrics: correlation, RMS, energy spectrum.
    """
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    gray_f = img_as_float(gray)

    # Baseline denoising (acts like crude wavelet denoise)
    denoised = gaussian_filter(gray_f, sigma=1.0)
    residual = gray_f - denoised

    rms = float(np.sqrt(np.mean(residual**2)))

    # Correlation of residual with itself shifted (quick PRNU proxy)
    shifted = np.roll(residual, 1, axis=1)
    prnu_corr = float(np.corrcoef(residual.flatten(), shifted.flatten())[0, 1])

    # Spectral slope estimation
    R = fftshift(fft2(residual))
    mag = np.abs(R)

    h, w = mag.shape
    cy, cx = h // 2, w // 2
    yy, xx = np.indices(mag.shape)
    r = np.sqrt((yy - cy)**2 + (xx - cx)**2)

    radial_profile = []
    for radius in range(1, min(cy, cx)):
        mask = (r >= radius) & (r < radius + 1)
        radial_profile.append(np.mean(mag[mask]))
    radial_profile = np.array(radial_profile)

    return {
        "rms_noise": rms,
        "prnu_corr": prnu_corr,
        "noise_residual": residual,
        "fft_radial_profile": radial_profile,
    }


# ---------------------------------------------------------------------------
# B. JPEG grid artifact analysis
# ---------------------------------------------------------------------------

def analyze_jpeg_artifacts(img: np.ndarray) -> Dict[str, Any]:
    """
    Robust JPEG-grid artifact detection.
    Works even when image dims are not divisible by 8.
    Pads reflectively so view_as_blocks() always works.
    """
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    h, w = gray.shape

    # Need at least 16x16 to say anything useful
    if h < 16 or w < 16:
        return {
            "jpeg_blockiness": None,
            "block_var_map": None,
            "note": "image too small for JPEG artifact analysis",
        }

    # Padding to nearest multiple of 8
    pad_h = (8 - h % 8) if (h % 8) else 0
    pad_w = (8 - w % 8) if (w % 8) else 0

    if pad_h or pad_w:
        gray_padded = np.pad(
            gray,
            ((0, pad_h), (0, pad_w)),
            mode="reflect"
        )
    else:
        gray_padded = gray

    # Now safe for block slicing
    blocks = view_as_blocks(gray_padded, block_shape=(8, 8))
    variances = np.var(blocks, axis=(2, 3))

    # Differences across block grid lines
    vert_diff = np.mean(np.abs(np.diff(variances, axis=1)))
    horiz_diff = np.mean(np.abs(np.diff(variances, axis=0)))
    blockiness = float(vert_diff + horiz_diff)

    return {
        "jpeg_blockiness": blockiness,
        "block_var_map": variances,
        "note": f"padded h={pad_h}, w={pad_w}" if (pad_h or pad_w) else "no padding",
    }


# ---------------------------------------------------------------------------
# C. FFT-based structural analysis
# ---------------------------------------------------------------------------

def analyze_fft_structure(img: np.ndarray) -> Dict[str, Any]:
    """
    Full-image FFT: radial + angular profiles.
    Good for detecting synthetic smoothness, missing high-frequency content,
    or unnatural symmetry.
    """
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    F = fftshift(fft2(gray))
    mag = np.abs(F)

    # Radial profile (already computed similarly above)
    h, w = mag.shape
    cy, cx = h // 2, w // 2
    yy, xx = np.indices(mag.shape)
    r = np.sqrt((yy - cy)**2 + (xx - cx)**2).astype(np.int32)
    radial = np.bincount(r.ravel(), mag.ravel())[:min(cy, cx)]

    # Angular profile (0-360 degrees)
    theta = np.degrees(np.arctan2(yy - cy, xx - cx))
    theta_idx = ((theta + 360) % 360).astype(np.int32)
    angular = np.bincount(theta_idx.ravel(), mag.ravel())
    angular = angular[:360]

    return {
        "fft_magnitude": mag,
        "fft_radial": radial,
        "fft_angular": angular,
    }


# ---------------------------------------------------------------------------
# D. Patch variance, kurtosis, local statistics
# ---------------------------------------------------------------------------

def analyze_patch_stats(img: np.ndarray, patch_size: int = 16) -> Dict[str, Any]:
    """Patch-level variance and kurtosis maps."""
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    h, w = gray.shape
    ph, pw = patch_size, patch_size

    # Crop to patch-grid
    h2 = (h // ph) * ph
    w2 = (w // pw) * pw
    gray = gray[:h2, :w2]

    blocks = view_as_blocks(gray, block_shape=(ph, pw))
    var_map = np.var(blocks, axis=(2, 3))

    # Excess kurtosis
    mean = np.mean(blocks, axis=(2, 3), keepdims=True)
    diff = blocks - mean
    kurt = np.mean(diff**4, axis=(2, 3)) / (np.var(blocks, axis=(2, 3)) + 1e-8)**2
    # Subtract 3 for excess kurtosis (normal distribution baseline)
    kurtosis_map = kurt - 3.0

    return {
        "patch_variance_map": var_map,
        "patch_kurtosis_map": kurtosis_map,
    }


# ---------------------------------------------------------------------------
# Extended Patch Analysis
# ---------------------------------------------------------------------------

def analyze_patch_full(img: np.ndarray, patch_size: int = 16) -> Dict[str, Any]:
    """
    Detailed patch-level forensic analysis.
    Computes variance, kurtosis, entropy, noise estimates,
    brightness/noise correlation, patch spectral slopes, etc.
    """
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    gray_f = img_as_float(gray)

    h, w = gray_f.shape
    ph = pw = patch_size

    # crop to grid
    h2 = (h // ph) * ph
    w2 = (w // pw) * pw
    gray_f = gray_f[:h2, :w2]

    # shape: (nH, nW, ph, pw)
    blocks = view_as_blocks(gray_f, block_shape=(ph, pw))
    nH, nW, _, _ = blocks.shape
    N = nH * nW
    B = blocks.reshape(N, ph, pw)

    # Patch-level metrics
    patch_mean = B.mean(axis=(1, 2))
    patch_var  = B.var(axis=(1, 2))

    # Kurtosis: (E[(x-mu)^4] / sigma^4) - 3
    patch_kurt = (((B - patch_mean[:,None,None])**4).mean(axis=(1,2)) /
                  (patch_var + 1e-8)**2) - 3.0

    # Entropy per patch

    # Patch entropy (scalar per patch)
    patch_entropy = []
    for b in B:
        hist, _ = np.histogram(b, bins=64, range=(0,1), density=True)
        hist = hist + 1e-12  # avoid log(0)
        entropy = -np.sum(hist * np.log(hist))
        patch_entropy.append(entropy)
    patch_entropy = np.array(patch_entropy)    
    
    # Quick noise estimate by high-pass filtering
    hp_kernel = np.array([[0, -1, 0],
                          [-1, 4, -1],
                          [0, -1, 0]], dtype=np.float32)
    patch_noise = np.array([
        np.mean(np.abs(convolve2d(b, hp_kernel, mode="same")))
    for b in B])

    # Per patch FFT slope (detect unnatural textures)
    patch_fft_slope = []
    for b in B:
        F = np.abs(fftshift(fft2(b)))
        h2b, w2b = F.shape
        cy, cx = h2b//2, w2b//2
        yy, xx = np.indices(F.shape)
        r = np.sqrt((yy-cy)**2 + (xx-cx)**2).astype(int)
        radial = np.bincount(r.ravel(), F.ravel())
        idx = np.arange(1, len(radial))
        if len(idx) < 4:
            patch_fft_slope.append(np.nan)
            continue
        log_r = np.log(idx+1)
        log_p = np.log(radial[1:len(idx)+1] + 1e-8)
        slope, _ = np.polyfit(log_r, log_p, 1)
        patch_fft_slope.append(slope)
    patch_fft_slope = np.array(patch_fft_slope)

    # Reference-free checks:
    # Real images usually have:
    # - broad distribution of patch variance
    # - correlation between brightness and noise
    # - heterogeneous kurtosis
    # - heterogeneous entropy
    # - FFT slopes with dispersion
    var_std = float(np.std(patch_var))
    kurt_std = float(np.std(patch_kurt))
    noise_std = float(np.std(patch_noise))
    entropy_std = float(np.std([np.sum(e) for e in patch_entropy]))
    fft_std = float(np.nanstd(patch_fft_slope))

    # brightness-variance correlation
    bv_corr = float(np.corrcoef(patch_mean, patch_var)[0,1]) if var_std > 0 else 0.0
    # brightness-noise correlation
    bn_corr = float(np.corrcoef(patch_mean, patch_noise)[0,1]) if noise_std > 0 else 0.0

    return {
        "patch_mean": patch_mean,
        "patch_var": patch_var,
        "patch_kurtosis": patch_kurt,
        "patch_noise": patch_noise,
        "patch_fft_slope": patch_fft_slope,
        "var_std": var_std,
        "kurt_std": kurt_std,
        "noise_std": noise_std,
        "entropy_std": entropy_std,
        "fft_std": fft_std,
        "brightness_variance_corr": bv_corr,
        "brightness_noise_corr": bn_corr,
    }


# ---------------------------------------------------------------------------
# E. Row/column banding
# ---------------------------------------------------------------------------

def analyze_banding(img: np.ndarray) -> Dict[str, Any]:
    """
    Detects row/column periodic artifacts, typical for:
        - CMOS readout
        - scanner rails
        - rolling shutter anomalies
    """
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    gray_f = img_as_float(gray)

    row_std = np.std(gray_f, axis=1)
    col_std = np.std(gray_f, axis=0)

    row_fft = np.abs(fftshift(fft2(row_std[np.newaxis, :])))
    col_fft = np.abs(fftshift(fft2(col_std[:, np.newaxis])))

    return {
        "row_std": row_std,
        "col_std": col_std,
        "row_fft": row_fft,
        "col_fft": col_fft,
    }


# ---------------------------------------------------------------------------
# F. Edge profile consistency
# ---------------------------------------------------------------------------

def analyze_edge_profiles(img: np.ndarray) -> Dict[str, Any]:
    """
    Detects unnatural smoothness or excessive sharpening on edges.
    Uses Sobel/Laplace sharpness + edge noise ratio.
    """
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    gray_f = img_as_float(gray)

    sob = sobel(gray_f)
    lap = laplace(gray_f)

    edge_strength = np.mean(np.abs(sob))
    lap_energy = np.mean(np.abs(lap))

    # Estimate noise level from skimage: modern param is channel_axis
    try:
        noise_est = estimate_sigma(gray_f, channel_axis=None)
    except TypeError:
        # fallback for old versions
        noise_est = estimate_sigma(gray_f, multichannel=False)

    edge_noise_ratio = float(edge_strength / (noise_est + 1e-8))

    return {
        "edge_strength": float(edge_strength),
        "laplacian_energy": float(lap_energy),
        "edge_noise_ratio": edge_noise_ratio,
    }


# ---------------------------------------------------------------------------
# G. Color-channel correlation (synthetic images often deviate)
# ---------------------------------------------------------------------------

def analyze_color_stats(img: np.ndarray) -> Dict[str, Any]:
    """
    Computes correlation between RGB channels.
    Synthetic images often show:
        - too high or too low channel correlation
        - unrealistic chroma relationships
    """
    R = img[..., 0].ravel()
    G = img[..., 1].ravel()
    B = img[..., 2].ravel()

    rg = float(np.corrcoef(R, G)[0, 1])
    rb = float(np.corrcoef(R, B)[0, 1])
    gb = float(np.corrcoef(G, B)[0, 1])

    return {
        "corr_RG": rg,
        "corr_RB": rb,
        "corr_GB": gb,
    }


# ---------------------------------------------------------------------------
# Helper: clamp and safe linear scoring
# ---------------------------------------------------------------------------

def _clamp01(x: float) -> float:
    return max(0.0, min(1.0, float(x)))


def _score_band(x: float, lo: float, hi: float) -> float:
    """
    Score in [0,1] where [lo, hi] is ideal band.
    Linearly falls to 0 beyond that.
    """
    if x <= lo:
        return _clamp01((x - 0.0) / (lo - 0.0)) if lo > 0 else 0.0
    if x >= hi:
        return _clamp01((hi - x) / (hi - 0.0)) if hi > 0 else 0.0
    # inside band: best = 1
    return 1.0


# ---------------------------------------------------------------------------
# Realism scoring (reference-free, heuristic)
# ---------------------------------------------------------------------------

def compute_realism_scores(res: Dict[str, Any]) -> Dict[str, Any]:
    """
    Compute reference-free realism subscores and overall score [0,100].

    Heuristics are based on typical digital camera behavior, not on any
    specific dataset. This is what you can do even when neither side
    has reference images.
    """
    nr = res["noise_residual"]
    jp = res["jpeg_artifacts"]
    fft = res["fft_structure"]
    ps = res["patch_stats"]
    pf = res["patch_full"]
    band = res["banding"]
    edge = res["edge_profiles"]
    col = res["color_stats"]

    # -------------------------
    # 1) Noise & PRNU realism
    # -------------------------
    rms = float(nr["rms_noise"])
    prnu = float(nr["prnu_corr"])

    # RMS in [0.005, 0.03] is "camera-like", lower = too clean, higher = too noisy
    s_noise_rms = _score_band(rms, 0.005, 0.03)

    # PRNU correlation in [0.02, 0.06] is "reasonable sensor fingerprint"
    s_noise_prnu = _score_band(abs(prnu), 0.02, 0.06)

    s_noise = 0.6 * s_noise_rms + 0.4 * s_noise_prnu

    # -------------------------
    # 2) JPEG trace realism
    # -------------------------
    blockiness = jp.get("jpeg_blockiness", None)
    if blockiness is None:
        s_jpeg = 0.5  # unknown; neither penalize nor reward strongly
    else:
        # Very small blockiness -> maybe lossless or synthetic;
        # moderate blockiness [1,4] -> typical JPEG; huge -> overcompressed / weird
        s_jpeg = 0.7 * _score_band(blockiness, 1.0, 4.0) + 0.3 * _score_band(
            blockiness, 0.5, 6.0
        )

    # -------------------------
    # 3) Edge behavior realism
    # -------------------------
    es = float(edge["edge_strength"])
    enr = float(edge["edge_noise_ratio"])

    # Edge strength in [0.02, 0.08] is typical (too low = blurry, too high = oversharp)
    s_edge_strength = _score_band(es, 0.02, 0.08)

    # Edge/noise ratio in [2, 7] typically; too low = edges too clean, too high = noisy
    s_edge_enr = _score_band(enr, 2.0, 7.0)

    s_edges = 0.5 * s_edge_strength + 0.5 * s_edge_enr

    # -------------------------
    # 4) Banding realism
    # -------------------------
    row_std = float(band["row_std"].std())
    col_std = float(band["col_std"].std())

    # We allow both very low and moderate banding. Extreme banding is penalized.
    # Typical low-level sensor banding std ~ 0.001-0.004 in normalized space.
    s_row = _score_band(row_std, 0.0005, 0.004)
    s_col = _score_band(col_std, 0.0005, 0.004)
    s_banding = 0.5 * s_row + 0.5 * s_col

    # -------------------------
    # 5) Color coupling realism
    # -------------------------
    rg = float(col["corr_RG"])
    rb = float(col["corr_RB"])
    gb = float(col["corr_GB"])

    # Correlations ~ [0.7, 0.95] are natural; <0.6 weird; >0.98 grayscale-ish/sus
    s_rg = _score_band(abs(rg), 0.7, 0.95)
    s_rb = _score_band(abs(rb), 0.7, 0.95)
    s_gb = _score_band(abs(gb), 0.7, 0.95)

    s_color = (s_rg + s_rb + s_gb) / 3.0

    # -------------------------
    # 6) Spectral naturalness (FFT radial slope)
    # -------------------------
    radial = fft["fft_radial"]
    # Avoid zeros and center
    idx = np.arange(1, len(radial))
    vals = np.array(radial[1:], dtype=np.float64) + 1e-8
    # log-log slope
    log_r = np.log(idx + 1.0)
    log_p = np.log(vals)
    if len(log_r) >= 5:
        slope, _ = np.polyfit(log_r, log_p, 1)
        # Natural images ~ 1/f^beta with beta ~ 2 => slope ~ -2
        # Acceptable band [-1.2, -2.8]
        s_fft = _score_band(abs(slope), 1.2, 2.8)
    else:
        slope = float("nan")
        s_fft = 0.5

    # -------------------------
    # 7) Patch statistics realism (kurtosis)
    # -------------------------
    kurt_map = ps["patch_kurtosis_map"]
    mean_kurt = float(np.mean(kurt_map))
    # For roughly normal noise, excess kurtosis ~ 0; allow small deviations.
    s_kurt = _score_band(abs(mean_kurt), 0.0, 1.0)  # abs close to 0 is best

    var_std   = pf["var_std"]
    kurt_std  = pf["kurt_std"]
    noise_std = pf["noise_std"]
    ent_std   = pf["entropy_std"]
    fft_std   = pf["fft_std"]

    bv_corr   = pf["brightness_variance_corr"]
    bn_corr   = pf["brightness_noise_corr"]



    # Patch variance distribution: want VARIETY
    s_pvar = _score_band(var_std, 0.002, 0.02)
    
    # Patch kurtosis distribution: heterogeneous is real
    s_pkurt = _score_band(kurt_std, 0.05, 0.5)
    
    # Patch noise distribution: uniform noise -> synthetic
    s_pnoise = _score_band(noise_std, 0.002, 0.02)
    
    # Patch entropy distribution: real images have wide entropy range
    s_pent = _score_band(ent_std, 0.01, 0.10)
    
    # FFT slope variability: real images vary patch to patch
    s_pfft = _score_band(fft_std, 0.15, 1.0)
    
    # Brightness-variance correlation: should be negative or weakly negative
    s_bv = 1.0 - _clamp01((bv_corr + 0.2) / 0.6)  # maps negative corr -> high score
    
    # Brightness-noise correlation: strongly negative is realistic
    s_bn = 1.0 - _clamp01((bn_corr + 0.2) / 0.6)
    
    # Combine patch realism
    s_patch = (
        0.15 * s_pvar +
        0.15 * s_pkurt +
        0.15 * s_pnoise +
        0.15 * s_pent +
        0.15 * s_pfft +
        0.125 * s_bv +
        0.125 * s_bn
    )

    
    # -------------------------
    # Combine subscores
    # -------------------------
    # Weights are heuristic; tweak if needed.
    w_noise = 0.2
    w_jpeg = 0.1
    w_edges = 0.2
    w_banding = 0.1
    w_color = 0.15
    w_fft = 0.15
    w_kurt = 0.1
    w_patch = 0.25


    overall = (
        w_noise * s_noise +
        w_jpeg * s_jpeg +
        w_edges * s_edges +
        w_banding * s_banding +
        w_color * s_color +
        w_fft * s_fft +
        w_kurt * s_kurt +
        w_patch * s_patch
    )    

    return {
        "overall_score": float(overall * 100.0),
        "noise_score": float(s_noise * 100.0),
        "jpeg_score": float(s_jpeg * 100.0),
        "edge_score": float(s_edges * 100.0),
        "banding_score": float(s_banding * 100.0),
        "color_score": float(s_color * 100.0),
        "fft_score": float(s_fft * 100.0),
        "kurtosis_score": float(s_kurt * 100.0),
        "fft_slope": float(slope) if "slope" in locals() else None,
        "mean_patch_kurtosis": mean_kurt,
        "row_std_std": row_std,
        "col_std_std": col_std,
        "patch_score": float(s_patch * 100.0),
        "patch_var_std": var_std,
        "kurt_std": kurt_std,
        "patch_noise_std": noise_std,
        "patch_entropy_std": ent_std,
        "patch_fft_std": fft_std,
        "patch_brightness_variance_corr": bv_corr,
        "patch_brightness_noise_corr": bn_corr,
        
    }


# ---------------------------------------------------------------------------
# Realism classification (reference-free heuristic)
# ---------------------------------------------------------------------------

def classify_realism(scores: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify image realism based on overall and component scores.
    Returns:
            {
                "label": "camera-like" | "ambiguous" | "likely synthetic",
                "overall_score": float,
                "flags": [list of textual reasons]
            }
    """
    overall = scores["overall_score"]
    flags = []

    # Rough thresholds
    if overall >= 70.0:
        label = "camera-like"
    elif overall >= 40.0:
        label = "ambiguous"
    else:
        label = "likely synthetic"

    # Flag low subscores
    def check(key: str, name: str, thresh: float = 50.0):
        if scores[key] < thresh:
            flags.append(f"{name} score low ({scores[key]:.1f})")

    check("noise_score", "Noise / PRNU realism")
    check("jpeg_score", "JPEG pipeline realism")
    check("edge_score", "Edge behavior realism")
    check("banding_score", "Banding realism")
    check("color_score", "Color coupling realism")
    check("fft_score", "Frequency spectrum realism")
    check("kurtosis_score", "Patch statistics realism")
    check("patch_score", "Patch-level realism")

    return {
        "label": label,
        "overall_score": overall,
        "flags": flags,
    }


def interpret_forensic_report(res: Dict[str, Any], scores: Optional[Dict[str, Any]] = None) -> str:
    """
    Convert raw forensic metrics into a human-readable diagnostic summary.
    No baseline needed yet - uses heuristic forensic expectations.
    """
    out = []
    nr = res["noise_residual"]
    jp = res["jpeg_artifacts"]
    fft = res["fft_structure"]
    ps = res["patch_stats"]
    band = res["banding"]
    edge = res["edge_profiles"]
    col = res["color_stats"]

    # ---------------------------------------------------------------
    # Noise Residual / PRNU
    # ---------------------------------------------------------------
    rms = nr["rms_noise"]
    prnu = nr["prnu_corr"]

    if rms < 0.005:
        out.append(f"- Noise RMS extremely low ({rms:.5f}): image likely too clean / synthetic.")
    elif rms < 0.015:
        out.append(f"- Noise RMS low ({rms:.5f}): cleaner than most lab photos.")
    else:
        out.append(f"- Noise RMS moderate ({rms:.5f}): within typical lab photo range.")

    if prnu < 0.01:
        out.append(f"- PRNU correlation very low ({prnu:.4f}): typical for synthetic images.")
    elif prnu < 0.03:
        out.append(f"- PRNU weak ({prnu:.4f}): mild sensor fingerprint.")
    else:
        out.append(f"- PRNU correlation noticeable ({prnu:.4f}): real-sensor signature likely present.")

    # ---------------------------------------------------------------
    # JPEG Artifact Level
    # ---------------------------------------------------------------
    blockiness = jp.get("jpeg_blockiness", None)
    if blockiness is None:
        out.append("- JPEG blockiness: not measurable (image too small).")
    else:
        if blockiness < 1.0:
            out.append(f"- JPEG blockiness very low ({blockiness:.2f}): looks synthetic or lossless.")
        elif blockiness < 4.0:
            out.append(f"- JPEG blockiness mild ({blockiness:.2f}): consistent with light compression.")
        else:
            out.append(f"- JPEG blockiness strong ({blockiness:.2f}): typical JPEG compression grid.")

    # ---------------------------------------------------------------
    # Edge Profiles
    # ---------------------------------------------------------------
    es = edge["edge_strength"]
    enr = edge["edge_noise_ratio"]

    if es < 0.02:
        out.append(f"- Very weak edge strength ({es:.3f}): soft or blurred image.")
    elif es > 0.08:
        out.append(f"- Strong edge response ({es:.3f}): possibly oversharpened (synthetic?).")
    else:
        out.append(f"- Edge strength ({es:.3f}) within typical range.")

    if enr < 2.0:
        out.append(f"- Edge noise ratio low ({enr:.2f}): edges unusually clean (synthetic?).")
    elif enr > 7.0:
        out.append(f"- Edge noise ratio high ({enr:.2f}): noisy or oversharpened.")
    else:
        out.append(f"- Edge noise ratio ({enr:.2f}) normal.")

    # ---------------------------------------------------------------
    # Banding
    # ---------------------------------------------------------------
    row_std = band["row_std"].std()
    col_std = band["col_std"].std()

    if row_std < 0.001 and col_std < 0.001:
        out.append("- No detectable row/column banding: synthetic or high-quality camera.")
    elif row_std > 0.003 or col_std > 0.003:
        out.append("- Row/column variability present: sensor or scanner signature.")
    else:
        out.append("- Very faint banding: normal low-level sensor pattern.")

    # ---------------------------------------------------------------
    # Color channel correlation
    # ---------------------------------------------------------------
    rg = col["corr_RG"]
    rb = col["corr_RB"]
    gb = col["corr_GB"]

    if max(rg, rb, gb) > 0.98:
        out.append("- RGB channels almost perfectly correlated: synthetic grayscale-like.")
    elif min(rg, rb, gb) < 0.6:
        out.append("- Low RGB correlation: unusual / synthetic color distribution.")
    else:
        out.append("- RGB correlation normal.")

    if scores is not None:
        out.append("")
        out.append(f"Realism scores (0-100): overall={scores['overall_score']:.1f}, "
                   f"noise={scores['noise_score']:.1f}, jpeg={scores['jpeg_score']:.1f}, "
                   f"edges={scores['edge_score']:.1f}, banding={scores['banding_score']:.1f}, "
                   f"color={scores['color_score']:.1f}, fft={scores['fft_score']:.1f}, "
                   f"kurtosis={scores['kurtosis_score']:.1f}")
    
    # ---------------------------------------------------------------
    # Patch Analysis
    # ---------------------------------------------------------------
    pf = res["patch_full"]
    var_std = pf["var_std"]
    kurt_std = pf["kurt_std"]
    noise_std = pf["noise_std"]
    ent_std = pf["entropy_std"]
    fft_std = pf["fft_std"]
    bv_corr = pf["brightness_variance_corr"]
    bn_corr = pf["brightness_noise_corr"]
    
    out.append("")
    out.append("--- Patch Analysis ---")
    out.append(f"Variance std: {var_std:.5f}")
    if var_std < 0.002:
        out.append("  -> Patch variance too uniform: synthetic-like.")
    elif var_std < 0.005:
        out.append("  -> Patch variance on low side.")
    else:
        out.append("  -> Patch variance distribution realistic.")
    
    out.append(f"Kurtosis std: {kurt_std:.5f}")
    if kurt_std < 0.05:
        out.append("  -> Patch kurtosis too uniform: synthetic noise.")
    else:
        out.append("  -> Kurtosis variability plausible.")
    
    out.append(f"Noise std: {noise_std:.5f}")
    if noise_std < 0.002:
        out.append("  -> Patch noise uniform: suspicious synthetic trait.")
    else:
        out.append("  -> Noise variation looks real.")
    
    out.append(f"Entropy std: {ent_std:.5f}")
    if ent_std < 0.01:
        out.append("  -> Entropy too uniform: repeated or artificial texture.")
    else:
        out.append("  -> Good entropy diversity.")
    
    out.append(f"FFT slope std: {fft_std:.5f}")
    if fft_std < 0.15:
        out.append("  -> Patch spectral slopes too similar: synthetic or overly smooth.")
    else:
        out.append("  -> Patch spectral diversity normal.")

    out.append(f"Brightness-variance corr: {bv_corr:.3f}")
    if bv_corr > -0.05:
        out.append("  -> Missing expected negative correlation: no camera physics.")
    else:
        out.append("  -> Brightness-variance relationship realistic.")
    
    out.append(f"Brightness-noise corr: {bn_corr:.3f}")
    if bn_corr > -0.05:
        out.append("  -> Missing brightness-noise dependency: synthetic noise.")
    else:
        out.append("  -> Brightness-dependent noise looks real.")

    return "\n".join(out)


# ---------------------------------------------------------------------------
# High-level one-shot report
# ---------------------------------------------------------------------------


def forensic_evaluate(img_input: Any) -> Dict[str, Any]:
    """
    Main entry point.
    Accepts:
        - path to PNG / JPEG
        - OpenCV BGR ndarray
    Returns:
        Dict with all forensic metrics.
    """
    img = _load_image(img_input)

    return {
        "noise_residual": analyze_noise_residual(img),
        "jpeg_artifacts": analyze_jpeg_artifacts(img),
        "fft_structure": analyze_fft_structure(img),
        "patch_stats": analyze_patch_stats(img),
        "patch_full": analyze_patch_full(img),
        "banding": analyze_banding(img),
        "edge_profiles": analyze_edge_profiles(img),
        "color_stats": analyze_color_stats(img),
    }


def generate_forensic_report(img_input: Any) -> Dict[str, Any]:
    """
    Full pipeline:
        1) forensic_evaluate
        2) compute_realism_scores
        3) classify_realism
        4) build human-readable report string

    Returns a dict:
        {
            "metrics": <raw forensic_evaluate output>,
            "scores": <subscores + overall>,
            "classification": <label + flags>,
            "text_report": <multi-line string>
        }
    """
    metrics = forensic_evaluate(img_input)
    scores = compute_realism_scores(metrics)
    classification = classify_realism(scores)

    header = [
        f"Realism classification: {classification['label']} "
        f"(overall score {classification['overall_score']:.1f}/100)"
    ]
    if classification["flags"]:
        header.append("Flags:")
        for f in classification["flags"]:
            header.append(f"  - {f}")
    header.append("")

    details = interpret_forensic_report(metrics, scores=scores)

    text_report = "\n".join(header + [details])

    return {
        "metrics": metrics,
        "scores": scores,
        "classification": classification,
        "text_report": text_report,
    }


if __name__ == "__main__":
    import sys
    path = sys.argv[1]
    rep = generate_forensic_report(path)
    print(rep["text_report"])
``` 
 
===== END fqc.py ===== 
 
===== START mpl_artist_preview.py ===== 
```python 
"""
mpl_artist_preview.py
---------------------
Render any Matplotlib artist with automatic bounding-box sizing (5% margin),
hidden axes, tight layout, and immediate display.
"""

from __future__ import annotations

__all__ = ["preview_mpl_artist",]


import matplotlib.pyplot as plt
from matplotlib.path import Path as mplPath
from matplotlib.lines import Line2D
from matplotlib.collections import LineCollection, PathCollection, PatchCollection
from matplotlib.patches import PathPatch, Patch, Circle, Rectangle
import numpy as np
from matplotlib.transforms import Bbox


def ax_autofit(ax, margin: float = 0.05) -> None:
    """
    Automatically adjust axis limits to tightly fit all artists currently attached to `ax`.

    Inspects the geometric extents of all patches, lines, collections, and generic
    artists in the given Axes, computes a combined bounding box, and expands the
    view limits by a fixed fractional margin (default 5%).

    Args:
        ax: Matplotlib Axes instance whose artists are to be fitted.
        margin: Fractional padding around the computed bounding box (default = 0.05).

    Behavior:
        - Collects artists from `ax.patches`, `ax.lines`, `ax.collections`, and `ax.artists`.
        - Falls back to direct vertex inspection if no extent methods exist.
        - Ignores zero-area objects and degenerate extents.
    """
    fig = ax.figure
    renderer = fig.canvas.get_renderer()
    bboxes: list[Bbox] = []

    # Collect all artists already added to the axes
    all_artists = list(ax.patches) + list(ax.lines) + list(ax.collections) + list(ax.artists)

    for a in all_artists:
        try:
            if hasattr(a, "get_extents"):
                bb = a.get_extents()
            elif hasattr(a, "get_datalim"):
                bb = a.get_datalim(ax.transData)
            elif hasattr(a, "get_window_extent"):
                bb = a.get_window_extent(renderer=renderer)
            else:
                # Manual vertex inspection fallback
                if hasattr(a, "get_paths"):
                    verts = np.vstack([p.vertices for p in a.get_paths()])
                elif hasattr(a, "get_data"):
                    x, y = a.get_data()
                    verts = np.column_stack([x, y])
                elif hasattr(a, "vertices"):
                    verts = a.vertices
                else:
                    continue
                bb = Bbox.from_extents(
                    np.min(verts[:, 0]), np.min(verts[:, 1]),
                    np.max(verts[:, 0]), np.max(verts[:, 1]),
                )
        except Exception:
            continue

        if bb.width > 0 and bb.height > 0:
            bboxes.append(bb)

    if not bboxes:
        # Fallback default
        ax.set_xlim(-1, 1)
        ax.set_ylim(-1, 1)
        return

    # --- Combine bounding boxes and apply margin ---
    combined = Bbox.union(bboxes)
    x0, y0, x1, y1 = combined.x0, combined.y0, combined.x1, combined.y1
    dx, dy = x1 - x0, y1 - y0
    pad_x, pad_y = dx * margin, dy * margin

    ax.set_xlim(x0 - pad_x, x1 + pad_x)
    ax.set_ylim(y0 - pad_y, y1 + pad_y)
    ax.set_aspect("equal", adjustable="box")


def preview_mpl_artist(artist, title: str = None):
    """
    Display a Matplotlib artist with automatic axis limits (5% margin),
    hidden axes, and tight layout. Calls plt.show() automatically.

    Args:
        artist: Any of Path, Line2D, LineCollection, PathCollection,
                Patch, or PatchCollection, or a list/tuple of them.
        title:  Optional title for display.
    """
    artists = [artist] if not isinstance(artist, (list, tuple)) else list(artist)
    fig, ax = plt.subplots()

    # Add all artists to axes
    for a in artists:
        if isinstance(a, mplPath):
            ax.add_patch(PathPatch(a, facecolor="none", edgecolor="black", lw=1.5))
        elif isinstance(a, (Line2D, LineCollection, PathCollection, Patch, PatchCollection)):
            ax.add_artist(a)
        else:
            raise TypeError(f"Unsupported artist type: {type(a).__name__}")

    ax_autofit(ax)

    # Final layout
    ax.set_aspect("equal", adjustable="box")
    ax.axis("off")
    if title:
        ax.set_title(title)
    fig.tight_layout(pad=0)

    plt.show()


def main():
    patches = [Circle((0, 0), 1), Rectangle((-1, -0.5), 2, 1)]
    pc = PatchCollection(patches, facecolor='lightgray', edgecolor='black')

    preview_mpl_artist(pc, title="Auto Preview Example")


if __name__ == "__main__":
    main()
``` 
 
===== END mpl_artist_preview.py ===== 
 
===== START mpl_grid_gen.py ===== 
```python 
"""
mpl_grid_gen.py
-----------------

Utilities for generating flexible 2D grids with optional geometric distortion.

The main API produces four Matplotlib ``LineCollection`` objects corresponding
to the four standard sub-grids:

  - X-major lines
  - X-minor lines
  - Y-major lines
  - Y-minor lines

This layout generalizes the major/minor grid structure commonly found in
spreadsheet applications, plotting libraries, and diagramming tools, while
extending it to support oblique (non-orthogonal) and rotated grids.

In addition to deterministic grid construction, the module provides a set of
stochastic distortion mechanisms that can be applied independently to each
sub-grid:

  - Angle jitter
      - Obliquity (inter-axis) angle
      - Global grid rotation angle
      - Individual line orientation

  - Spacing jitter
      - Randomized offsets of major/minor line positions

  - Line dropout
      - Random removal of individual grid lines

All distortion parameters are expressed as 3sigma bounds for truncated normal
distributions. Each bound K defines both a 3sigma range and a hard cutoff:

  - Symmetric jitter:
        K * normal(0, 1/3) clipped to [-K, +K]

  - One-sided jitter (fractions, dropout rates):
        K * |normal(0, 1/3)| clipped to [0, K]

These conventions ensure stable, statistically well-behaved distortions while
preserving simple, intuitive bounds on all grid perturbations.
"""

from __future__ import annotations

__all__ = ["GridJitterConfig", "generate_grid_collections", "debug_dump_grid_info",]

import os
import sys
import math
import random
import sys
from dataclasses import dataclass
from functools import lru_cache
from numbers import Real
from typing import Optional, Sequence, Tuple, Union

import numpy as np
from numpy.typing import NDArray
from matplotlib.collections import LineCollection

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.sep.join(os.path.abspath(__file__).split(os.sep)[:-2]))
from utils.rng import RNGBackend, RNG, get_rng

BBoxTuple = Tuple[float, float, float, float]
BBoxLike = Union[Tuple[Tuple[float, float], Tuple[float, float]], BBoxTuple]


@dataclass(frozen=True)
class GridJitterConfig:
    """Configuration for grid-level and line-level jitter.

    All parameters represent 3sigma bounds for truncated normal distributions.
    All values must be non-negative real numbers (coerced via float()).

    Attributes:
        global_angle_deg:
            3sigma bound for global jitter of obliquity (alpha) and rotation (theta),
            in degrees.

        line_angle_deg:
            3sigma bound for per-line orientation jitter, in degrees.

        line_offset_factor:
            3sigma bound for per-line positional offset as a fraction of the
            corresponding spacing (major/minor).

        line_offset_fraction:
            3sigma bound for the fraction of lines in each sub-grid that receive
            per-line jitter.

        drop_fraction:
            3sigma bound for the fraction of lines randomly removed in each
            sub-grid.
    """

    global_angle_deg     : float = 6.0
    line_angle_deg       : float = 3.0
    line_offset_factor   : float = 0.4
    line_offset_fraction : float = 0.25
    drop_fraction        : float = 0.05

    def __post_init__(self) -> None:
        """Validate that all fields are non-negative Real and coerce to float."""
        for field_name, value in vars(self).items():
            if not isinstance(value, Real):
                raise TypeError(
                    f"{field_name} must be a real number, "
                    f"got {value!r} of type {type(value).__name__}"
                )

            float_val = float(value)
            if float_val < 0:
                raise ValueError(
                    f"{field_name} must be non-negative, got {float_val!r}"
                )

            object.__setattr__(self, field_name, float_val)

    # ---------------------------------------------------------------------------
    # Cached default instance
    # ---------------------------------------------------------------------------
    @staticmethod
    @lru_cache(maxsize=1)
    def DEFAULT() -> "GridJitterConfig":
        """Return a cached default configuration instance."""
        return GridJitterConfig()

    # ---------------------------------------------------------------------------
    # Internal primitive: symmetric truncated normal in [-1, 1]
    # ---------------------------------------------------------------------------
    @staticmethod
    def normal3s(rng: RNGBackend) -> float:
        """Return a symmetric truncated normal sample in [-1, 1]."""
        if hasattr(rng, "normal"):            
            sample = rng.normal(0, 1/3)
        else:
            sample = rng.normalvariate(0, 1/3)
        return max(-1.0, min(1.0, float(sample)))

    # ---------------------------------------------------------------------------
    # Public sampling helpers: signed and one-sided jitters
    # ---------------------------------------------------------------------------
    def jitter_angle_global(self, rng: object) -> float:
        """Return a signed global angle jitter in degrees for alpha and theta."""
        if self.global_angle_deg <= 0.0:
            return 0.0
        return self.global_angle_deg * self.normal3s(rng)

    def jitter_line_angle(self, rng: object) -> float:
        """Return a per-line signed angle jitter in degrees."""
        if self.line_angle_deg <= 0.0:
            return 0.0
        return self.line_angle_deg * self.normal3s(rng)

    def jitter_line_offset(self, rng: object) -> float:
        """Return a signed offset coefficient in [-line_offset_factor, +line_offset_factor].

        This coefficient is dimensionless and should be multiplied by the
        corresponding spacing (major/minor) to obtain an absolute offset.
        """
        if self.line_offset_factor <= 0.0:
            return 0.0
        return self.line_offset_factor * self.normal3s(rng)

    def jitter_offset_fraction(self, rng: object) -> float:
        """Return the fraction of lines that receive per-line jitter.

        Result is in [0, line_offset_fraction].
        """
        if self.line_offset_fraction <= 0.0:
            return 0.0
        return self.line_offset_fraction * abs(self.normal3s(rng))

    def jitter_drop_fraction(self, rng: object) -> float:
        """Return the fraction of lines dropped in a sub-grid.

        Result is in [0, drop_fraction].
        """
        if self.drop_fraction <= 0.0:
            return 0.0
        return self.drop_fraction * abs(self.normal3s(rng))

    # ---------------------------------------------------------------------------
    # Hand-drawn preset
    # ---------------------------------------------------------------------------
    @staticmethod
    def hand_drawn() -> "GridJitterConfig":
        """Return a jitter configuration suitable for hand-drawn style grids.

        Characteristics:
            - Large global angle jitter (alpha, theta)
            - Strong per-line orientation jitter
            - High positional jitter (offset factor)
            - Large fraction of jittered lines
            - Moderate dropout for visual irregularity
        """
        return GridJitterConfig(
            global_angle_deg=12.0,        # strong wobble of overall frame
            line_angle_deg=8.0,           # strong per-line orientation noise
            line_offset_factor=0.8,       # +/-80% of step at 3sigma
            line_offset_fraction=0.50,    # ~50% of lines receive jitter
            drop_fraction=0.08,           # ~8% dropout
        )    
    
    # ---------------------------------------------------------------------------
    # Style preset factory
    # ---------------------------------------------------------------------------
    @staticmethod
    def preset(name: str) -> "GridJitterConfig":
        """
        Return a deterministic jitter configuration corresponding to a named style.

        Supported styles:
            - "sketchy"
            - "technical"
            - "messy"
            - "blueprint"
            - "handwriting_synthetic"
            - "engineering_paper"
            - "architectural_drift"
            - "printlike_subtle"

        Returns:
            A GridJitterConfig instance.
        """

        style = name.lower().strip()

        if style == "sketchy":
            return GridJitterConfig(global_angle_deg=12.0, line_angle_deg=8.0,
                line_offset_factor=0.8, line_offset_fraction=0.50, drop_fraction=0.07)
        if style == "technical":
            return GridJitterConfig(global_angle_deg=1.5, line_angle_deg=1.0,
                line_offset_factor=0.10, line_offset_fraction=0.10, drop_fraction=0.01)
        if style == "messy":
            return GridJitterConfig(global_angle_deg=20.0, line_angle_deg=18.0,
                line_offset_factor=1.2, line_offset_fraction=0.80, drop_fraction=0.18)
        if style == "blueprint":
            return GridJitterConfig(global_angle_deg=0.3, line_angle_deg=0.3,
                line_offset_factor=0.05, line_offset_fraction=0.05, drop_fraction=0.01)
        if style == "handwriting_synthetic":
            return GridJitterConfig(global_angle_deg=4.0, line_angle_deg=3.0,
                line_offset_factor=0.20, line_offset_fraction=0.40, drop_fraction=0.05)
        if style == "engineering_paper":
            return GridJitterConfig(global_angle_deg=1.5, line_angle_deg=0.8,
                line_offset_factor=0.06, line_offset_fraction=0.10, drop_fraction=0.01)
        if style == "architectural_drift":
            return GridJitterConfig(global_angle_deg=5.5, line_angle_deg=0.3,
                line_offset_factor=0.03, line_offset_fraction=0.05, drop_fraction=0.00)
        if style == "printlike_subtle":
            return GridJitterConfig(global_angle_deg=0.15, line_angle_deg=0.15,
                line_offset_factor=0.01, line_offset_fraction=0.02, drop_fraction=0.00)

        raise ValueError(
            f"Unknown jitter preset '{name}'.\n"
            "Valid presets: sketchy, technical, messy, blueprint, "
            "handwriting_synthetic, engineering_paper, architectural_drift, "
            "printlike_subtle."
        )


def generate_grid_collections(
        bbox          : BBoxLike,
        obliquity_deg : float,
        rotation_deg  : float,
        x_major_step  : float,
        x_minor_step  : float,
        y_major_step  : float,
        y_minor_step  : float,
        jitter        : GridJitterConfig = None,
        rng           : RNGBackend       = None,
    ) -> Tuple[LineCollection, LineCollection, LineCollection, LineCollection]:
    """Generate LineCollections for a 2D oblique grid with optional jitter.

    Args:
        bbox:
            Bounding box as either ((x_min, y_min), (x_max, y_max)) or
            (x_min, y_min, x_max, y_max).

        obliquity_deg:
            Inter-axis (obliquity) angle between the x and y grid directions,
            in degrees. 90deg corresponds to an orthogonal grid.

        rotation_deg:
            Rotation of the x-family axis in degrees (CCW, world coordinates).
            The y-family axis is located at rotation_deg + obliquity_deg.

        x_major_step:
            Spacing for X-major grid lines (in x-coordinate units).

        x_minor_step:
            Spacing for X-minor grid lines.

        y_major_step:
            Spacing for Y-major grid lines.

        y_minor_step:
            Spacing for Y-minor grid lines.

        jitter:
            Optional GridJitterConfig. If provided, enables stochastic
            distortion of grid angles, offsets, and line dropout.

        rng:
            Optional random number generator. If None, a new
            random.Random() instance is created. The RNG must support at
            least one of: normal3s(), normalvariate(), normal().

    Returns:
        A tuple of four LineCollections:
            (x_major_lc, x_minor_lc, y_major_lc, y_minor_lc).
    """
    x_min, y_min, x_max, y_max = _parse_bbox(bbox)

    if rng is None:
        rng = random.Random()

    # ---------------------------------------------------------------------------
    # 1) Global angle setup and jitter
    # ---------------------------------------------------------------------------
    theta_rad = math.radians(rotation_deg)
    alpha_rad = math.radians(obliquity_deg)

    if jitter is not None and jitter.global_angle_deg > 0.0:
        theta_rad += math.radians(jitter.jitter_angle_global(rng))
        alpha_rad += math.radians(jitter.jitter_angle_global(rng))

    # Basis vectors for the oblique grid.
    # X-family axis (u) at angle theta_rad.
    # Y-family axis (v) at angle theta_rad + alpha_rad.
    ex = np.array([math.cos(theta_rad), math.sin(theta_rad)], dtype=float)
    ey = np.array(
        [math.cos(theta_rad + alpha_rad), math.sin(theta_rad + alpha_rad)],
        dtype=float,
    )

    # (u, v) -> (x, y) linear map has columns ex, ey.
    M = np.array([[ex[0], ey[0]], [ex[1], ey[1]]], dtype=float)
    Minv = np.linalg.inv(M)

    # ---------------------------------------------------------------------------
    # 2) Express bbox corners in (u, v) coordinates to determine index ranges
    # ---------------------------------------------------------------------------
    corners = np.array(
        [
            [x_min, y_min],
            [x_max, y_min],
            [x_min, y_max],
            [x_max, y_max],
        ],
        dtype=float,
    )
    uv_corners = corners @ Minv.T
    u_vals = uv_corners[:, 0]
    v_vals = uv_corners[:, 1]
    u_min, u_max = float(u_vals.min()), float(u_vals.max())
    v_min, v_max = float(v_vals.min()), float(v_vals.max())

    bbox_tuple: BBoxTuple = (x_min, y_min, x_max, y_max)

    # ---------------------------------------------------------------------------
    # 3) Build line families: constants in u or v, direction ex or ey
    # ---------------------------------------------------------------------------
    x_major_segments = _build_line_family(
        coord_min=u_min,
        coord_max=u_max,
        step=x_major_step,
        fixed_vec=ex,
        dir_vec=ey,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=x_major_step,
    )

    x_minor_segments = _build_line_family(
        coord_min=u_min,
        coord_max=u_max,
        step=x_minor_step,
        fixed_vec=ex,
        dir_vec=ey,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=x_minor_step,
    )

    y_major_segments = _build_line_family(
        coord_min=v_min,
        coord_max=v_max,
        step=y_major_step,
        fixed_vec=ey,
        dir_vec=ex,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=y_major_step,
    )

    y_minor_segments = _build_line_family(
        coord_min=v_min,
        coord_max=v_max,
        step=y_minor_step,
        fixed_vec=ey,
        dir_vec=ex,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=y_minor_step,
    )

    # ---------------------------------------------------------------------------
    # 4) Wrap into LineCollections
    # ---------------------------------------------------------------------------
    x_major_lc = LineCollection(x_major_segments)
    x_minor_lc = LineCollection(x_minor_segments)
    y_major_lc = LineCollection(y_major_segments)
    y_minor_lc = LineCollection(y_minor_segments)

    return x_major_lc, x_minor_lc, y_major_lc, y_minor_lc


def debug_dump_grid_info(
        bbox          : BBoxLike,
        obliquity_deg : float,
        rotation_deg  : float,
        x_major_step  : float,
        x_minor_step  : float,
        y_major_step  : float,
        y_minor_step  : float,
        jitter        : GridJitterConfig = None,
        rng           : RNGBackend       = None,
        file                             = None,
    ) -> None:
    """
    Print a detailed diagnostic dump of grid construction internals.

    Useful for debugging:

      - coordinate-space (u,v) ranges
      - line index ranges (k_min..k_max)
      - candidate line coordinates
      - which lines intersect the bbox
      - drop/jitter masks
      - final clipped segment counts
      - numerical edge cases

    Args:
        bbox:
            Bounding box in world coordinates.

        obliquity_deg, rotation_deg:
            Grid geometry parameters.

        x_major_step, x_minor_step, y_major_step, y_minor_step:
            Grid spacings.

        jitter:
            Optional jitter configuration.

        rng:
            Optional RNG for reproducible jitter.

        file:
            Optional file-like object to write output (default: sys.stdout).
    """
    if file is None:
        file = sys.stdout

    printf = lambda *a, **k: __builtins__["print"](*a, **k, file=file)

    printf("\n================ GRID DEBUG DUMP ================")
    printf(f"bbox = {bbox}")
    printf(f"obliquity_deg = {obliquity_deg}")
    printf(f"rotation_deg  = {rotation_deg}")
    printf(f"x_major_step  = {x_major_step}")
    printf(f"x_minor_step  = {x_minor_step}")
    printf(f"y_major_step  = {y_major_step}")
    printf(f"y_minor_step  = {y_minor_step}")
    printf(f"jitter        = {jitter}")

    # -----------------------------------------------------------
    # 1) Recompute u/v ranges and basis vectors exactly like main
    # -----------------------------------------------------------

    x_min, y_min, x_max, y_max = _parse_bbox(bbox)

    theta_rad = math.radians(rotation_deg)
    alpha_rad = math.radians(obliquity_deg)

    if rng is None:
        rng = random.Random()

    if jitter is not None and jitter.global_angle_deg > 0.0:
        theta_rad += math.radians(jitter.jitter_angle_global(rng))
        alpha_rad += math.radians(jitter.jitter_angle_global(rng))

    ex = np.array([math.cos(theta_rad), math.sin(theta_rad)], dtype=float)
    ey = np.array(
        [math.cos(theta_rad + alpha_rad), math.sin(theta_rad + alpha_rad)],
        dtype=float,
    )

    M = np.array([[ex[0], ey[0]], [ex[1], ey[1]]], dtype=float)
    Minv = np.linalg.inv(M)

    corners = np.array([
            [x_min, y_min],
            [x_max, y_min],
            [x_min, y_max],
            [x_max, y_max],
    ], dtype=float)
    uv = corners @ Minv.T
    u_vals = uv[:, 0]
    v_vals = uv[:, 1]
    u_min, u_max = float(u_vals.min()), float(u_vals.max())
    v_min, v_max = float(v_vals.min()), float(v_vals.max())

    printf("\n--- Coordinate-space (u,v) ranges ---")
    printf(f"u_min={u_min:.6f}, u_max={u_max:.6f}")
    printf(f"v_min={v_min:.6f}, v_max={v_max:.6f}")

    # Helper to analyze a single line family
    def analyze_family(name, coord_min, coord_max, step, fixed_vec, dir_vec):
        printf(f"\n=== FAMILY: {name} ===")
        if step <= 0:
            printf("  step <= 0 - no lines")
            return

        k_min = int(math.floor(coord_min / step)) - 1
        k_max = int(math.ceil(coord_max / step)) + 1

        printf(f"  coord range: {coord_min:.3f} .. {coord_max:.3f}")
        printf(f"  step       : {step}")
        printf(f"  k_min={k_min}, k_max={k_max}, total candidates = {k_max-k_min+1}")

        # All candidate raw coordinates
        coords = np.arange(k_min, k_max + 1, dtype=float) * step
        printf(f"  coords (raw): {coords}")

        # Test intersection for each
        def intersects(c0):
            # same method _clip_infinite_line_to_bbox() uses
            p0 = c0 * fixed_vec
            d = dir_vec
            x0, y0 = p0
            dx, dy = d
            eps = 1e-12
            ts = []

            if abs(dx) > eps:
                for xb in (x_min, x_max):
                    t = (xb - x0) / dx
                    y = y0 + t * dy
                    if y_min - eps <= y <= y_max + eps:
                        ts.append(t)
            if abs(dy) > eps:
                for yb in (y_min, y_max):
                    t = (yb - y0) / dy
                    x = x0 + t * dx
                    if x_min - eps <= x <= x_max + eps:
                        ts.append(t)

            return len(ts) >= 2

        mask = [intersects(c) for c in coords]
        printf(f"  intersects: {mask}")
        printf(f"  kept coords: {[float(c) for c, m in zip(coords, mask) if m]}")

    # -----------------------------------------------------------
    # 2) Analyze each line family exactly as generator sees them
    # -----------------------------------------------------------
    analyze_family("X-MAJOR", u_min, u_max, x_major_step, ex, ey)
    analyze_family("X-MINOR", u_min, u_max, x_minor_step, ex, ey)
    analyze_family("Y-MAJOR", v_min, v_max, y_major_step, ey, ex)
    analyze_family("Y-MINOR", v_min, v_max, y_minor_step, ey, ex)

    printf("\n============== END DEBUG DUMP ==============\n")


# =============================================================================
# Internals
# =============================================================================


def _parse_bbox(bbox: BBoxLike) -> BBoxTuple:
    """Normalize bbox into the form (x_min, y_min, x_max, y_max)."""
    if (isinstance(bbox, Sequence)
        and len(bbox) == 2
        and isinstance(bbox[0], Sequence)):
        (x0, y0), (x1, y1) = bbox  # type: ignore[misc]
    elif isinstance(bbox, Sequence) and len(bbox) == 4:
        x0, y0, x1, y1 = bbox  # type: ignore[misc]
    else:
        raise ValueError(
            "bbox must be ((x_min, y_min), (x_max, y_max)) "
            "or (x_min, y_min, x_max, y_max)"
        )

    x_min = float(min(x0, x1))
    x_max = float(max(x0, x1))
    y_min = float(min(y0, y1))
    y_max = float(max(y0, y1))
    return x_min, y_min, x_max, y_max


def _build_line_family(
        coord_min        : float,
        coord_max        : float,
        step             : float,
        fixed_vec        : NDarray,
        dir_vec          : NDarray,
        bbox             : BBoxTuple,
        rng              : RNGBackend,
        jitter           : GridJitterConfig,
        base_offset_step : float,
    ) -> NDarray:
    """Generate clipped line segments for a single grid-line family.

    Args:
        coord_min:
            Minimum coordinate (u or v) over bbox corners.

        coord_max:
            Maximum coordinate (u or v) over bbox corners.

        step:
            Nominal spacing along that coordinate for this family
            (major or minor).

        fixed_vec:
            Unit vector along which the fixed coordinate is applied:
                - ex for X-family lines (u = const)
                - ey for Y-family lines (v = const)

        dir_vec:
            Nominal direction vector of the lines:
                - ey for X-family lines
                - ex for Y-family lines

        bbox:
            Axis-aligned bounding box in world coordinates.

        rng:
            Random number generator compatible with GridJitterConfig.

        jitter:
            Optional GridJitterConfig controlling offsets, orientations,
            and dropout.

        base_offset_step:
            Step used to convert dimensionless offset coefficients into
            absolute displacements.

    Returns:
        segments:
            NumPy array of shape (n_lines, 2, 2) containing line endpoints.
    """
    x_min, y_min, x_max, y_max = bbox

    if step <= 0.0:
        return np.empty((0, 2, 2), dtype=float)

    # Determine index range in coordinate space with a small padding
    k_min = int(math.floor(coord_min / step)) - 1
    k_max = int(math.ceil(coord_max / step)) + 1
    if k_max < k_min:
        return np.empty((0, 2, 2), dtype=float)

    coord_values = np.arange(k_min, k_max + 1, dtype=float) * step
    n = coord_values.size
    if n == 0:
        return np.empty((0, 2, 2), dtype=float)

    indices = np.arange(n)

    # ---------------------------------------------------------------------------
    # Per-group jitter/drop fractions
    # ---------------------------------------------------------------------------
    if jitter is not None:
        jitter_frac = jitter.jitter_offset_fraction(rng)
        drop_frac = jitter.jitter_drop_fraction(rng)
    else:
        jitter_frac = 0.0
        drop_frac = 0.0

    keep_mask = np.ones(n, dtype=bool)

    # Randomly mark lines to be dropped
    if drop_frac > 0.0:
        n_drop = int(round(drop_frac * n))
        n_drop = min(max(n_drop, 0), n)
        if n_drop > 0:
            drop_idx = np.random.default_rng().choice(
                indices, size=n_drop, replace=False
            )
            keep_mask[drop_idx] = False

    jitter_mask = np.zeros(n, dtype=bool)
    if jitter_frac > 0.0 and keep_mask.any():
        n_keep = int(keep_mask.sum())
        n_jitter = int(round(jitter_frac * n_keep))
        n_jitter = min(max(n_jitter, 0), n_keep)
        if n_jitter > 0:
            candidate_idx = indices[keep_mask]
            chosen = np.random.default_rng().choice(
                candidate_idx, size=n_jitter, replace=False
            )
            jitter_mask[chosen] = True

    # ---------------------------------------------------------------------------
    # Build and clip each line
    # ---------------------------------------------------------------------------
    base_phi = math.atan2(dir_vec[1], dir_vec[0])
    segments = []

    for i, c0 in enumerate(coord_values):
        if not keep_mask[i]:
            continue

        coord_val = c0
        phi = base_phi

        if jitter is not None and jitter_mask[i]:
            # Positional jitter along the fixed coordinate
            if jitter.line_offset_factor > 0.0 and base_offset_step > 0.0:
                offset_coeff = jitter.jitter_line_offset(rng)
                coord_val += offset_coeff * base_offset_step

            # Orientation jitter
            if jitter.line_angle_deg > 0.0:
                phi += math.radians(jitter.jitter_line_angle(rng))

        d = np.array([math.cos(phi), math.sin(phi)], dtype=float)
        p0 = coord_val * fixed_vec

        seg = _clip_infinite_line_to_bbox(p0, d, x_min, y_min, x_max, y_max)
        if seg is not None:
            segments.append(seg)

    if not segments:
        return np.empty((0, 2, 2), dtype=float)

    return np.stack(segments, axis=0)


def _clip_infinite_line_to_bbox(
        p0    : NDarray,
        d     : NDarray,
        x_min : float,
        y_min : float,
        x_max : float,
        y_max : float,
    ) -> NDarray:
    """Clip an infinite line to an axis-aligned bounding box.

    The infinite line is given by p(t) = p0 + t * d.

    Args:
        p0:
            Base point on the line.

        d:
            Direction vector of the line.

        x_min, y_min, x_max, y_max:
            Bounding box limits.

    Returns:
        A (2, 2) array [[x1, y1], [x2, y2]] representing the clipped segment,
        or None if the line does not intersect the bbox.
    """
    x0, y0 = float(p0[0]), float(p0[1])
    dx, dy = float(d[0]), float(d[1])
    eps = 1e-12

    ts = []

    # Intersections with x = constant
    if abs(dx) > eps:
        for xb in (x_min, x_max):
            t = (xb - x0) / dx
            y = y0 + t * dy
            if y_min - eps <= y <= y_max + eps:
                ts.append(t)

    # Intersections with y = constant
    if abs(dy) > eps:
        for yb in (y_min, y_max):
            t = (yb - y0) / dy
            x = x0 + t * dx
            if x_min - eps <= x <= x_max + eps:
                ts.append(t)

    if len(ts) < 2:
        return None

    ts_sorted = sorted(ts)
    t1, t2 = ts_sorted[0], ts_sorted[-1]

    p1 = np.array([x0 + t1 * dx, y0 + t1 * dy], dtype=float)
    p2 = np.array([x0 + t2 * dx, y0 + t2 * dy], dtype=float)
    return np.stack([p1, p2], axis=0)

``` 
 
===== END mpl_grid_gen.py ===== 
 
===== START mpl_grid_gen_demo.py ===== 
```python 
"""
mpl_grid_gen_demo.py
--------------------

Demonstration of jittered oblique grids using presets.

Includes visual gallery of multiple jitter presets from mpl_grid_utils.py.
Produces an 8-panel (2x4) comparison of different grid distortion styles.
"""

from __future__ import annotations

import matplotlib.pyplot as plt

import os
import sys

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.sep.join(os.path.abspath(__file__).split(os.sep)[:-2]))
from utils.rng import RNGBackend, RNG, get_rng

from mpl_grid_gen import (
    generate_grid_collections,
    debug_dump_grid_info,
    GridJitterConfig,
)


# ---------------------------------------------------------------------------
# Helper function for drawing a single grid into an Axes
# ---------------------------------------------------------------------------
def draw_grid(ax, preset_name, bbox=(-10, -10, 10, 10)):

    # Create jitter config from preset
    jitter = GridJitterConfig.preset(preset_name)

    # Grid geometry
    obliquity_deg = 60.0
    rotation_deg = 20.0

    x_major_step = 3.0
    x_minor_step = 1.0
    y_major_step = 3.0
    y_minor_step = 1.0

    xM, xm, yM, ym = generate_grid_collections(
        bbox=bbox,
        obliquity_deg=obliquity_deg,
        rotation_deg=rotation_deg,
        x_major_step=x_major_step,
        x_minor_step=x_minor_step,
        y_major_step=y_major_step,
        y_minor_step=y_minor_step,
        jitter=jitter,
    )

    # Styling
    for lc in (xM, yM):
        lc.set_linewidth(1.4)
        lc.set_color((0.15, 0.15, 0.15, 0.8))
    for lc in (xm, ym):
        lc.set_linewidth(0.7)
        lc.set_color((0.15, 0.15, 0.15, 0.4))

    # Add to axes
    ax.add_collection(xM)
    ax.add_collection(xm)
    ax.add_collection(yM)
    ax.add_collection(ym)

    ax.set_xlim(bbox[0], bbox[2])
    ax.set_ylim(bbox[1], bbox[3])
    ax.set_aspect("equal", adjustable="box")
    ax.set_title(preset_name.replace("_", " ").title(), fontsize=10)

    ax.set_xticks([])
    ax.set_yticks([])


# ---------------------------------------------------------------------------
# Gallery
# ---------------------------------------------------------------------------
def demo0():

    debug_dump_grid_info(
        bbox=(-10,-10,10,10),
        obliquity_deg=90,
        rotation_deg=0,
        x_major_step=5,
        x_minor_step=2.5,
        y_major_step=5,
        y_minor_step=2.5,
        jitter = GridJitterConfig()
    )    
        
    
    presets = [
        "handwriting_synthetic",
        "engineering_paper",
        "architectural_drift",
        "printlike_subtle",
        "sketchy",
        "technical",
        "messy",
        "blueprint",
    ]

    fig, axes = plt.subplots(
        nrows=2, ncols=4, figsize=(10, 16),
        constrained_layout=True
    )

    for ax, preset in zip(axes.ravel(), presets):
        draw_grid(ax, preset)

    fig.suptitle("Grid Jitter Preset Gallery (2x4)", fontsize=16, y=0.995)
    plt.show()



def demo1():
    # Plot area (world coordinates)
    bbox = (-10.0, -10.0, 10.0, 10.0)

    # Oblique grid: 60deg between axes, rotated 20deg CCW
    obliquity_deg = 60.0
    rotation_deg = 20.0

    # Steps: fairly fine minor grid, more spaced major grid
    x_major = 3.0
    x_minor = 1.0
    y_major = 3.0
    y_minor = 1.0

    # Use the hand-drawn preset
    jitter = GridJitterConfig.hand_drawn()

    x_major_lc, x_minor_lc, y_major_lc, y_minor_lc = generate_grid_collections(
        bbox=bbox,
        obliquity_deg=obliquity_deg,
        rotation_deg=rotation_deg,
        x_major_step=x_major,
        x_minor_step=x_minor,
        y_major_step=y_major,
        y_minor_step=y_minor,
        jitter=jitter,
    )

    # Styling
    for lc in (x_major_lc, y_major_lc):
        lc.set_linewidth(1.5)
        lc.set_color((0.1, 0.1, 0.1, 0.8))  # dark grey, almost black

    for lc in (x_minor_lc, y_minor_lc):
        lc.set_linewidth(0.8)
        lc.set_color((0.1, 0.1, 0.1, 0.4))  # lighter grey

    # Plotting
    fig, ax = plt.subplots(figsize=(7, 7))
    ax.add_collection(x_major_lc)
    ax.add_collection(x_minor_lc)
    ax.add_collection(y_major_lc)
    ax.add_collection(y_minor_lc)

    ax.set_xlim(bbox[0], bbox[2])
    ax.set_ylim(bbox[1], bbox[3])
    ax.set_aspect("equal", adjustable="box")

    ax.set_title("Heavily Jittered Oblique Grid (Hand-drawn Preset)")
    ax.set_xticks([])
    ax.set_yticks([])

    plt.show()


def demo2():
    fig, ax = plt.subplots(figsize=(6, 6))
    
    bbox = ((-10.0, -10.0), (10.0, 10.0))
    
    x_major_lc, x_minor_lc, y_major_lc, y_minor_lc = generate_grid_collections(
        bbox=bbox,
        obliquity_deg=90.0,      # orthogonal
        rotation_deg=15.0,      # rotate grid 15deg CCW
        x_major_step=2.0,
        x_minor_step=0.5,
        y_major_step=2.0,
        y_minor_step=0.5,
        jitter=GridJitterConfig(),  # enable jitter with defaults
    )
    
    # Style the collections however you like
    x_major_lc.set_linewidth(1.2)
    x_major_lc.set_alpha(0.7)
    
    x_minor_lc.set_linewidth(0.6)
    x_minor_lc.set_alpha(0.4)
    
    y_major_lc.set_linewidth(1.2)
    y_major_lc.set_alpha(0.7)
    
    y_minor_lc.set_linewidth(0.6)
    y_minor_lc.set_alpha(0.4)
    
    ax.add_collection(x_major_lc)
    ax.add_collection(x_minor_lc)
    ax.add_collection(y_major_lc)
    ax.add_collection(y_minor_lc)
    
    ax.set_title("Default Jittered Oblique Grid")
    ax.set_xlim(-10, 10)
    ax.set_ylim(-10, 10)
    ax.set_aspect("equal", adjustable="box")
    
    plt.show()



def demo3():
    pass
    """
    lc.set(**{
        "linewidths": 1.2,
        "colors": "tab:blue",
        "alpha": 0.6,
        "linestyles": "--",
        "zorder": 0,
    })
    """

def main():
    demo0()
    demo1()
    demo2()


if __name__ == "__main__":
    main()
``` 
 
===== END mpl_grid_gen_demo.py ===== 
 
===== START mpl_grid_gen_effects.py ===== 
```python 
"""
mpl_grid_gen_effects.py
-----------------------

Optional post-processing effects for grid line geometry and rendering.
These effects operate on Matplotlib LineCollections and/or their backing
segment arrays.

Included effects:
    1) Low-frequency distortion fields (Perlin/Simplex-like approximation)
    2) Pencil-style linewidth modulation
    3) Organic endpoint perturbation ("pen pressure" look)
    4) Subtle paper texture generation (low-contrast, multi-scale noise)
"""

from __future__ import annotations

import math
from dataclasses import dataclass
from typing import Tuple, Optional

import numpy as np
from matplotlib.collections import LineCollection

# ======================================================================
# 1) LOW-FREQUENCY DISTORTION FIELD (Perlin/Simplex-like)
# ======================================================================


@dataclass(frozen=True)
class SinusoidalDistortionField:
    """Smooth pseudo-Perlin displacement field for warping grids.

    The displacement is a mean of sinusoidal modes at randomized phases
    and low spatial frequencies. It approximates Perlin/Simplex-style
    warping sufficiently well for hand-drawn grid aesthetics.

    Args:
        amplitude:
            Maximum displacement magnitude (~3s) in world units.

        min_freq, max_freq:
            Frequency bounds for sinusoidal modes (cycles per world unit).

        n_modes:
            Number of sinusoidal modes per component.

        seed:
            RNG seed for reproducible field.
    """

    amplitude: float = 0.5
    min_freq: float = 0.02
    max_freq: float = 0.08
    n_modes: int = 5
    seed: Optional[int] = None

    # Internal cached params
    def _params(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        rng = np.random.default_rng(self.seed)
        freqs = rng.uniform(self.min_freq, self.max_freq, size=(self.n_modes, 2))
        phase_x = rng.uniform(0.0, 2 * math.pi, size=self.n_modes)
        phase_y = rng.uniform(0.0, 2 * math.pi, size=self.n_modes)
        return freqs, phase_x, phase_y

    def displacement(self, xy: np.ndarray) -> np.ndarray:
        """Evaluate displacement field at given (x,y) points.

        Args:
            xy: array (..., 2)

        Returns:
            Array (..., 2) offsets in world coordinates.
        """
        xy = np.asarray(xy, float)
        flat = xy.reshape(-1, 2)

        freqs, px, py = self._params()

        x = flat[:, 0:1]
        y = flat[:, 1:2]

        arg = 2 * math.pi * (x * freqs[:, 0] + y * freqs[:, 1])  # (N, m)

        dx = np.sin(arg + px).mean(axis=1)
        dy = np.sin(arg + py).mean(axis=1)

        disp = np.stack([dx, dy], axis=-1) * self.amplitude
        return disp.reshape(xy.shape)


def warp_segments_with_field(
    segments: np.ndarray,
    field: SinusoidalDistortionField,
    strength: float = 1.0,
) -> np.ndarray:
    """Warp line segments by sampling a distortion field.

    Args:
        segments: array (n_segments, 2, 2)
        field: SinusoidalDistortionField
        strength: scaling factor for displacement

    Returns:
        Warped segment array of same shape.
    """
    segs = np.asarray(segments, float)
    pts = segs.reshape(-1, 2)
    pts_w = pts + field.displacement(pts) * strength
    return pts_w.reshape(segs.shape)


def warp_line_collection(
    lc: LineCollection,
    field: SinusoidalDistortionField,
    strength: float = 1.0,
) -> None:
    """Warp an existing LineCollection in-place."""
    segs = lc.get_segments()
    warped = warp_segments_with_field(segs, field, strength)
    lc.set_segments(warped)


# ======================================================================
# 2) PENCIL-SKETCH LINEWIDTH MODULATION
# ======================================================================


def apply_pencil_linewidths(
    lc: LineCollection,
    base_width: float = 1.5,
    jitter_fraction: float = 0.4,
    seed: Optional[int] = None,
) -> None:
    """Apply per-segment linewidth jitter to simulate pencil strokes.

    Line widths:
        w_i = base * (1 + jitter_fraction * N(0, 1/3)),
        clipped to [0.1*base, +inf).

    Args:
        lc: Matplotlib LineCollection
        base_width: nominal line width
        jitter_fraction: relative jitter strength
        seed: RNG seed
    """
    segs = lc.get_segments()
    n = len(segs)
    if n == 0:
        return

    rng = np.random.default_rng(seed)

    if jitter_fraction <= 0.0:
        widths = np.full(n, float(base_width))
    else:
        noise = rng.normal(loc=0.0, scale=1.0 / 3.0, size=n)
        widths = base_width * (1.0 + jitter_fraction * noise)
        widths = np.clip(widths, 0.1 * base_width, None)

    lc.set_linewidths(widths)


# ======================================================================
# 3) ENDPOINT MICRO-PERTURBATION ("pen pressure")
# ======================================================================


def perturb_segment_endpoints(
    segments: np.ndarray,
    max_offset: float = 0.15,
    seed: Optional[int] = None,
) -> np.ndarray:
    """Perturb endpoints along the normal to the segment.

    Args:
        segments: array (n, 2, 2)
        max_offset: 3s bound for offset magnitude
        seed: RNG seed

    Returns:
        New segment array.
    """
    segs = np.asarray(segments, dtype=float)
    n = len(segs)
    if n == 0 or max_offset <= 0:
        return segs.copy()

    rng = np.random.default_rng(seed)

    p1 = segs[:, 0, :]
    p2 = segs[:, 1, :]

    v = p2 - p1
    L = np.linalg.norm(v, axis=1, keepdims=True)
    L = np.maximum(L, 1e-12)

    normals = np.stack([-v[:, 1], v[:, 0]], axis=1) / L

    sigma = max_offset / 3.0
    off1 = rng.normal(0.0, sigma, size=(n, 1))
    off2 = rng.normal(0.0, sigma, size=(n, 1))

    p1p = p1 + off1 * normals
    p2p = p2 + off2 * normals

    out = segs.copy()
    out[:, 0, :] = p1p
    out[:, 1, :] = p2p
    return out


def perturb_line_collection(
    lc: LineCollection,
    max_offset: float = 0.15,
    seed: Optional[int] = None,
) -> None:
    """Apply endpoint micro-perturbation in-place."""
    segs = lc.get_segments()
    lc.set_segments(perturb_segment_endpoints(segs, max_offset, seed))


# ======================================================================
# 4) PAPER TEXTURE (fast, subtle, low-contrast)
# ======================================================================


def _box_blur(img: np.ndarray, radius: int) -> np.ndarray:
    """Cheap separable box filter using cumulative sums."""
    if radius <= 0:
        return img

    h, w = img.shape
    pad = radius

    # Horizontal blur
    tmp = np.pad(img, ((0, 0), (pad, pad)), mode="reflect")
    csum = np.cumsum(tmp, axis=1)
    left = csum[:, :-2 * pad]
    right = csum[:, 2 * pad :]
    horz = (right - left) / (2 * pad)

    # Vertical blur
    tmp = np.pad(horz, ((pad, pad), (0, 0)), mode="reflect")
    csum = np.cumsum(tmp, axis=0)
    top = csum[:-2 * pad, :]
    bot = csum[2 * pad :, :]
    vert = (bot - top) / (2 * pad)
    return vert


def generate_paper_texture(
    shape: Tuple[int, int] = (1024, 1024),
    seed: Optional[int] = None,
    base_color: Tuple[float, float, float] = (0.97, 0.97, 0.94),
    max_deviation: float = 0.05,
    n_layers: int = 3,
) -> np.ndarray:
    """Generate low-contrast procedural paper texture.

    Args:
        shape: (H, W)
        seed: RNG seed
        base_color: base RGB in [0,1]
        max_deviation: max +/- deviation from base_color
        n_layers: multi-scale noise layers

    Returns:
        Float32 array (H, W, 3) in [0,1].
    """
    rng = np.random.default_rng(seed)
    h, w = shape
    acc = np.zeros((h, w), float)

    for i in range(n_layers):
        noise = rng.normal(0.0, 1.0, size=(h, w))
        radius = 2 ** (i + 1)
        smooth = _box_blur(noise, radius)
        acc += smooth

    acc -= acc.mean()
    acc /= (acc.std() or 1.0)
    acc *= max_deviation

    base = np.array(base_color, dtype=float).reshape(1, 1, 3)
    tex = np.clip(base + acc[..., None], 0.0, 1.0)
    return tex.astype(np.float32)


def resolve_theme_from_preset(preset_name: str) -> str:
    """Map jitter preset to the default visual theme."""
    name = preset_name.lower()

    if name in ("blueprint", "architectural_drift"):
        return "blueprint"
    if name in ("sketchy", "messy", "handwriting_synthetic"):
        return "sketchy"
    if name in ("engineering_paper", "technical"):
        return "engineering_paper"
    if name in ("printlike_subtle", "blueprint_clean"):
        return "printlike_subtle"

    return "default"


def style_lc(
    lc,
    *,
    linewidth: float | None = None,
    color: str | tuple | None = None,
    alpha: float | None = None,
    linestyle: str | None = None,
    zorder: float | None = None,
):
    """Convenience styling helper for LineCollection.

    Accepts intuitive kwargs matching matplotlib.plot() naming, converts
    them to the correct LineCollection property names, and applies them.
    """
    props = {}

    if linewidth is not None:
        props["linewidths"] = linewidth

    if color is not None:
        props["colors"] = color

    if alpha is not None:
        props["alpha"] = alpha

    if linestyle is not None:
        props["linestyles"] = linestyle

    if zorder is not None:
        props["zorder"] = zorder

    if props:
        lc.set(**props)


GRID_COLOR_PALETTES = {
    "default": {
        "major":  (0.15, 0.15, 0.15, 0.9),
        "minor":  (0.15, 0.15, 0.15, 0.4),
    },

    "blueprint": {   # classic blueprint-blue
        "major":  (0.10, 0.25, 0.70, 0.90),
        "minor":  (0.10, 0.25, 0.70, 0.45),
    },

    "engineering_paper": {   # muted graphite
        "major":  (0.00, 0.00, 0.00, 0.80),
        "minor":  (0.00, 0.00, 0.00, 0.35),
    },

    "sketchy": {    # pencil style
        "major":  (0.10, 0.10, 0.10, 0.85),
        "minor":  (0.10, 0.10, 0.10, 0.45),
    },

    "messy": {      # chaotic scribbles
        "major":  (0.05, 0.05, 0.05, 0.85),
        "minor":  (0.05, 0.05, 0.05, 0.35),
    },

    "printlike_subtle": {    # crisp laser printer
        "major":  (0.00, 0.00, 0.00, 0.95),
        "minor":  (0.00, 0.00, 0.00, 0.20),
    },

    "handwriting_synthetic": {  # notebook pencil
        "major":  (0.12, 0.12, 0.12, 0.85),
        "minor":  (0.12, 0.12, 0.12, 0.40),
    },

    "architectural_drift": {   # blueprint-like but softer
        "major":  (0.08, 0.18, 0.55, 0.90),
        "minor":  (0.08, 0.18, 0.55, 0.45),
    },
}


def apply_grid_style(
    x_major_lc,
    x_minor_lc,
    y_major_lc,
    y_minor_lc,
    *,
    style: str = "default",
    linewidth_major: float = 1.2,
    linewidth_minor: float = 0.6,
    linestyle_major: str = "-",
    linestyle_minor: str = "-",
    zorder: float = 0,
):
    """Apply a complete styling scheme to all four grid collections."""

    palette = GRID_COLOR_PALETTES.get(style, GRID_COLOR_PALETTES["default"])

    major_color = palette["major"]
    minor_color = palette["minor"]

    # Major lines
    for lc in (x_major_lc, y_major_lc):
        style_lc(
            lc,
            linewidth=linewidth_major,
            color=major_color,
            linestyle=linestyle_major,
            alpha=major_color[3],
            zorder=zorder,
        )

    # Minor lines
    for lc in (x_minor_lc, y_minor_lc):
        style_lc(
            lc,
            linewidth=linewidth_minor,
            color=minor_color,
            linestyle=linestyle_minor,
            alpha=minor_color[3],
            zorder=zorder,
        )
``` 
 
===== END mpl_grid_gen_effects.py ===== 
 
===== START mpl_grid_gen_pipeline.py ===== 
```python 
"""
mpl_grid_gen_pipeline.py
------------------------

High-level aesthetic pipeline for applying visual effects to grid
LineCollections produced by mpl_grid_utils.generate_grid_collections().

The pipeline can:
    - Apply low-frequency warping (Perlin-like)
    - Apply endpoint perturbation ("pen pressure")
    - Apply pencil-style linewidth jitter
    - Apply major/minor styling
    - Add a paper texture background
    - Use named presets for complete styles

This module depends on:
    - grid_effects.py  (for primitive effects)
    - mpl_grid_utils   (only indirectly, for user-level integration)
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Tuple, Dict, Any

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection

from mpl_grid_gen import GridJitterConfig, generate_grid_collections
from mpl_grid_gen_effects import (
    SinusoidalDistortionField,
    warp_line_collection,
    perturb_line_collection,
    apply_pencil_linewidths,
    generate_paper_texture,
    apply_grid_style,
    resolve_theme_from_preset,
)


@dataclass
class GridEffectsPipeline:
    """
    High-level grid post-processing pipeline.

    Each step is optional. The pipeline can be applied to:
        - the segment geometry of line collections (warp, perturb)
        - styling (colors, widths, linestyles)
        - the plot background (paper texture)

    The pipeline is intentionally stateless except for preset parameters.
    """

    # --- Distortion field ---
    distortion_field: Optional[SinusoidalDistortionField] = None
    distortion_strength: float = 1.0

    # --- Endpoint jitter ---
    endpoint_offset: float = 0.0       # world units

    # --- Linewidth modulation ---
    pencil_width_major: Optional[Tuple[float, float]] = None  # (base, jitter_frac)
    pencil_width_minor: Optional[Tuple[float, float]] = None

    # --- Background (paper) ---
    paper_texture: bool = False
    paper_texture_params: Dict[str, Any] = None

    # --- Styling (major/minor colors, widths, etc.) ---
    theme: Optional[str] = None
    styling_params: Dict[str, Any] = None

    # ------------------------------------------------------------------
    # 1) FACTORY: BUILD FROM PRESET NAME
    # ------------------------------------------------------------------
    @staticmethod
    def from_preset(name: str) -> "GridEffectsPipeline":
        """
        Create a pre-tuned pipeline for a named aesthetic.
        """

        name = name.lower().strip()

        # Notebook-style, hand-drawn look
        if name == "handdrawn_notebook":
            return GridEffectsPipeline(
                distortion_field=SinusoidalDistortionField(
                    amplitude=0.35,
                    min_freq=0.01,
                    max_freq=0.05,
                    n_modes=6,
                    seed=42,
                ),
                distortion_strength=1.0,
                endpoint_offset=0.14,
                pencil_width_major=(1.8, 0.55),
                pencil_width_minor=(0.9, 0.55),
                paper_texture=True,
                paper_texture_params=dict(
                    shape=(1600, 1600),
                    seed=777,
                    base_color=(0.97, 0.97, 0.94),
                    max_deviation=0.04,
                    n_layers=3,
                ),
                theme=resolve_theme_from_preset("handwriting_synthetic"),
                styling_params=dict(
                    zorder=-1,
                    linewidth_major=1.8,
                    linewidth_minor=0.9,
                ),
            )

        # Technical / blueprint hybrid
        if name == "blueprint_technical":
            return GridEffectsPipeline(
                distortion_field=SinusoidalDistortionField(
                    amplitude=0.15,
                    min_freq=0.02,
                    max_freq=0.08,
                    n_modes=4,
                    seed=101,
                ),
                distortion_strength=0.7,
                endpoint_offset=0.04,
                pencil_width_major=(1.2, 0.2),
                pencil_width_minor=(0.6, 0.2),
                paper_texture=False,
                theme="blueprint",
                styling_params=dict(
                    zorder=-1,
                    linewidth_major=1.2,
                    linewidth_minor=0.6,
                ),
            )

        # "Perfect print" - subtle distortions only
        if name == "printlike":
            return GridEffectsPipeline(
                distortion_field=SinusoidalDistortionField(
                    amplitude=0.05,
                    min_freq=0.02,
                    max_freq=0.06,
                    n_modes=3,
                    seed=999,
                ),
                distortion_strength=0.5,
                endpoint_offset=0.02,
                pencil_width_major=(1.2, 0.05),
                pencil_width_minor=(0.6, 0.05),
                paper_texture=False,
                theme="printlike_subtle",
                styling_params=dict(
                    zorder=0,
                    linewidth_major=1.2,
                    linewidth_minor=0.6,
                ),
            )

        # Default simple aesthetic
        return GridEffectsPipeline(
            distortion_field=None,
            endpoint_offset=0.0,
            pencil_width_major=(1.4, 0.2),
            pencil_width_minor=(0.8, 0.2),
            paper_texture=False,
            theme="default",
            styling_params=dict(zorder=0),
        )

    # ------------------------------------------------------------------
    # 2) APPLY TO LINE COLLECTIONS (geometric effects)
    # ------------------------------------------------------------------
    def apply_to_collections(
        self,
        x_major: LineCollection,
        x_minor: LineCollection,
        y_major: LineCollection,
        y_minor: LineCollection,
    ) -> None:
        """Apply all enabled geometric effects to line collections."""

        families = [x_major, x_minor, y_major, y_minor]

        # 2.1 Warp field
        if self.distortion_field is not None:
            for lc in families:
                warp_line_collection(lc, self.distortion_field, self.distortion_strength)

        # 2.2 Endpoint wobble
        if self.endpoint_offset > 0:
            for lc in families:
                perturb_line_collection(lc, self.endpoint_offset)

        # 2.3 Pencil-style linewidth jitter
        if self.pencil_width_major:
            base, jitter = self.pencil_width_major
            for lc in (x_major, y_major):
                apply_pencil_linewidths(lc, base_width=base, jitter_fraction=jitter)

        if self.pencil_width_minor:
            base, jitter = self.pencil_width_minor
            for lc in (x_minor, y_minor):
                apply_pencil_linewidths(lc, base_width=base, jitter_fraction=jitter)

    # ------------------------------------------------------------------
    # 3) APPLY STYLING (colors, alpha, linewidths, zorder)
    # ------------------------------------------------------------------
    def apply_styling(
        self,
        x_major: LineCollection,
        x_minor: LineCollection,
        y_major: LineCollection,
        y_minor: LineCollection,
    ) -> None:
        """Apply major/minor styling according to the selected theme."""

        style = self.theme or "default"
        params = self.styling_params or {}

        apply_grid_style(
            x_major,
            x_minor,
            y_major,
            y_minor,
            style=style,
            **params,
        )

    # ------------------------------------------------------------------
    # 4) APPLY BACKGROUND
    # ------------------------------------------------------------------
    def apply_background(self, ax, bbox) -> None:
        """Draw paper texture on the axes behind other layers."""

        if not self.paper_texture:
            return

        params = self.paper_texture_params or {}
        tex = generate_paper_texture(**params)

        x0, y0, x1, y1 = bbox
        ax.imshow(
            tex,
            origin="lower",
            extent=(x0, x1, y0, y1),
            zorder=-10,
        )


def main():
    #from grid_effects_pipeline import GridEffectsPipeline
    
    # Step 1 - Generate grid (already available)

    # Create jitter config from preset
    preset_name = "sketchy"
    jitter = GridJitterConfig.preset(preset_name)

    bbox=(-10, -10, 10, 10)
    
    # Grid geometry
    obliquity_deg = 60.0
    rotation_deg = 20.0

    x_major_step = 3.0
    x_minor_step = 1.0
    y_major_step = 3.0
    y_minor_step = 1.0

    xM, xm, yM, ym = generate_grid_collections(
        bbox=bbox,
        obliquity_deg=obliquity_deg,
        rotation_deg=rotation_deg,
        x_major_step=x_major_step,
        x_minor_step=x_minor_step,
        y_major_step=y_major_step,
        y_minor_step=y_minor_step,
        jitter=jitter,
    )
    
    # Step 2 - Choose style pipeline
    effects = GridEffectsPipeline.from_preset("handdrawn_notebook")
    
    # Step 3 - Apply geometry effects
    effects.apply_to_collections(xM, xm, yM, ym)
    
    # Step 4 - Create figure, add background
    fig, ax = plt.subplots(figsize=(7, 7))
    effects.apply_background(ax, bbox)
    
    # Step 5 - Add styled grid
    effects.apply_styling(xM, xm, yM, ym)
    for lc in (xM, xm, yM, ym):
        ax.add_collection(lc)
    
    ax.set_aspect("equal")
    ax.set_xticks([])
    ax.set_yticks([])
    plt.show()
    


if __name__ == "__main__":
    main()
``` 
 
===== END mpl_grid_gen_pipeline.py ===== 
 
===== START mpl_grid_utils~.py ===== 
```python 
"""
mpl_grid_utils.py
-----------------

Utilities for generating flexible 2D grids with optional geometric distortion.

The generator produces four Matplotlib "LineCollection" objects corresponding
to the four standard sub-grids:

  - X-major lines  
  - X-minor lines  
  - Y-major lines  
  - Y-minor lines  

This layout generalizes the major/minor grid structure commonly found in
spreadsheet applications, plotting libraries, and diagramming tools, while
extending it to support **oblique (non-orthogonal)** and **rotated** grids.

In addition to deterministic grid construction, the module provides a set of
stochastic distortion mechanisms that can be applied independently to each
sub-grid:

  - **Angle jitter**
       Obliquity (inter-axis) angle  
       Global grid rotation angle  
       Individual line orientation

  - **Spacing jitter**
       Randomized offsets of major/minor line positions

  - **Line dropout**
       Random removal of individual grid lines

All distortion parameters are expressed in terms of bounded symmetric or
one-sided normal distributions.  Each parameter "K" defines both a
3-sigma range and a hard cutoff, following one of the two patterns:

  - Symmetric jitter:
        "K * normal(0, 1/3)" clipped to "[-K, +K]"

  - One-sided jitter (fractions, dropout rates):
        "K * abs(normal(0, 1/3))" clipped to "[0, K]"

These conventions ensure stable, statistically well-behaved distortions while
preserving intuitive user-controlled bounds on all grid perturbations.

________________________________________________________________________________________

https://chatgpt.com/c/69120de6-5468-832d-8bff-88120cb94daa

LLM Code Generation PROMPT
--------------------------

Let's work on a flexible Matplotlib grid generator utility.
Output:
    Four line collections - x_major_lc, x_minor_lc, y_major_lc, y_minor_lc
The arguments:
- bounding box (bottom-left and top-tight coners)
- grid angle (alpha=90 - for ordinary Cartesian coords, 90>alpha>0 for generic grids
- theta in [0, 90) - rotation of the grid in CCW
- x_major, x_minor, y_major, y_minor - respective sub-grid spacings

I want to be able to jitter both alpha and theta symmetrically (normal distribution
with 3sigma = 5 deg). Further, I want to jitter shift of individual lines symmetrically
about exact positions with 3sigma = 0.4*step (minor for minor lines and major for major
lines.) I also want to jitter angles of individual lines symmetrically with
3sigma = 3 deg. Not all lines should be affected by jitter however. I want select
a random fraction for each of the four types (selected fraction normally distributed
with mu=0% and sigma=25%). I also want to randomly drop a fraction (mu=0%, sigma=5%)
lines for each group.
________________________________________________________________________________________
"""

from __future__ import annotations

__all__ = ["GridJitterConfig", "generate_grid_collections",]

import os
import sys
import math
from numbers import Integral, Real
from dataclasses import dataclass
from typing import Optional, Union

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
from numpy.typing import NDArray

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.sep.join(os.path.abspath(__file__).split(os.sep)[:-2]))
from utils.rng import RNGBackend, RNG, get_rng

BBoxBounds = Union[
    tuple[Real, Real, Real, Real,],
    tuple[tuple[Real, Real], tuple[Real, Real],],
]


# ---------------------------------------------------------------------------
# Key grid distortion parameters
# ---------------------------------------------------------------------------
@dataclass
class GridJitterConfig:
    """Configuration for grid-level and line-level jitter.

    Attributes:
        global_angle_deg:     3sigma for global jitter of (alpha, theta), degrees.
        line_angle_deg:       3sigma for per-line angle jitter, degrees.
        line_offset_factor:   3sigma for per-line offset jitter as a fraction of
                                  the corresponding grid spacing (major/minor).
        line_offset_fraction: 3sigma for the fraction of lines that receive per-line
                                  jitter in each group (x_major, x_minor, y_major, y_minor).
        drop_fraction:        3sigma for the fraction of lines randomly dropped in each group.
    """
    global_angle_deg:     float = 6
    line_angle_deg:       float = 3
    line_offset_factor:   float = 0.4
    line_offset_fraction: float = 0.25
    drop_fraction:        float = 0.05


def generate_grid_collections(
        bbox      : BBoxBounds,
        alpha_deg : float,
        theta_deg : float,
        x_major   : float,
        x_minor   : float,
        y_major   : float,
        y_minor   : float,
        jitter    : GridJitterConfig = None,
        rng       : RNGBackend       = None,
    ) -> tuple[LineCollection, LineCollection, LineCollection, LineCollection]:
    """Generate 4 LineCollections for an oblique, optionally jittered grid.

    Args:
        bbox:
            Bounding box as ((x_min, y_min), (x_max, y_max)) in world coordinates.
        alpha_deg:
            Grid skew angle between x- and y-families in degrees.
            alpha_deg = 90 => ordinary Cartesian (orthogonal) grid.
            0 < alpha_deg <= 90 for generic oblique grids.
        theta_deg:
            Rotation of the x-family axis in degrees (CCW, world coordinates).
            The y-family axis is at theta_deg + alpha_deg.
        x_major:
            X major spacing (world-independent).
        x_minor:
            X minor spacing
        y_major:
            Y major spacing
        y_minor:
            Y minor spacing
        jitter:
            If provided, enables all jitter behavior controlled by GridJitterConfig.
            If None, the grid is perfectly regular (no jitter, no dropping).
        rng:
            Optional NumPy random Generator. If None, a custom thread-safe class RNG is used.

    Returns:
        (x_major_lc, x_minor_lc, y_major_lc, y_minor_lc)
        Each is a matplotlib.collections.LineCollection.
    """
    # --- RNG setup ---------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True, use_numpy=True)
    normal3s = getattr(
        rng, "normal3s",
        lambda: max(-1, min(1, float(rng.normalvariate(0, 1.0 / 3.0)))),
    )

    x_min, y_min, x_max, y_max = _parse_bbox(bbox)

    # ---------------------------------------------------------------------------
    # 1) Global angle jitter for alpha and theta
    # ---------------------------------------------------------------------------
    theta = math.radians(theta)
    alpha = math.radians(alpha)
    if jitter is not None and jitter.global_angle_deg > 0:
        theta += math.radians(jitter.global_angle_deg * normal3s())
        alpha += math.radians(jitter.global_angle_deg * normal3s())

    # Basis vectors for the oblique grid:
    # x-family coordinate axis (u) at angle theta
    # y-family coordinate axis (v) at angle theta + alpha
    ex = np.array([math.cos(theta), math.sin(theta)])        # x-axis direction
    ey = np.array([math.cos(theta + alpha), math.sin(theta + alpha)])  # y-axis

    # Linear map (u, v) -> (x, y) has columns ex, ey
    M = np.array([[ex[0], ey[0]], [ex[1], ey[1]]], dtype=float)
    Minv = np.linalg.inv(M)

    # ---------------------------------------------------------------------------
    # 2) Transform bbox corners -> (u, v) coord space to get ranges for lines
    # ---------------------------------------------------------------------------
    corners = np.array([
        [x_min, y_min],
        [x_max, y_min],
        [x_min, y_max],
        [x_max, y_max],
    ])
    uv_corners = corners @ Minv.T
    u_vals = uv_corners[:, 0]
    v_vals = uv_corners[:, 1]
    u_min, u_max = float(u_vals.min()), float(u_vals.max())
    v_min, v_max = float(v_vals.min()), float(v_vals.max())

    # ---------------------------------------------------------------------------
    # 3) Common jitter sigmas for per-line effects
    # ---------------------------------------------------------------------------
    if jitter is not None:
        line_angle_jitter_rad = math.radians(jitter.line_angle_deg)
    else:
        line_angle_jitter_rad = 0.0

    # ---------------------------------------------------------------------------
    # 4) Build each of the four line families
    #    - X-family lines: u = const, direction ~ ey
    #    - Y-family lines: v = const, direction ~ ex
    # ---------------------------------------------------------------------------
    bbox_tuple = (x_min, y_min, x_max, y_max)

    # X major
    x_major_segments = _build_line_family(
        coord_min=u_min,
        coord_max=u_max,
        step=x_major,
        fixed_vec=ex,
        dir_vec=ey,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=x_major,
        line_angle_jitter_rad=line_angle_jitter_rad,
    )

    # X minor
    x_minor_segments = _build_line_family(
        coord_min=u_min,
        coord_max=u_max,
        step=x_minor,
        fixed_vec=ex,
        dir_vec=ey,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=x_minor,
        line_angle_jitter_rad=line_angle_jitter_rad,
    )

    # Y major
    y_major_segments = _build_line_family(
        coord_min=v_min,
        coord_max=v_max,
        step=y_major,
        fixed_vec=ey,
        dir_vec=ex,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=y_major,
        line_angle_jitter_rad=line_angle_jitter_rad,
    )

    # Y minor
    y_minor_segments = _build_line_family(
        coord_min=v_min,
        coord_max=v_max,
        step=y_minor,
        fixed_vec=ey,
        dir_vec=ex,
        bbox=bbox_tuple,
        rng=rng,
        jitter=jitter,
        base_offset_step=y_minor,
        line_angle_jitter_rad=line_angle_jitter_rad,
    )

    # ---------------------------------------------------------------------------
    # 5) Wrap in LineCollections
    # ---------------------------------------------------------------------------
    x_major_lc = LineCollection(x_major_segments)
    x_minor_lc = LineCollection(x_minor_segments)
    y_major_lc = LineCollection(y_major_segments)
    y_minor_lc = LineCollection(y_minor_segments)

    return x_major_lc, x_minor_lc, y_major_lc, y_minor_lc


# =============================================================================
# Internals
# =============================================================================

def _parse_bbox(bbox: BBox) -> BBoxBounds:
    """Normalize bbox to (x_min, y_min, x_max, y_max)."""
    if len(bbox) == 2 and isinstance(bbox[0], (tuple, list)):
        (x0, y0), (x1, y1) = bbox  # type: ignore[misc]
    elif len(bbox) == 4:
        x0, y0, x1, y1 = bbox  # type: ignore[misc]
    else:
        raise ValueError("bbox must be ((x_min, y_min), (x_max, y_max)) or (x0, y0, x1, y1)")

    x_min = float(min(x0, x1))
    x_max = float(max(x0, x1))
    y_min = float(min(y0, y1))
    y_max = float(max(y0, y1))
    return x_min, y_min, x_max, y_max


def _sample_fraction(rng: RNGBackend, sigma: float) -> float:
    """Sample a [0, 1] fraction from |N(0, sigma)|, clipped."""
    if sigma <= 0:
        return 0.0
    val = abs(rng.normal(0.0, sigma))
    return float(np.clip(val, 0.0, 1.0))


def _build_line_family(coord_min: float, coord_max: float, step: float,
                       fixed_vec: NDArray, dir_vec: NDArray, bbox: BBoxBounds,
                       rng: RNGBackend, jitter: GridJitterConfig,
                       base_offset_step: float, line_angle_jitter_rad: float,) -> NDArray:
    """Generate clipped line segments for one family (major/minor X or Y).

    Args:
        coord_min: Minimum coordinate (u or v) over bbox corners.
        coord_max: Maximum coordinate (u or v) over bbox corners.
        step:      Spacing for this family (major or minor) along its coordinate.
        fixed_vec: Unit vector along which the fixed coordinate is applied
            (ex for X-family, ey for Y-family).
        dir_vec:   Nominal direction vector of the lines (ey for X-family,
            ex for Y-family).
        bbox:      (x_min, y_min, x_max, y_max) in world coords.
        rng:       NumPy RNG.
        jitter:   Jitter configuration or None.
        base_offset_step:     The step size used to scale the offset jitter.
        line_angle_jitter_rad: sigma for per-line angle jitter in radians.

    Returns:
        segments: ndarray of shape (n_lines, 2, 2).
    """
    x_min, y_min, x_max, y_max = bbox

    if step <= 0:
        return np.empty((0, 2, 2), dtype=float)

    # Determine index range in coordinate space that covers the bbox, with a small
    # margin to avoid missing lines due to rounding.
    k_min = int(math.floor(coord_min / step)) - 1
    k_max = int(math.ceil(coord_max / step)) + 1
    if k_max < k_min:
        return np.empty((0, 2, 2), dtype=float)

    coord_values = np.arange(k_min, k_max + 1, dtype=float) * step
    n = coord_values.size
    if n == 0:
        return np.empty((0, 2, 2), dtype=float)

    indices = np.arange(n)

    # ---------------------------------------------------------------------------
    # Per-group jitter/drop fractions (independent for each of the 4 families)
    # ---------------------------------------------------------------------------
    if jitter is not None:
        jitter_frac = _sample_fraction(rng, jitter.line_offset_fraction)
        drop_frac = _sample_fraction(rng, jitter.drop_fraction)
        offset_sigma = (jitter.line_offset_factor * base_offset_step) / 3.0
    else:
        jitter_frac = 0.0
        drop_frac = 0.0
        offset_sigma = 0.0

    # Which lines to drop?
    keep_mask = np.ones(n, dtype=bool)
    if drop_frac > 0:
        n_drop = int(round(drop_frac * n))
        n_drop = min(max(n_drop, 0), n)
        if n_drop > 0:
            drop_idx = rng.choice(indices, size=n_drop, replace=False)
            keep_mask[drop_idx] = False

    # Which remaining lines get jitter?
    jitter_mask = np.zeros(n, dtype=bool)
    if jitter_frac > 0 and keep_mask.any():
        n_keep = int(keep_mask.sum())
        n_jitter = int(round(jitter_frac * n_keep))
        n_jitter = min(max(n_jitter, 0), n_keep)
        if n_jitter > 0:
            candidate_idx = indices[keep_mask]
            chosen = rng.choice(candidate_idx, size=n_jitter, replace=False)
            jitter_mask[chosen] = True

    # ---------------------------------------------------------------------------
    # Build segments
    # ---------------------------------------------------------------------------
    base_phi = math.atan2(dir_vec[1], dir_vec[0])
    segments = []

    for i, c0 in enumerate(coord_values):
        if not keep_mask[i]:
            continue

        # Base coordinate (offset) and angle
        c = c0
        phi = base_phi

        if jitter is not None and jitter_mask[i]:
            if offset_sigma > 0:
                c += rng.normal(0.0, offset_sigma)
            if line_angle_jitter_rad > 0:
                phi += rng.normal(0.0, line_angle_jitter_rad)

        # Line direction in world coordinates
        d = np.array([math.cos(phi), math.sin(phi)], dtype=float)
        # Base point displaced along fixed_vec at coordinate c
        p0 = c * fixed_vec

        seg = _clip_infinite_line_to_bbox(p0, d, x_min, y_min, x_max, y_max)
        if seg is not None:
            segments.append(seg)

    if not segments:
        return np.empty((0, 2, 2), dtype=float)

    return np.stack(segments, axis=0)


def _clip_infinite_line_to_bbox(p0: NDArray, d: NDArray,
                                x_min: float, y_min: float,
                                x_max: float, y_max: float) -> NDArray:
    """Clip an infinite line to an axis-aligned bbox.

    The line is p(t) = p0 + t * d.

    Returns:
        A (2, 2) array [[x1, y1], [x2, y2]] if it intersects the bbox with a segment,
        otherwise None.
    """
    x0, y0 = float(p0[0]), float(p0[1])
    dx, dy = float(d[0]), float(d[1])
    eps = 1e-12

    ts = []

    # Intersect with x = x_min and x = x_max
    if abs(dx) > eps:
        for xb in (x_min, x_max):
            t = (xb - x0) / dx
            y = y0 + t * dy
            if y_min - eps <= y <= y_max + eps:
                ts.append(t)

    # Intersect with y = y_min and y = y_max
    if abs(dy) > eps:
        for yb in (y_min, y_max):
            t = (yb - y0) / dy
            x = x0 + t * dx
            if x_min - eps <= x <= x_max + eps:
                ts.append(t)

    if len(ts) < 2:
        return None

    # Sort and take the extreme intersection points
    ts_sorted = sorted(ts)
    t1, t2 = ts_sorted[0], ts_sorted[-1]

    p1 = np.array([x0 + t1 * dx, y0 + t1 * dy], dtype=float)
    p2 = np.array([x0 + t2 * dx, y0 + t2 * dy], dtype=float)
    return np.stack([p1, p2], axis=0)


def main():
    """
    from mpl_grid_utils import (
        generate_grid_collections,
        GridJitterConfig,
    )
    """
    
    fig, ax = plt.subplots(figsize=(6, 6))
    
    bbox = ((-10.0, -10.0), (10.0, 10.0))
    
    x_major_lc, x_minor_lc, y_major_lc, y_minor_lc = generate_grid_collections(
        bbox=bbox,
        alpha_deg=90.0,      # orthogonal
        theta_deg=15.0,      # rotate grid 15deg CCW
        x_major=2.0,
        x_minor=0.5,
        y_major=2.0,
        y_minor=0.5,
        jitter=GridJitterConfig(),  # enable jitter with defaults
    )
    
    # Style the collections however you like
    x_major_lc.set_linewidth(1.2)
    x_major_lc.set_alpha(0.7)
    
    x_minor_lc.set_linewidth(0.6)
    x_minor_lc.set_alpha(0.4)
    
    y_major_lc.set_linewidth(1.2)
    y_major_lc.set_alpha(0.7)
    
    y_minor_lc.set_linewidth(0.6)
    y_minor_lc.set_alpha(0.4)
    
    ax.add_collection(x_major_lc)
    ax.add_collection(x_minor_lc)
    ax.add_collection(y_major_lc)
    ax.add_collection(y_minor_lc)
    
    ax.set_xlim(-10, 10)
    ax.set_ylim(-10, 10)
    ax.set_aspect("equal", adjustable="box")
    
    plt.show()
    
    
if __name__ == "__main__":
    main()
``` 
 
===== END mpl_grid_utils~.py ===== 
 
===== START mpl_path_utils.py ===== 
```python 
"""
mpl_path_utils.py
-----------

The primary focus of this module is generation of random Paths of geometric
primitives, such as lines, circles/ellipses, circular/elliptical arcs, triangles,
squares/recatngles, and tabulated functions.

The core generation workflow is performed in stages:
 1. Generation of a random Path of basic shapes:
      - line segment,
      - unit circle and arc,
      - square,
      - arbitrary triangle.
      - arbitrary tabulated functions {(x, y) or (x, y, y')}.
    Circular arc is part of the unit circle, while line segments, triangles, and
    squares are inscribed into the unit circle. This convention, paired with polar
    coordinates enables convinient workflow for randomization of shape during this
    stage essentially independent of size, orientation, and position (randomized in
    subsequent stages).
    
    Particularly convinient are polar coordinates, which provide an expressive full
    control over the shape of triangles. Generation of elliptical and general
    rectangular shaoes is unnecessary at this stage, as the full spectrum of
    elliptical and rectangular shapes is generated from circular and square shapes
    via anisotropic scaling (using separate scaling factors for Cartesian X and Y)
    during the random SRT transform. Because SRT transform is responsible for
    randomizing size/scale, no need to worry about size randomization at this stage
    either, that is only polar angles of vertices on the unit cicle are randomized,
    but not circle radius.
    
    This stage also introduces jitter on initial angaular coordinates and then
    Cartesian XY coordinates, after coordinate switching. Jitter distorts idealized
    shapes (circles, regular polygons, right angles, specific triangle subtypes),
    imitating realistic non-idealized rendering.

    Because circles are rendered as piecewise cubic Bezier splines, jittering
    cordinates introduces distortions to arc segments, imitating non-idealized hand
    drawing.

    For other primitives, which are essentially straight segment polylines, hand
    drawing imitation is peformed in a separate stage.

 2. Hand drawing imitation.
    The second stage focuses on distorting idealized straight line segments forming
    polyine primitives (line segments and polygons). Each straight segment is split
    into a configurable number of subsegments of randomized length. Each subsegment
    is replaced with Matplotlib cubic Bezier segment, slightly and randomly
    deviating from a straight line.

    Tabulated functions Paths are not subjected to this process.

 3. Random Scale->Rotate->Translate (SRT) transform. This stage randomizes the size,
    orientation, and position of Paths from prior stages. For cicles, arcs, and
    squares, independent (anisotropic) XY scaling generates the full spectrum of
    rectangles and elliprical shapes.

Separate processes are used for genration of randomized
 - line rendering style (linewidth, linestyle, and color);
 - background color;
 - idealized or randomly distorted grid.

Note, grid is generated as four LineCollection objects (X and Y - major and minor),
added to the Matplotlib plot via corresponding four drawing calls. Paths are wrapped
in Patch objects with generated styles. Use of PatchCollection is generally unnecessary
here, as the main objective is generating scenes with small number of independently
styled shapes. While PathCollection probably provides sufficient flaxibility for this
purpose, its use would complicate the code, while typically not providing considerable
performance benefit.

Core API:

    join_paths(paths: list[mplPath], preserve_moveto: bool = False) -> mplPath

        Joins muptiple paths into a single continous or disjoint matplotlib.path.Path
        object.
    
    
    random_srt_path(shape: mplPath, canvas_x1x2: PointXY, canvas_y1y2: PointXY,
                    y_compress: float = None, angle_deg: numeric = None,
                    origin: PointXY = None, rng: RNGBackend = None) -> tuple[mplPath, dict]

        Applies a random Scale->Rotate->Translate (SRT) transform to given Path within
        the specified canvas. the primary use is to transform a random Path defined on
        the unit box ([-1, 1]) to a rnadom Path within the specified canvas. Scaling is
        defined assymetrically. Isotropic scaling within the ratio of the sizes of the
        original bounding box and canvas is performed isotropically (XY). y_compress
        defines additional compression of the y coordinate, turning circles, circular
        arcs, and squares into elliptical and rectangular shapes.

        Note: presently this routine does not work correctly resulting in shapes going
        partially or even fully off the canvas. See the notes in the routine's docstring.
    
    
    unit_circle_diameter(base_angle: numeric = None,
                         jitter_angle_deg: int = JITTER_ANGLE_DEG,
                         rng: RNGBackend = None) -> tuple[mplPath, dict]

        Generates a randomly oriented unit circle diamter (line segment).
    
    
    unit_circular_arc(start_deg: float = 0.0, end_deg: float = 90.0,
                      jitter_amp: float = 0.02, jitter_y: float = 0.1,
                      max_angle_step_deg: float = 20.0, min_angle_steps: int = 3,
                      rng: RNGBackend = None) -> mplPath

        Generates a Path representation of a unit circular arc modeled as a chain of
        cubic Bezier splines. The routine optionally introduces angular jitter on angular
        cordinates, aspect ration (distorting the circle), line shape, imitating hand
        drawing.

    
    unit_rectangle_path(equal_sides: int = None, jitter_angle_deg: int = 5,
                        base_angle: int = None, rng: RNGBackend = None) -> mplPath

        Generates a Path representation of a rectangle inscribed into a unit circle.


    unit_triangle_path(equal_sides: int = None, angle_category: int = None,
                       jitter_angle_deg: int = 5, base_angle: int = None,
                       rng: RNGBackend = None) -> tuple[mplPath, dict]

        Generates a Path representation of a triangle inscribed into a unit circle.

    
    random_cubic_spline_segment(start: PointXY, end: PointXY, amp: float = 0.15,
                                tightness: float = 0.3, rng: RNGBackend = None) -> mplPath

        Transforms a single straight line segment into a single randomized cubic Bezier
        segment, imitating hand drawing. Suitable for short segments.
            
    
    handdrawn_polyline_path(points: list[PointXY], splines_per_segment: int = 5,
                            amp: float = 0.15, tightness: float = 0.3,
                            rng: RNGBackend = None) -> mplPath

        Given open or closed polyline Path, creates a new Path that imitates hand
        drawn style by replacing each straight segment with configurable number of
        Bezier sections.

    
    bezier_from_xy_dy(x: NDarray, y: NDarray, dy: NDarray = None, tension: float = 0.0,
                      endpoint_style: str = "default") -> mplPath
    
        Creates a Path containing piecewise spline representation of a tabulated
        function.

    
    unit_circular_arc_segment(start_deg: float = 0.0, end_deg: float = 90.0) -> mplPath
    
        Creates a single Bezier segment approximation of an acute circular arc.
    
    
    basic_ellipse_or_arc_path(x0: float, y0: float, r: float, y_compress: float = 1.0,
                              start_angle: float = 0.0, end_angle: float = 360.0,
                              angle_offset: float = 0.0, close: bool = False) -> mplPath:

        This routine creates basic primitives using Matplotlib Circle, Ellipse, and Arc
        patches. For these patches, Matplotlib internally creates an associated path
        that is extracted after the appropriate patch object is created. The primary
        purpose of this routine is satisfy potential needs of testing or basic demos.
        Flexible generation of primary elliptical arcs objects is performed via separate
        routines.
"""

from __future__ import annotations

"""
__all__ = [
    "join_paths", "ellipse_or_arc_path",
    "JITTER_ANGLE_DEG",
]
"""

import os
import sys
import time
import random
import numbers
from numbers import Integral, Real
import math
from typing import TypeAlias, Union
import numpy as np
from numpy.typing import NDArray

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.sep.join(os.path.abspath(__file__).split(os.sep)[:-2]))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.patches import PathPatch, Circle, Ellipse, Arc
from matplotlib.path import Path as mplPath
from matplotlib.transforms import Affine2D, Bbox

from mpl_utils import *
from utils.rng import RNGBackend, RNG, get_rng

PointXY: TypeAlias = tuple[Real, Real]
CoordRange: TypeAlias = tuple[Real, Real]

JITTER_ANGLE_DEG = 5


# ---------------------------------------------------------------------------
# Path joining utility
# ---------------------------------------------------------------------------
def join_paths(
        paths           : list[mplPath],
        preserve_moveto : bool           = False,
    ) -> mplPath:
    """Join multiple Matplotlib ``Path`` objects into a single composite path.
    
    Args:
        paths (list[matplotlib.path.Path]):
            Input list of path objects to join.
        preserve_moveto (bool, optional):
            Whether to keep the initial ``MOVETO`` command for each path.
            If ``False`` (default), subsequent paths are joined seamlessly
            into one continuous path.
    
    Returns:
        matplotlib.path.Path:
            The concatenated composite path.
    
    Raises:
        ValueError: If ``paths`` is empty.
        TypeError: If any element of ``paths`` is not a ``Path`` instance.
    """
    if not paths:
        raise ValueError("Expected a non-empty list of Matplotlib paths.")

    for path in paths:
        if not isinstance(path, mplPath):
            raise TypeError(f"Expected a list of Matplotlib paths, got {type(path).__name__}.")

    verts_list, codes_list = [paths[0].vertices], [paths[0].codes]

    start = 0 if preserve_moveto else 1
    for path in paths[1:]:
        if path.vertices.size == 0:
            continue
        verts_list.append(path.vertices[start:])
        codes_list.append(path.codes[start:])

    return mplPath(np.concatenate(verts_list), np.concatenate(codes_list))


# ---------------------------------------------------------------------------
# Computes Path bounding box
# ---------------------------------------------------------------------------
def bbox_from_path(path: Path) -> NDarray:
    """Computes Path bounding box"""
    verts = np.asarray(path.vertices, dtype=float)
    verts = verts[np.isfinite(verts).all(axis=1)]
    if verts.size == 0:
        return np.array([[0,0],[0,0]])
    min_xy = verts.min(axis=0)
    max_xy = verts.max(axis=0)
    return np.stack((min_xy, max_xy))


# ---------------------------------------------------------------------------
# Applies random SRT transform to Path.
# ---------------------------------------------------------------------------
def random_srt_path(
        shape            : mplPath,
        canvas_x1x2      : PointXY,
        canvas_y1y2      : PointXY,
        y_compress       : float      = None,
        angle_deg        : Real       = None,
        jitter_angle_deg : int        = JITTER_ANGLE_DEG,
        origin           : PointXY    = None,
        rng              : RNGBackend = None,
    ) -> tuple[mplPath, dict]:
    """Apply a random Scale-Rotate-Translate (SRT) transform to a Path so it fits
    inside a given canvas box with some jitter.

    The shape is:
        1) scaled uniformly in X and Y, plus by `y_compress` in Y,
        2) rotated around `origin` (default: path bbox center),
        3) translated into the canvas with small random offsets.

    The scaling process aims for the final shape to be within 0.1x to 0.9x fraction
    of the smaller canvas dimension. However, at high extreme ends (combined with
    translation and rotation), part of the Path may ocassionaly extend beyond the
    canvas, also ocasionally failing the associated test.

    Args:
        shape:
            Input Matplotlib Path.
        canvas_x1x2:
            (xmin, xmax) of the target canvas.
        canvas_y1y2:
            (ymin, ymax) of the target canvas.
        y_compress:
            Optional vertical compression factor. If None, sampled in [0.5, 1.0].
        angle_deg:
            Base rotation in degrees. If None, sampled uniformly in [0, 360).
            If non-zero, a small +/-JITTER_ANGLE_DEG jitter is added.
            Note, for non-zero angle, the value is rounded. To have jitter with
            0 deg, set it to abs() < 0.5 deg, such as 0.1.
        jitter_angle_deg: Angular jitter amplitude in degrees.
            Controls small random deviations around the base angle.
        origin:
            Optional rotation center (x, y) in path coordinates. If None, uses
            the path bounding-box center.
        rng:
            Optional RNG backend. If None, uses get_rng(thread_safe=True).

    Returns:
        (new_path, meta) where:
            new_path: transformed Path
            meta: dict with scale, rotation, and translation parameters.
    """    
    # --- Validation --------------------------------------------------------
    if not isinstance(shape, mplPath):
        raise TypeError(f"Expected mplPath, got {type(shape).__name__}")
    if not (isinstance(canvas_x1x2, tuple) and isinstance(canvas_y1y2, tuple)):
        raise TypeError("canvas_x1x2 and canvas_y1y2 must be tuples of floats")
    if not origin is None and not isinstance(origin, tuple):
        raise TypeError(f"origin must be tuples of floats, not '{type(origin).__name__}'")

    # --- RNG ---------------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(
        rng, "normal3s",
        lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))),
    )

    # --- Canvas geometry ---------------------------------------------------
    cxmin, cxmax = map(float, canvas_x1x2)
    cymin, cymax = map(float, canvas_y1y2)
    cw, ch = cxmax - cxmin, cymax - cymin
    if cw <= 0 or ch <= 0:
        raise ValueError(f"Invalid canvas size: ({cw}, {ch})")
    cx0, cy0 = (cxmin + cxmax) / 2, (cymin + cymax) / 2

    # --- Path bounding box -------------------------------------------------
    (bmin, bmax) = bbox_from_path(shape)
    bxmin, bymin = bmin
    bxmax, bymax = bmax
    bw, bh = bxmax - bxmin, bymax - bymin
    bx0, by0 = (bxmax + bxmin) / 2, (bymax + bymin) / 2
    if bw == 0 or bh == 0:
        bw = bh = 1e-6

    # --- Randomized parameters --------------------------------------------
    if not isinstance(y_compress, Real):
        y_compress = rng.uniform(0.2, 1.0)
    y_compress = max(0.1, y_compress)

    if not isinstance(angle_deg, Real):
        angle_deg = rng.uniform(-180, 180)
    else:
        angle_deg += jitter_angle_deg * normal3s()
    angle_deg = ((angle_deg + 180) % 360) - 180
    angle_rad = math.radians(angle_deg)

    # --- Compute rotated bbox footprint (unscaled) ------------------------
    corners = np.array([
        [bxmin, bymin],
        [bxmax, bymin],
        [bxmax, bymax],
        [bxmin, bymax],
    ])
    pivot = np.array(origin or (bx0, by0))

    # Rotate corners about pivot (no scale yet)
    rot_corners = (
        Affine2D()
        .rotate_around(pivot[0], pivot[1], angle_rad)
        .transform(corners)
    )

    # --- Compute maximum scale to fit in canvas ---------------------------
    rxmin, rymin = rot_corners.min(axis=0)
    rxmax, rymax = rot_corners.max(axis=0)
    rw, rh = rxmax - rxmin, rymax - rymin

    margin_frac = 0.05
    margin_x = cw * margin_frac
    margin_y = ch * margin_frac
    cw_eff = cw - 2 * margin_x
    ch_eff = ch - 2 * margin_y
    max_scale = min(cw_eff / max(rw, 1e-12), ch_eff / max(rh, 1e-12))

    sfx = rng.uniform(0.2, 0.9) * max_scale
    sfy = sfx * y_compress

    # --- Apply Scale+Rotate ONLY (no translation yet) ---------------------------
    if origin is None:
        origin = (bx0, by0)
    
    sr = (
        Affine2D()
        .scale(sfx, sfy)
        .rotate_around(origin[0], origin[1], angle_rad)
    )
    sr_verts = sr.transform(shape.vertices)
    
    # --- Get SR bbox directly from transformed vertices -------------------------
    xmin = float(np.min(sr_verts[:, 0]))
    xmax = float(np.max(sr_verts[:, 0]))
    ymin = float(np.min(sr_verts[:, 1]))
    ymax = float(np.max(sr_verts[:, 1]))
    
    sr_w = max(1e-12, xmax - xmin)
    sr_h = max(1e-12, ymax - ymin)
    sr_cx = 0.5 * (xmin + xmax)
    sr_cy = 0.5 * (ymin + ymax)
    
    # --- Compute allowed target-center region inside canvas ---------------------
    # If you want a small visual margin, set margin_frac > 0.0 (e.g. 0.05)
    margin_frac = 0.05
    cxmin_eff = cxmin + margin_frac * (cxmax - cxmin)
    cxmax_eff = cxmax - margin_frac * (cxmax - cxmin)
    cymin_eff = cymin + margin_frac * (cymax - cymin)
    cymax_eff = cymax - margin_frac * (cymax - cymin)
    
    # Target center must leave half-bbox on each side within effective canvas
    tgt_cx_min = cxmin_eff + 0.5 * sr_w
    tgt_cx_max = cxmax_eff - 0.5 * sr_w
    tgt_cy_min = cymin_eff + 0.5 * sr_h
    tgt_cy_max = cymax_eff - 0.5 * sr_h
    
    # Handle degenerate cases where numeric tolerances collapse the range
    if tgt_cx_max < tgt_cx_min:
        tgt_cx_min = tgt_cx_max = 0.5 * (cxmin_eff + cxmax_eff)
    if tgt_cy_max < tgt_cy_min:
        tgt_cy_min = tgt_cy_max = 0.5 * (cymin_eff + cymax_eff)
    
    # Sample a feasible target center (optionally add small jitter if you like)
    target_cx = rng.uniform(tgt_cx_min, tgt_cx_max)
    target_cy = rng.uniform(tgt_cy_min, tgt_cy_max)
    
    # --- Translation that exactly places SR center to target center -------------
    tx = target_cx - sr_cx
    ty = target_cy - sr_cy
    
    # --- Final verts = (S+R) + T ------------------------------------------------
    final_verts = sr_verts + np.array([tx, ty])
    shape_srt = mplPath(final_verts, shape.codes)
    
    # (Optional) if you want to assert hard containment (debug safety):
    assert cxmin <= final_verts[:,0].min() + 1e-9
    assert final_verts[:,0].max() <= cxmax + 1e-9
    assert cymin <= final_verts[:,1].min() + 1e-9
    assert final_verts[:,1].max() <= cymax + 1e-9
    
    # --- 6) Build result + meta -------------------------------------------------
    meta = {
        "operation": "SRT",
        "scale_x": sfx,
        "scale_y": sfy,
        "rot_x": origin[0],
        "rot_y": origin[1],
        "rot_deg": angle_deg,
        "trans_x": tx,
        "trans_y": ty,
    }

    return shape_srt, meta


# ---------------------------------------------------------------------------
# Random unit circle diameter (straight line segment)
# ---------------------------------------------------------------------------
def unit_circle_diameter(
            base_angle       : Real       = None,
            jitter_angle_deg : int        = JITTER_ANGLE_DEG,
            rng              : RNGBackend = None,
        ) -> tuple[mplPath, dict]:
    """Generates a diameter (straight line) within a unit circle.

    The line passes through the circle center (0, 0) and connects opposite
    points on the unit circle at a given or random orientation.

    Args:
        base_angle: Optional base orientation angle in degrees.
            If None, randomly sampled from [-90, 90].
        jitter_angle_deg: Angular jitter amplitude in degrees.
            Controls small random deviations around the base angle.
        rng: Optional RNG backend (RNG, random.Random, or np.random.Generator).
            If None, uses `get_rng(thread_safe=True)`.

    Returns:
        tuple[mplPath, dict]:
            - Path: Matplotlib path representing the circle diameter.
            - dict: Metadata including the final angle in degrees.
    """
    # --- RNG ----------------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(rng, "normal3s",
                   lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))))

    # --- Determine base angle and jitter -----------------------------------
    if base_angle is None:
        base_angle = rng.uniform(-90, 90)
    elif not isinstance(base_angle, Real):
        raise TypeError(
            f"angle_deg must be of type integer or float.\n"
            f"Received type: {type(base_angle).__name__}; value: {base_angle}."
        )

    # Use RNG for normal jitter to stay consistent with other random primitives
    jitter = normal3s() * jitter_angle_deg
    angle_deg = ((base_angle + jitter + 90) % 180) - 90
    angle_rad = math.radians(angle_deg)

    # --- Compute endpoints on unit circle ----------------------------------
    x1, y1 = math.cos(angle_rad), math.sin(angle_rad)
    x2, y2 = -x1, -y1  # opposite side

    # --- Build Path ---------------------------------------------------------
    verts = [(x1, y1), (x2, y2)]
    codes = [mplPath.MOVETO, mplPath.LINETO]
    path = mplPath(verts, codes)

    meta: dict = {
        "shape_kind" : "line",
        "angle_deg"  : angle_deg,
    }

    return path, meta


# ---------------------------------------------------------------------------
# Random unit circular arc
# ---------------------------------------------------------------------------
def unit_circular_arc(
        start_deg          : float      = 0.0,
        end_deg            : float      = 90.0,
        jitter_amp         : float      = 0.02,
        jitter_y           : float      = 0.1,
        max_angle_step_deg : float      = 20.0,
        min_angle_steps    : int        = 3,
        rng                : RNGBackend = None,
    ) -> mplPath:
    """Generate a unit circular arc as a multi-segment cubic Bezier path.

    Each sub-arc spans <= `max_angle_step_deg` (default 20deg) and uses the
    analytic 4/3*tan(Dtheta/4) handle length for optimum circular curvature.
    Additive and multiplicative jitter simulate hand-drawn irregularities.

    Note: Uses vectorized random function - requires NumPy backend.

    Args:
        start_deg: Starting angle in degrees.
        end_deg: Ending angle in degrees.
        jitter_amp: Additive jitter amplitude (fraction of radius).
        jitter_y: Multiplicative jitter (vertical squish).
        max_angle_step_deg: Maximum sub-arc span (degrees).
        min_angle_steps: Minimum number of Bezier segments.
        rng: Optional RNG backend (`RNG`, `random.Random`, or `np.random.Generator`).

    Returns:
        tuple:
            matplotlib.path.Path - Bezier path approximating the arc.
            dict - Metadata about span, closure, and parameters.
    """
    # --- RNG setup -----------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(rng, "normal3s",
                   lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))))

    # --- Angle normalization -------------------------------------------------
    if start_deg is None or end_deg is None:
        start_deg = rng.uniform(0, 360 - JITTER_ANGLE_DEG * 3)
        end_deg = rng.uniform(start_deg + JITTER_ANGLE_DEG, 360)
    span_deg = end_deg - start_deg

    if span_deg < 1 or span_deg > 359:
        start_deg, end_deg, span_deg = 0, 360, 360
        closed = True
    else:
        closed = False

    # --- Segmentation -------------------------------------------------------
    theta_steps = int(max(min_angle_steps, round(span_deg / max_angle_step_deg)))
    start, end = math.radians(start_deg), math.radians(end_deg)
    span = end - start
    step_theta = span / theta_steps
    t = 4.0 / 3.0 * math.tan(step_theta / 4.0)

   # --- Vertex generation --------------------------------------------------
    P0 = (math.cos(start), math.sin(start))
    verts: list[PointXY] = [P0]
    theta_beg = start
    for _ in range(theta_steps):
        theta_end = theta_beg + step_theta
        cos_b, sin_b = math.cos(theta_beg), math.sin(theta_beg)
        cos_e, sin_e = math.cos(theta_end), math.sin(theta_end)

        P1 = (cos_b - t * sin_b, sin_b + t * cos_b)
        P2 = (cos_e + t * sin_e, sin_e - t * cos_e)
        P3 = (cos_e, sin_e)

        verts.extend([P1, P2, P3])
        theta_beg = theta_end

    codes = [mplPath.MOVETO] + [mplPath.CURVE4] * 3 * theta_steps

    if closed:
        verts.append((np.nan, np.nan))
        codes.append(mplPath.CLOSEPOLY)

    verts = np.array(verts, dtype=float)

    # --- Y-axis multiplicative jitter ----------------------------------------
    if jitter_y:
        verts[:, 1] *= 1 - rng.uniform(0, 1) * jitter_y

    # --- Additive jitter -----------------------------------------------------
    if jitter_amp:
        verts += rng.uniform(-1, 1, size=verts.shape) * jitter_amp

    path = mplPath(verts, codes)

    meta: dict = {
        "shape_kind" : "circle",
        "start_deg"  : start_deg,
        "end_deg"    : end_deg,
    }
    return path, meta


# ---------------------------------------------------------------------------
# Random unit rectangle
# ---------------------------------------------------------------------------
def unit_rectangle_path(
        diagonal_angle   : Real       = None,
        jitter_angle_deg : int        = JITTER_ANGLE_DEG,
        base_angle       : int        = None,
        rng              : RNGBackend = None,
    ) -> mplPath:
    """Generates a rectangle or square inscribed in a unit circle.

    Args:
        diagonal_angle: Angle between digonals in degrees (90 for square and
                        0-180 for rectangle). Randomly chosen if None.
        jitter_angle_deg: Maximum angular deviation (degrees).
        base_angle: Base rotation of the figure (degrees).
        rng: Optional RNG backend (RNG, random.Random, np.random.Generator).

    Returns:
        Matplotlib Path representing the shape.
    """
    # --- RNG setup ---------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(rng, "normal3s",
                   lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))))

    # --- Shape type --------------------------------------------------------
    if not diagonal_angle is None and not isinstance(diagonal_angle, Real):
        raise TypeError(f"diagonal_angle must be numeric. "
                        f"Received {type(diagonal_angle)}")

    angle_margin = max(jitter_angle_deg, JITTER_ANGLE_DEG) * 2
    if diagonal_angle is None:
        # Using equal chances for square vs. irregular rectangle
        diagonal_angle = 90 + (
            rng.choice((-1, 0, 1, 0)) * rng.uniform(angle_margin, 90 - angle_margin)
        )
    diagonal_angle = max(angle_margin, min(180 - angle_margin, diagonal_angle))

    # --- Angular offsets ---------------------------------------------------

    top_right_angle = diagonal_angle / 2
    offset = top_right_angle - 45

    #  thetas = [
    #      45 + offset + base_angle + normal3s() * jitter_angle_deg,
    #     135 - offset + base_angle + normal3s() * jitter_angle_deg,
    #    -135 + offset + base_angle + normal3s() * jitter_angle_deg,
    #     -45 - offset + base_angle + normal3s() * jitter_angle_deg,
    #  ]

    if not isinstance(base_angle, Real):
        base_angle = rng.uniform(-90, 90)
    else:
        base_angle += normal3s() * jitter_angle_deg

    # --- Corner angles -----------------------------------------------------
    thetas = [
         0 + top_right_angle + base_angle + normal3s() * jitter_angle_deg,
       180 - top_right_angle + base_angle + normal3s() * jitter_angle_deg,
      -180 + top_right_angle + base_angle + normal3s() * jitter_angle_deg,
         0 - top_right_angle + base_angle + normal3s() * jitter_angle_deg,
    ]

    thetas = [math.radians(((theta + 180) % 360) - 180) for theta in thetas]

    # --- Vertices and Path -------------------------------------------------
    verts = [(math.cos(t), math.sin(t)) for t in thetas]
    verts.append(verts[0])  # close shape

    codes = [mplPath.MOVETO] + [mplPath.LINETO] * (len(verts) - 2) + [mplPath.CLOSEPOLY]

    meta: dict = {
        "shape_kind"     : "rectangle",
        "angle_deg"      : base_angle,
        "diagonal_angle" : diagonal_angle,
        "offset_deg"     : offset,
    }
    
    return mplPath(verts, codes), meta


# ---------------------------------------------------------------------------
# Random unit triangle
# ---------------------------------------------------------------------------
def unit_triangle_path(
        equal_sides      : int        = None,
        angle_category   : int        = None,
        jitter_angle_deg : int        = JITTER_ANGLE_DEG,
        base_angle       : int        = None,
        rng              : RNGBackend = None,
    ) -> tuple[mplPath, dict]:
    """Generates vertices of a triangle inscribed in a unit circle.

    Reference triangle:
        Base = [(-1, 0), (1, 0)], top = (0, 1).

    Geometry overview:
        - The top vertex is offset by +/-top_offset relative to the reference (0, 1),
          controlling symmetry (Isosceles vs. Scalene).
        - Base vertices are symmetrically offset by +/-base_offset relative to
          (+/-1, 0), defining angular classification and regularity.
        - These offsets define all triangle classes:
            - Isosceles : top_offset  = 0
            - Right     : base_offset = 0
            - Acute     : base_offset < 0
            - Obtuse    : base_offset > 0

    Args:
        equal_sides (int, optional): 1, 2, or 3.
            - 3 - Equilateral
            - 2 - Isosceles
            - 1 - Scalene
        angle_category (int, optional): Nominal angular class, compared to 90deg.
            <90 - Acute, =90 - Right, >90 - Obtuse
        jitter_angle_deg (int, optional): 3sigma angular jitter magnitude in degrees.
        base_angle (int, optional): Global rotation of the triangle in degrees.
        rng (RNGBackend, optional): Random number generator backend
            (`RNG`, `random.Random`, or `np.random.Generator`).

    Returns:
        tuple:
            - mplPath: Matplotlib Path representing the triangle.
            - dict: Metadata describing parameters and applied offsets.
    """
    # --- RNG setup ---------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(
        rng, "normal3s",
        lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))),
    )

    # --- Input validation --------------------------------------------------
    if not equal_sides:
        equal_sides = rng.choice((1, 2, 3))
    if equal_sides not in (1, 2, 3):
        raise ValueError(
            f"equal_sides must be an integer in [1, 3]. "
            f"Got {equal_sides!r}."
        )

    if not angle_category:
        angle_category = rng.choice((60, 90, 120))
    if not isinstance(angle_category, Real):
        raise TypeError(
            f"angle_category must be numeric. "
            f"Got {type(angle_category).__name__}."
        )

    # --- Base geometry -----------------------------------------------------
    if equal_sides == 3:
        # Equilateral triangle
        thetas = [90, -30, 210]
        top_offset = base_offset = 0.0
    else:
        top_offset = (
            0 if equal_sides > 1 else rng.choice([-1, 1])
            * rng.uniform(jitter_angle_deg, 90 - jitter_angle_deg)
        )
        base_offset = (
            ((angle_category > 90) - (angle_category < 90))
            * rng.uniform(jitter_angle_deg, 90 - jitter_angle_deg)
        )
        thetas = [90 + top_offset, 0 + base_offset, 180 - base_offset]

    # --- Jitter and rotation -----------------------------------------------
    thetas[0] += normal3s() * jitter_angle_deg

    if not isinstance(base_angle, Real):
        base_angle = rng.uniform(-90, 90)
    else:
        base_angle += normal3s() * jitter_angle_deg

    thetas = [(theta + base_angle) for theta in thetas]
    thetas = [math.radians(((theta + 180) % 360) - 180) for theta in thetas]

    # --- Path construction -------------------------------------------------
    verts = [(math.cos(theta), math.sin(theta)) for theta in thetas]
    verts.append(verts[0])
    codes = [mplPath.MOVETO, mplPath.LINETO, mplPath.LINETO, mplPath.CLOSEPOLY]

    meta = {
        "shape_kind"      : "triangle",
        "equal_sides"     : equal_sides,
        "angle_category"  : angle_category,
        "base_angle_deg"  : base_angle,
        "top_offset_deg"  : top_offset,
        "base_offset_deg" : base_offset,
    }

    return mplPath(verts, codes), meta


# ---------------------------------------------------------------------------
# Random cubic spline segment (hand-drawn imitation)
# ---------------------------------------------------------------------------
def random_cubic_spline_segment(
        start     : PointXY,
        end       : PointXY,
        amp       : float      = 0.15,
        tightness : float      = 0.3,
        rng       : RNGBackend = None,
    ) -> mplPath:
    """Generate a cubic spline Path segment imitating a hand-drawn line.

    The function creates a 4-point cubic Bezier curve between two points
    with randomized perpendicular deviation to simulate "hand-drawn" jitter.

    Args:
        start: Starting point (x0, y0).
        end: Ending point (x1, y1).
        amp: Amplitude of perpendicular deviation (typ. 0.1-0.3).
        tightness: Controls curvature bias toward endpoints (typ. 0.2-0.5).
        rng: Optional RNG backend (RNG, random.Random, or np.random.Generator).

    Returns:
        mplPath: A cubic Bezier Path with one MOVETO and three CURVE4 vertices.
    """
    # --- RNG ----------------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(rng, "normal3s",
                   lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))))

    if not (isinstance(start, tuple) and isinstance(end, tuple)):
        raise TypeError(
            f"start and end must be tuple[float, float]. "
            f"Received {type(start)} and {type(end)}."
        )
    if len(start) != 2 or len(end) != 2:
        raise ValueError("start and end tuples must each have exactly two elements.")

    x0, y0 = start
    x1, y1 = end
    dx = x1 - x0
    dy = y1 - y0

    # Generate two normal deviations, clipped to [-1, 1]
    dev1 = normal3s() * amp
    dev2 = normal3s() * amp

    # Define control points with small perpendicular offsets
    P0 = (x0, y0)
    P1 = (x0 + dx * tightness - dy * dev1, y0 + dy * tightness + dx * dev1)
    P2 = (x1 - dx * tightness - dy * dev2, y1 - dy * tightness + dx * dev2)
    P3 = (x1, y1)

    verts = [P0, P1, P2, P3]
    codes = [mplPath.MOVETO, mplPath.CURVE4, mplPath.CURVE4, mplPath.CURVE4]
    return mplPath(verts, codes)


# ---------------------------------------------------------------------------
# Hand-drawn polyline using chained cubic splines
# ---------------------------------------------------------------------------
def handdrawn_polyline_path(
        points              : list[PointXY],
        splines_per_segment : int            = 5,
        amp                 : float          = 0.15,
        tightness           : float          = 0.3,
        rng                 : RNGBackend     = None,
    ) -> mplPath:
    """Generate a hand-drawn style polyline represented as a cubic Bezier chain.

    Each straight segment between consecutive points is subdivided into multiple
    short cubic spline sections with randomized curvature and jitter, producing
    a continuous, organic "hand-drawn" appearance.

    Each original line segment is divided into ``splines_per_segment`` equal-length
    subsections. For each subsection, an inner point is randomly *slid* along the
    parent segment by up to +/-0.4 x step length. This random shift changes the
    actual spacing between neighboring spline anchor points, which may range from
    roughly 0.2x to 1.8x the nominal step length - while always preserving the
    overall point order (no self-intersections due to inversion).

    Args:
        points: Sequence of (x, y) coordinates forming the base polyline.
        splines_per_segment: Number of spline subdivisions per straight segment.
        amp: Amplitude of random perpendicular deviation applied to each spline
            (controls "waviness").
        tightness: Fraction controlling how close control points are pulled toward
            endpoints (higher values yield tighter, less curved splines).
        rng: Optional RNG backend (``RNG``, ``random.Random``, or ``np.random.Generator``)
            used for reproducible randomization. If not provided, a thread-safe
            global RNG is used.

    Returns:
        mplPath: A continuous cubic Bezier chain path mimicking a hand-drawn polyline.
    """
    # --- Validation --------------------------------------------------------
    if not isinstance(points, (list, tuple)) or isinstance(points, (str, bytes)):
        raise TypeError("'points' must be an iterable of (x, y) pairs.")
    if len(points) < 2:
        raise ValueError("At least two points are required to form a polyline.")
    if not isinstance(splines_per_segment, int) or splines_per_segment < 1:
        raise ValueError("splines_per_segment must be a positive integer.")
    for name, val in {"amp": amp, "tightness": tightness}.items():
        if not isinstance(val, Real):
            raise TypeError(f"{name} must be numeric, got {type(val).__name__}")

    JITTER_AMPLITUDE = 0.4 # Fraction of a step for sliding amplitude

    # --- RNG ----------------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True)
    normal3s = getattr(rng, "normal3s",
                   lambda: max(-1, min(1, rng.normalvariate(0, 1.0 / 3.0))))

    # --- Core setup --------------------------------------------------------
    P1, Pn = points[0], points[-1]
    closed = (
        (np.isnan(Pn[0]) and np.isnan(Pn[1])) or
        math.hypot(Pn[0] - P1[0], Pn[1] - P1[1]) < 1e-6
    )

    verts: list[PointXY] = [points[0]]

    # --- Loop through polyline segments ------------------------------------
    for start, end in zip(points, points[1:]):
        x0, y0 = start
        xn, yn = end
        dx, dy = xn - x0, yn - y0
        stepx, stepy = dx / splines_per_segment, dy / splines_per_segment
        xp, yp = x0, y0

        # --- Loop through spline sections ----------------------------------
        for i in range(1, splines_per_segment + 1):
            slide = normal3s() * JITTER_AMPLITUDE
            xi = x0 + (i + slide) * stepx # end point of the current section
            yi = y0 + (i + slide) * stepy # end point of the current section
            dxs, dys = xi - xp, yi - yp

            dev1 = normal3s() * amp
            dev2 = normal3s() * amp

            P1 = (xp + dxs * tightness - dys * dev1, yp + dys * tightness + dxs * dev1)
            P2 = (xi - dxs * tightness - dys * dev2, yi - dys * tightness + dxs * dev2)
            P3 = (xi, yi)

            verts.extend([P1, P2, P3])
            xp, yp = xi, yi # set next section start (xp, yp) to curent section end (xi, yi)

        verts[-1] = end

    codes = [mplPath.MOVETO] + [mplPath.CURVE4] * (len(verts) - 1)

    if closed:
        codes.append(mplPath.CLOSEPOLY)
        verts.append(points[0])

    meta: dict = {
        "operation" : "spline",
    }

    return mplPath(verts, codes), meta


# ---------------------------------------------------------------------------
# Demo: visualize hand-drawn polyline parameter effects
# ---------------------------------------------------------------------------
def demo_handdrawn_polyline_path(base_points: list[PointXY] = None,
                                 amps: list[float] = None,
                                 tightness_values: list[float] = None,
                                 seed: int = None) -> None:
    """Visual diagnostic demo for :func:`handdrawn_polyline_path`.

    Generates a grid of examples showing how amplitude and tightness affect
    the curvature and jitter of hand-drawn splines.

    Args:
        base_points: Optional sequence of control points defining the base polyline.
            Defaults to a 4-point zigzag pattern if None.
        amps: Sequence of amplitude values to visualize (controls "waviness").
        tightness_values: Sequence of tightness values to visualize.
        seed: Optional seed for deterministic reproducibility.

    Example:
        >>> from spt.mpl_path_utils import demo_handdrawn_polyline_path
        >>> demo_handdrawn_polyline_path()
    """
    # --- Defaults ----------------------------------------------------------
    if base_points is None:
        base_points = [(0, 0), (1, 0.2), (2, -0.3), (3, 0.1)]
    if amps is None:
        amps = [0.05, 0.1, 0.2, 0.3]
    if tightness_values is None:
        tightness_values = [0.1, 0.2, 0.4, 0.6]

    rng = get_rng(thread_safe=True)
    if seed is not None:
        rng.seed(seed)

    n_rows, n_cols = len(amps), len(tightness_values)
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 2.0 * n_rows))

    if n_rows == 1 and n_cols == 1:
        axes = np.array([[axes]])
    elif n_rows == 1:
        axes = np.array([axes])
    elif n_cols == 1:
        axes = np.array([[ax] for ax in axes])

    # --- Plot each combination --------------------------------------------
    for i, amp in enumerate(amps):
        for j, tight in enumerate(tightness_values):
            ax = axes[i, j]
            path = handdrawn_polyline_path(
                base_points, amp=amp, tightness=tight, rng=rng
            )
            patch = PathPatch(path, facecolor="none", lw=2.0, alpha=0.8)
            ax.add_patch(patch)
            ax.plot(*zip(*base_points), "--", lw=0.8, color="gray", alpha=0.5)
            ax.set_aspect("equal")
            ax.autoscale_view()
            ax.set_xticks([])
            ax.set_yticks([])
            ax.set_title(f"amp={amp:.2f}, tight={tight:.2f}")

    plt.suptitle("Hand-Drawn Polyline Parameter Sweep", fontsize=14, weight="bold")
    plt.tight_layout()
    plt.show()


# ---------------------------------------------------------------------------
# Construct a Matplotlib Path composed of cubic Bezier segments with C1 continuity.
# ---------------------------------------------------------------------------
def bezier_from_xy_dy(
        x              : NDarray,
        y              : NDarray,
        dy             : NDarray  = None,
        tension        : float    = 0.0,
        endpoint_style : str      = "default",
    ) -> mplPath:
    """
    Construct a Matplotlib Path composed of cubic Bezier segments with C1 continuity.
    
    Each segment between consecutive (x, y) pairs is defined by four control points:
    P0, P1, P2, P3, where P1 and P2 determine tangent behavior. The default scaling
    (1/3 of the segment length) yields a standard cubic Bezier interpolant.
    
    The curve shape can be tuned using:
      - `tension`: adjusts derivative magnitude (smoothness)
      - `endpoint_style`: modifies tangent scaling at endpoints
    
    Args:
        x: 1D strictly increasing array of x-coordinates.
        y: 1D array of function values y(x).
        dy: Optional 1D array of derivatives y'(x).
            If None, estimated via finite differences.
        tension: Smoothness control in [0, 1].
            0 - fully smooth (Catmull-Rom-like)
            1 - polyline (zero curvature)
            Nonlinear scaling ( (1-tension)^2 ) is applied for gentler decay.
        endpoint_style:
            - 'default': uniform 1/3 tangent scaling (standard Bezier)
            - 'catmull': uniform 1/6 scaling (softer curvature)
            - 'relaxed': adaptive - 1/6 at endpoints, 1/3 inside
            - numeric value: custom uniform scaling factor (e.g., 0.25)
    
    Returns:
        matplotlib.path.Path:
            Path representing the continuous Bezier spline.
    
    Raises:
        ValueError: if fewer than two points are provided or x is not strictly increasing.
    """
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    n = len(x)
    if n < 2:
        raise ValueError("Need at least two data points.")
    if np.any(np.diff(x) <= 0):
        raise ValueError("x must be strictly increasing.")

    # --- Derivative estimation if not provided ---
    if dy is None:
        dy = np.empty_like(y)
        dx = np.diff(x)
        dy[1:-1] = (y[2:] - y[:-2]) / (x[2:] - x[:-2])
        dy[0] = (y[1] - y[0]) / dx[0]
        dy[-1] = (y[-1] - y[-2]) / dx[-1]
        dy *= (1.0 - tension) ** 2  # Nonlinear tension scaling

    # --- Segment geometry ---
    h = np.diff(x)
    x0, y0, dy0 = x[:-1], y[:-1], dy[:-1]
    x1, y1, dy1 = x[1:], y[1:], dy[1:]

    # --- Tangent scaling factor selection ---
    if isinstance(endpoint_style, Real):
        scale = np.full_like(h, float(endpoint_style))
    elif endpoint_style == "catmull":
        scale = np.full_like(h, 1 / 6)
    elif endpoint_style == "relaxed":
        scale = np.full_like(h, 1 / 3)
        if len(scale) >= 2:
            scale[0] = scale[-1] = 1 / 6
    else:  # default
        scale = np.full_like(h, 1 / 3)

    # --- Compute control points ---
    B0 = np.column_stack([x0, y0])
    B1 = np.column_stack([x0 + scale * h, y0 + scale * h * dy0])
    B2 = np.column_stack([x1 - scale * h, y1 - scale * h * dy1])
    B3 = np.column_stack([x1, y1])

    # --- Assemble vertices and codes sequentially ---
    verts = [B0[0]]
    codes = [mplPath.MOVETO]
    for b1, b2, b3 in zip(B1, B2, B3):
        verts.extend([b1, b2, b3])
        codes.extend([mplPath.CURVE4, mplPath.CURVE4, mplPath.CURVE4])

    verts = np.array(verts, dtype=float)
    codes = np.array(codes, dtype=np.uint8)
    return mplPath(verts, codes)


# ---------------------------------------------------------------------------
# Single segment Bezier approximation for an acute unit circular arc
# ---------------------------------------------------------------------------
def unit_circular_arc_segment(
        start_deg : float = 0.0,
        end_deg   : float = 90.0
    ) -> mplPath:
    """ Construct a cubic Bezier Path approximating a circular arc between two angles.

    The arc lies on the unit circle centered at (0, 0) and spans from `start_deg`
    to `end_deg` degrees, measured counter-clockwise. For spans larger than 90deg,
    multiple segments should be joined for accurate curvature.

    Args:
        start_deg: Start angle in degrees (0deg = +X axis).
        end_deg:   End angle in degrees.
    
    Returns:
        mplPath: Path consisting of four vertices (MOVETO + 3xCURVE4)
                 representing a single cubic Bezier arc segment.

    Raises:
        ValueError: If the absolute angular span exceeds 90deg.

    Notes:
        - The handle length `t = 4/3 * tan(theta / 4)` ensures tangent continuity.
        - Approximation error < 0.00027 R for theta = 90deg.
        - Suitable for composing smooth multi-segment arcs.
    """
    # --- Validate span -------------------------------------------------------
    span = abs(end_deg - start_deg)
    if span > 90.0 + 1e-9:
        raise ValueError(
            f"Span too large ({span:.2f}deg) for single cubic Bezier; "
            "split into <= 90deg segments."
        )

    # --- Core geometry -------------------------------------------------------
    start = np.radians(start_deg)
    end = np.radians(end_deg)
    delta = end - start
    t = 4.0 / 3.0 * np.tan(delta / 4.0)  # handle scaling

    # --- Compute control points ---------------------------------------------
    cos_s, sin_s = np.cos(start), np.sin(start)
    cos_e, sin_e = np.cos(end), np.sin(end)

    P0 = (cos_s, sin_s)
    P1 = (cos_s - t * sin_s, sin_s + t * cos_s)
    P2 = (cos_e + t * sin_e, sin_e - t * cos_e)
    P3 = (cos_e, sin_e)

    verts = np.array([P0, P1, P2, P3], dtype=float)
    codes = np.array(
        [mplPath.MOVETO, mplPath.CURVE4, mplPath.CURVE4, mplPath.CURVE4],
        dtype=np.uint8,
    )
    return mplPath(verts, codes)


# ---------------------------------------------------------------------------
# Basic Ellipse / Arc path generator
# ---------------------------------------------------------------------------
def basic_ellipse_or_arc_path(
        x0           : float,
        y0           : float,
        r            : float,
        y_compress   : float = 1.0,
        start_angle  : float = 0.0,
        end_angle    : float = 360.0,
        angle_offset : float = 0.0,
        close        : bool  = False
    ) -> mplPath:
    """Create a basic Matplotlib Path representing a circle, ellipse, or elliptical arc.
  
    Supports anisotropic vertical scaling via ``y_compress`` and rotation via
    ``angle_offset``. Optionally closes the arc to form a filled sector (pie slice).

    Args:
        x0: Center X-coordinate.
        y0: Center Y-coordinate.
        r: Horizontal radius before compression (Rx).
        y_compress: Vertical compression factor (Ry = r * y_compress).
        start_angle: Start angle in degrees (0deg = +X axis).
        end_angle: End angle in degrees.
        angle_offset: Rotation angle in degrees for the ellipse major axis.
        close: If True, closes the arc to the center (for filled sectors).
  
    Returns:
        mplPath: Path representing the circle, ellipse, or arc segment.
    """
    start_angle = float(start_angle)
    end_angle = float(end_angle)
    span = (end_angle - start_angle) % 360.0

    rx = r
    ry = r * y_compress

    # --- Full circle / ellipse ---
    if abs(span) < 1e-6 or abs(span - 360.0) < 1e-6:
        if abs(y_compress - 1.0) < 1e-9 and abs(angle_offset) < 1e-9:
            patch = Circle((x0, y0), rx)
        else:
            patch = Ellipse((x0, y0), 2 * rx, 2 * ry, angle=angle_offset)
        return patch.get_transform().transform_path(patch.get_path())

    # --- Partial arc / elliptical arc ---
    arc = Arc((x0, y0), 2 * rx, 2 * ry, angle=angle_offset,
              theta1=start_angle, theta2=end_angle)
    path = arc.get_path()
    transformed = arc.get_transform().transform_path(path)

    if not close:
        return transformed

    # --- Close arc to center (filled sector) ---
    verts = transformed.vertices
    codes = transformed.codes.copy()

    verts_closed = np.vstack([
        verts,
        [x0, y0],           # line to center
        verts[0],           # close back to start
    ])
    codes_closed = np.concatenate([
        codes,
        [mplPath.LINETO, mplPath.CLOSEPOLY],
    ])

    return mplPath(verts_closed, codes_closed)


# ---------------------------------------------------------------------------
# Ellipse / Arc
# ---------------------------------------------------------------------------
def elliptical_arc(
        canvas_x1x2        : CoordRange = (0, 1023),
        canvas_y1y2        : CoordRange = (0, 1023),
        start_deg          : float      = None,
        end_deg            : float      = None,
        y_compress         : float      = None,
        angle_deg          : int        = None,
        origin             : PointXY    = None,
        jitter_angle_deg   : int        = JITTER_ANGLE_DEG,
        jitter_amp         : float      = 0.04,
        jitter_y           : float      = 0.1,
        max_angle_step_deg : int        = 20,
        min_angle_steps    : int        = 3,
        rng                : RNGBackend = None,
    ) -> tuple[mplPath, dict]:
    """Creates a generalized elliptical arc or ellipse.

    The function first generates a unit circular arc using piecewise cubic
    Bezier curves. It then applies multi-stage transformations:

      1. Jittered arc generation (minor spatial & angular irregularities)
      2. Elliptical scaling (via y_compress)
      3. Random rotation and translation (via random_srt_path)

    Args:
        canvas_x1x2: Horizontal bounding range (pixels).
        canvas_y1y2: Vertical bounding range (pixels).
        start_deg, end_deg: Arc angles in degrees. Defaults to random values.
        y_compress: Optional y-axis compression (<1.0 -> ellipse).
        angle_deg: Optional global rotation angle.
        origin: Optional translation origin.
        jitter_angle_deg: Angular jitter magnitude (3sigma).
        jitter_amp: Additive positional jitter magnitude.
        jitter_y: Multiplicative jitter applied to y-axis only.
        max_angle_step_deg: Max angular span per cubic Bezier segment.
        min_angle_steps: Minimum number of Bezier segments.
        rng: Optional random number generator backend.

    Returns:
        tuple:
            mplPath: Final elliptical arc path.
            dict: Metadata with applied parameters and transformations.
    """
    # --- RNG setup ---------------------------------------------------------
    if rng is None:
        rng = get_rng(thread_safe=True, use_numpy=True)

    if not isinstance(rng._rng, np.random.Generator):
        raise TypeError(f"elliptical_arc requires np.random.Generator. Received '{type(rng._rng)}'")

    # --- Stage 1: unit circular arc ---------------------------------------
    shape, shape_meta = unit_circular_arc(
        start_deg=start_deg,
        end_deg=end_deg,
        jitter_amp=jitter_amp,
        jitter_y=jitter_y,
        max_angle_step_deg=max_angle_step_deg,
        min_angle_steps=min_angle_steps,
        rng=rng,
    )

    # --- Stage 2: apply SRT (scale / rotate / translate) -------------------
    shape, srt_meta = random_srt_path(
        shape=shape,
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=y_compress,
        angle_deg=angle_deg,
        origin=origin,
        jitter_angle_deg=jitter_angle_deg,
        rng=rng,
    )

    # --- Merge metadata ----------------------------------------------------
    """
    meta: dict = {
        "shape_meta": {
            "shape_kind": "circle",
            "start_deg" : start_deg,
            "end_deg"   : end_deg,
        },
        "srt_meta": {
            "scale_x": srt_meta["scale_x"],
            "scale_y": srt_meta["scale_y"],
            "rot_x"  : srt_meta["rot_x"],
            "rot_y"  : srt_meta["rot_y"],
            "rot_deg": srt_meta["rot_deg"],
            "trans_x": srt_meta["trans_x"],
            "trans_y": srt_meta["trans_y"],
        }
    }
    """
    meta = {
        "shape_meta"  : shape_meta,
        "srt_meta"    : srt_meta,
    }

    return shape, meta


# ---------------------------------------------------------------------------
# Line Segment
# ---------------------------------------------------------------------------
def line_segment(
        canvas_x1x2         : PointXY,
        canvas_y1y2         : PointXY,
        base_angle          : int        = None,
        jitter_angle_deg    : int        = JITTER_ANGLE_DEG,
        splines_per_segment : int        = 5,
        amp                 : float      = 0.3,
        tightness           : float      = 0.25,
        rng                 : RNGBackend = None,
    ) -> mplPath:
    """Creates a random line segment."""

    # --- Stage 1: unit line ------------------------------------------------
    shape, shape_meta = unit_circle_diameter(
            base_angle=base_angle,
            jitter_angle_deg=jitter_angle_deg,
            rng=rng,
    )
    
    # --- Stage 2: apply hand-drawn style -----------------------------------
    shape, spline_meta = handdrawn_polyline_path(
        points=list(shape.vertices),
        splines_per_segment=splines_per_segment,
        amp=amp,
        tightness=tightness,
        rng=rng,
    )
    
    # --- Stage 3: apply SRT (scale / rotate / translate) -------------------
    shape, srt_meta = random_srt_path(
        shape=shape,
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=None,
        angle_deg=base_angle,
        jitter_angle_deg=jitter_angle_deg,
        rng=rng,
    )

    meta = {
        "shape_meta"  : shape_meta,
        "spline_meta" : spline_meta,
        "srt_meta"    : srt_meta,
    }

    return shape, meta


# ---------------------------------------------------------------------------
# Triangle
# ---------------------------------------------------------------------------
def triangle(
        canvas_x1x2         : PointXY,
        canvas_y1y2         : PointXY,
        equal_sides         : int        = None,
        angle_category      : int        = None,
        base_angle          : int        = None,
        origin              : PointXY    = None,
        jitter_angle_deg    : int        = JITTER_ANGLE_DEG,
        splines_per_segment : int        = 5,
        amp                 : float      = 0.3,
        tightness           : float      = 0.25,
        rng                 : RNGBackend = None,
    ) -> mplPath:
    """Creates a random triangle."""

    # --- Stage 1: unit triangle -------------------------------------------
    shape, shape_meta = unit_triangle_path(
        equal_sides=equal_sides,
        angle_category=angle_category,
        jitter_angle_deg=jitter_angle_deg,
        base_angle=base_angle,
        rng=rng,
    )

    # --- Stage 2: apply hand-drawn style -----------------------------------
    shape, spline_meta = handdrawn_polyline_path(
        points=list(shape.vertices),
        splines_per_segment=splines_per_segment,
        amp=amp,
        tightness=tightness,
        rng=rng,
    )
    
    # --- Stage 3: apply SRT (scale / rotate / translate) -------------------
    shape, srt_meta = random_srt_path(
        shape=shape,
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=None,
        angle_deg=base_angle,
        origin=origin,
        jitter_angle_deg=jitter_angle_deg,
        rng=rng,
    )

    meta = {
        "shape_meta"  : shape_meta,
        "spline_meta" : spline_meta,
        "srt_meta"    : srt_meta,
    }

    return shape, meta


# ---------------------------------------------------------------------------
# Rectangle
# ---------------------------------------------------------------------------
def rectangle(
        canvas_x1x2         : PointXY,
        canvas_y1y2         : PointXY,
        diagonal_angle      : Real       = None,
        base_angle          : int        = None,
        origin              : PointXY    = None,
        jitter_angle_deg    : int        = JITTER_ANGLE_DEG,
        splines_per_segment : int        = 5,
        amp                 : float      = 0.3,
        tightness           : float      = 0.25,
        rng                 : RNGBackend = None,
    ) -> mplPath:
    """Creates a random rectangle.

    Composes three primitives:
    1. unit_rectangle_rnd() - geometric primitive generation
    2. random_srt_path()    - geometric transformation to canvas space
    3. polyline_path()      - stylization into hand-drawn form
    
    This function performs *no* parameter interpretation or mutation
    beyond connecting compatible interfaces between the components.
    """
    # --- Stage 1: unit rectangle ------------------------------------------
    shape, shape_meta = unit_rectangle_path(
        diagonal_angle=diagonal_angle,
        jitter_angle_deg=jitter_angle_deg,
        base_angle=base_angle,
        rng=rng,
    )

    # --- Stage 2: apply hand-drawn style -----------------------------------
    shape, spline_meta = handdrawn_polyline_path(
        points=list(shape.vertices),
        splines_per_segment=splines_per_segment,
        amp=amp,
        tightness=tightness,
        rng=rng,
    )
    
    # --- Stage 3: apply SRT (scale / rotate / translate) -------------------
    shape, srt_meta = random_srt_path(
        shape=shape,
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=None,
        angle_deg=base_angle,
        origin=origin,
        jitter_angle_deg=jitter_angle_deg,
        rng=rng,
    )

    meta = {
        "shape_meta"  : shape_meta,
        "spline_meta" : spline_meta,
        "srt_meta"    : srt_meta,
    }

    return shape, meta


def demo():
    rng = get_rng(thread_safe=True, use_numpy=True)
    
    canvas_x1x2=(0, 40)
    canvas_y1y2=(0, 30)
        
    fig, ax = plt.subplots(figsize=(5, 5))

    ax.set_aspect("equal")
    ax.grid(True, ls="--", alpha=0.5)
    ax.set_xlim(*canvas_x1x2)
    ax.set_ylim(*canvas_y1y2)

    line_shape, meta = line_segment(
        canvas_x1x2=canvas_x1x2, canvas_y1y2=canvas_y1y2, base_angle=None, 
    )
    ax.add_patch(PathPatch(line_shape, edgecolor="green", lw=2, facecolor="none", linestyle="dashdot"))

    arc_shape, meta = elliptical_arc(
        canvas_x1x2=canvas_x1x2, canvas_y1y2=canvas_y1y2,
        start_deg=None, end_deg=None, angle_deg=None, origin=(0, 0),
    )
    ax.add_patch(PathPatch(arc_shape, edgecolor="blue", lw=2, facecolor="none", linestyle="--"))

    rect_shape, meta = rectangle(
        canvas_x1x2=canvas_x1x2, canvas_y1y2=canvas_y1y2, diagonal_angle=None, base_angle=None, origin=None,
    )
    ax.add_patch(PathPatch(rect_shape, edgecolor="purple", lw=2, facecolor="none", linestyle="dashed"))

    triangle_shape, meta = triangle(
        canvas_x1x2, canvas_y1y2, equal_sides = None, angle_category = None, base_angle = None
    )
    ax.add_patch(PathPatch(triangle_shape, edgecolor="orange", lw=3, facecolor="none", linestyle="dotted"))

    x = np.linspace(-1, 1, 10)
    y = np.sin(np.pi * x)
    dy = np.cos(np.pi * x) * np.pi
    function1, meta = random_srt_path(
        bezier_from_xy_dy(x, y, dy=None, tension=0.25),
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=1,
        angle_deg=None,
        jitter_angle_deg=None,
        origin=(0, 0),
        rng=rng,
    )
    ax.add_patch(PathPatch(function1, edgecolor="gold", lw=2, facecolor="none", linestyle="solid"))

    function2, meta = random_srt_path(
        bezier_from_xy_dy(x, y, dy=dy, tension=0.25), 
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=1,
        angle_deg=None,
        jitter_angle_deg=None,
        origin=(0, 0),
        rng=rng,
    )
    ax.add_patch(PathPatch(function2, edgecolor="violet", lw=2, facecolor="none", linestyle="solid"))

    x = np.linspace(0.1, 10, 100)
    negx = np.linspace(-10, -0.1, 100)
    negy = 1 / negx
    y = 1 / x
    dy = -1 / (x * x)
    function3, meta = random_srt_path(
        join_paths([bezier_from_xy_dy(negx, negy, dy=None, tension=0.25), bezier_from_xy_dy(x, y, dy=None, tension=0.25)], True), 
        canvas_x1x2=canvas_x1x2,
        canvas_y1y2=canvas_y1y2,
        y_compress=1,
        angle_deg=None,
        jitter_angle_deg=None,
        origin=(0, 0),
        rng=rng,
    )
    ax.add_patch(PathPatch(function3, edgecolor="magenta", lw=2, facecolor="none", linestyle="solid"))

    plt.show()


if __name__ == "__main__":
    demo()
``` 
 
===== END mpl_path_utils.py ===== 
 
===== START mpl_renderer.py ===== 
```python 
"""
mpl_renderer.py
-----------
"""

from __future__ import annotations

import os
import sys
import time
import random
import logging
from enum import Enum, auto
from typing import Optional, Union
from collections.abc import Iterable

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.patches import PathPatch
from matplotlib.path import Path as mplPath
from matplotlib.transforms import Affine2D

from rng import RNG, get_rng
from utils.logging_utils import configure_logging
from mpl_utils import (
    # Conversion helpers
    bgr_from_rgba, rgb_from_bgr,
    # Rendering helpers
    show_RGBx_grid, render_scene,
    # Type aliases
    ImageBGR, ImageRGB, ImageRGBA, ImageRGBx,
    # Constants
    PAPER_COLORS,
)

numeric = Union[int, float]
PointXY = tuple[numeric, numeric]
CoordRange = tuple[numeric, numeric]


def clamped_normal(self, sigma=1, amp=1):
    return max(-amp, min(amp, self.rng.normalvariate(0, sigma)))


class MPLRenderer:
    """
    Generator of basic Matplotlib scenes
    
    Prepares a Matplotlib scene composed of geometric primitives:
     - Basic geometric shapes (lines, triangles, rectangles, ellipsoidal arcs.
     - Tabulated smooth functions {(x, y) pairs or (x, y, y') triples.
     - Randomizes scale, orientation, position, kind, style.
     - Uses Matplotlib provided cubic Bezier curves to imitate hand-drawn lines.
     - Introduces random jitter to shapes and angles, imitating non-ideal rendering.
     - Selects a random background from a predefined list.
    """

    rng: RNG = get_rng(thread_safe=True)  # class-level RNG shared by all instances

    def __init__(self):
        self.pid = os.getpid()
        self.logger = logging.getLogger(self.__class__.__name__)
        if not self.logger.handlers:
            log_path = configure_logging(
                level=logging.DEBUG,
                name=self.__class__.__name__,
                run_prefix=f"{self.__class__.__name__}_{self.pid}"
            )            

    @classmethod
    def reseed(cls, seed: int = None) -> None:
        """Re-seed the internal RNG (for deterministic replay)."""
        cls.rng.seed(seed)

    def render_scene() -> ImageRGBA:
        """Renders Matplotlib scene as RGBA"""
        # Dummy stub
        return self.render_dummy_scene()

    def render_dummy_scene() -> ImageRGBA:
        """Renders dummy Matplotlib scene as RGBA"""
        rng: RNG = self.__class__.rng
        return render_scene(
                   canvas_bg_idx=rng.randrange(len(PAPER_COLORS)),
                   plot_bg_idx=rng.randrange(len(PAPER_COLORS)),
               )
``` 
 
===== END mpl_renderer.py ===== 
 
===== START mpl_utils.py ===== 
```python 
"""
mpl_utils.py
-----------
"""

from __future__ import annotations

__all__ = [
    "bgr_from_rgba", "rgb_from_bgr", "rgbf_from_rgba", "rgb_from_rgbf",
    "show_RGBx_grid", "render_scene",
    "ImageBGR", "ImageBGRF", "ImageRGB", "ImageRGBF", "ImageRGBA", "ImageRGBx",
    "PAPER_COLORS", "DEFAULT_LINEWIDTHS",
]

import os
import sys
import time
import random
import math
from typing import TypeAlias, Literal, Sequence, Union
from functools import lru_cache, cache
import numpy as np
from numpy.typing import NDArray
from skimage import util, exposure

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection

ImageBGR:  TypeAlias = NDArray[np.uint8]    # (H, W, 3) BGR order
ImageBGRF: TypeAlias = NDArray[np.float32]  # (H, W, 3) BGR order
ImageRGB:  TypeAlias = NDArray[np.uint8]    # (H, W, 3) RGB order
ImageRGBF: TypeAlias = NDArray[np.float32]  # (H, W, 3) RGB order
ImageRGBA: TypeAlias = NDArray[np.uint8]    # (H, W, 4) RGBA order
ImageRGBx: TypeAlias = Union[ImageRGB, ImageRGBA] # Either RGB or RGBA

DEFAULT_LINEWIDTHS = (1.0, 1.5, 2.0, 2.5, 3.0)
PAPER_COLORS = [
    "none", "white", "cornsilk", "ivory", "oldlace", "floralwhite", "whitesmoke"
] # X11/CSS4

# Plot background color settings
#
# Global settings:
#   plt.rcParams["figure.facecolor"] = "white" # Canvas
#   plt.rcParams["axes.facecolor"] = "white"   # Plot area
#
# Object:
#   fig.patch.set_facecolor("white")           # Canvas
#   ax.set_facecolor("white")                  # Plot area
#
# Object - Transparent:                        # Canvas   
#   fig.patch.set_alpha(0.0)                   # Plot area
#   ax.set_facecolor("none")

# Plot padding trimming (numbers are fractions of canvas size)
#
# Global:
#   fig.subplots_adjust(left=0, right=1, top=1, bottom=0, wspace=0, hspace=0)
#   plt.tight_layout() # Reduces margins to reasonable minimum.
#       IMPORTANT: must be executed AFTER ax.axis("off")
#
# Object:
#   ax.set_position([0, 0, 1, 1])
#   ax.margins(x=0, y=0)


def bgr_from_rgba(rgba: ImageRGBA) -> ImageBGR:
    """Convert RGBA (Matplotlib) to BGR (OpenCV)."""
    return rgba[..., :3][..., ::-1]


def rgb_from_bgr(bgr: ImageBGR) -> ImageRGB:
    """Convert BGR (OpenCV) to RGB (Matplotlib)."""
    return bgr[..., ::-1]


def rgbf_from_rgba(rgba: ImageRGBA) -> ImageRGBF:
    """Convert RGBA uint8 -> RGB float32 in [0, 1]."""
    return rgba[..., :3].astype(np.float32) / 255.0


def rgb_from_rgbf(rgbf: ImageRGBF) -> ImageRGB:
    """Convert RGB float32 in [0, 1] -> RGB uint8."""
    # Clip to avoid rounding issues if upstream overshoots
    return (np.clip(rgbf, 0.0, 1.0) * 255.0 + 0.5).astype(np.uint8)


def show_RGBx_grid(images: dict[str, ImageRGBx], title_style: dict = None, 
                   n_columns: int = None, figsize_scale: float = 5) -> None:
    """
    Display multiple images in an automatically balanced rectangular grid.

    Layout rule:
        cols = ceil(sqrt(N))
        rows = ceil(N / cols)
    (Keeps the layout close to square, with longer side horizontal.)

    Args:
        images: Dictionary of <Title>:<Image>; Image - NumPy array (RGB or RGBA).
        title_style: Optional dict for Matplotlib title styling.
        figsize_scale: Multiplier for overall figure size.
    """
    images_n = len(images)
    if images_n == 0:
        raise ValueError("No images to display.")

    # --- Compute balanced grid ---
    
    cols = n_columns or math.ceil(math.sqrt(images_n))
    rows = math.ceil(images_n / cols)

    fig_w = cols * figsize_scale
    fig_h = rows * figsize_scale * 0.9
    fig, axes = plt.subplots(rows, cols, figsize=(fig_w, fig_h))
    axes = np.array(axes).reshape(-1)  # flatten axes array

    # --- Title style defaults ---
    style = dict(fontsize=14, fontweight="bold", color="green")
    if title_style:
        style.update(title_style)

    # --- Draw each image ---
    for (title, img), ax in zip(images.items(), axes):
        ax.imshow(img)
        ax.set_title(title, **style)
        ax.axis("off")

    for i in range(images_n, rows * cols):
        axes[i].axis("off")

    plt.tight_layout()
    plt.show()


def add_grid(ax, width_mm=100, height_mm=80) -> None:
    """Add fine (1 mm) and major (10 mm) gridlines using LineCollection."""
    # Fine grid every 1 mm
    x_fine = np.arange(0, width_mm + 1, 1)
    y_fine = np.arange(0, height_mm + 1, 1)
    lines_fine = (
        [((x, 0), (x, height_mm)) for x in x_fine] +
        [((0, y), (width_mm, y)) for y in y_fine]
    )
    lc_fine = LineCollection(lines_fine, colors="gray", linewidths=0.2, alpha=0.5, zorder=0)
    ax.add_collection(lc_fine)

    # Major grid every 10 mm
    x_major = np.arange(0, width_mm + 1, 10)
    y_major = np.arange(0, height_mm + 1, 10)
    lines_major = (
        [((x, 0), (x, height_mm)) for x in x_major] +
        [((0, y), (width_mm, y)) for y in y_major]
    )
    lc_major = LineCollection(lines_major, colors="gray", linewidths=0.6, alpha=0.7, zorder=0)
    ax.add_collection(lc_major)


# ----------------------------------------------------------------------
# Public API (randomized selection)
# ----------------------------------------------------------------------
def render_scene(
        width_mm      : float = 100, 
        height_mm     : float = 80,
        dpi           : int   = 200,
        canvas_bg_idx : int   = None,
        plot_bg_idx   : int   = None,
    ) -> ImageRGBA:
    """
    Renders a dummy Matplotlib scene as RGBA.

    Public API - returns a (possibly random) scene.
    Randomizes background choices if invalid or None.
    Wraps the cached renderer.
    """
    
    """Public entry - randomizes missing bg indices, then uses the cached renderer."""

    rng = random.Random(os.getpid() ^ int(time.time()))

    # Assign random backgrounds where needed
    bg_n = len(PAPER_COLORS)
    if canvas_bg_idx is None or canvas_bg_idx not in range(bg_n):
        canvas_bg_idx = rng.randrange(bg_n)

    if plot_bg_idx is None or plot_bg_idx not in range(bg_n):
        plot_bg_idx = rng.randrange(bg_n)

    # Call the deterministic, cached version
    return render_scene_cached(width_mm, height_mm, dpi, canvas_bg_idx, plot_bg_idx)


# ----------------------------------------------------------------------
# Cache renderer
# ----------------------------------------------------------------------
@lru_cache(maxsize=None)
def render_scene_cached(
        width_mm      : float = 100, 
        height_mm     : float = 80,
        dpi           : int   = 200,
        canvas_bg_idx : int   = None,
        plot_bg_idx   : int   = None,
    ) -> ImageRGBA:
    """
    LRU-cached deterministic renderer.
    
    Render an ideal grid + primitives scene via Matplotlib.

    Returns:
        RGBA numpy array (H x W x 4), to be passed into SyntheticPhotoProcessor.
    """    
    fig, ax = plt.subplots(figsize=(width_mm / 25.4, height_mm / 25.4), dpi=dpi)

    if canvas_bg_idx is not None:
        if canvas_bg_idx == 0:
            fig.patch.set_alpha(0.0)
        else:
            fig.patch.set_facecolor(PAPER_COLORS[canvas_bg_idx])

    if plot_bg_idx is not None:
        ax.set_facecolor(PAPER_COLORS[plot_bg_idx])

    ax.set_xlim(0, width_mm)
    ax.set_ylim(0, height_mm)
    ax.set_aspect("equal")
    ax.axis("off")
    plt.tight_layout()
    #ax.set_position([0, 0, 1, 1])
    #ax.margins(x=0, y=0)
    
    # Grid (1mm + 10mm thicker lines)
    add_grid(ax, width_mm=width_mm, height_mm=height_mm)

    ax.add_patch(plt.Rectangle((30, 30), 20, 20, edgecolor="red", fill=False, lw=2))
    ax.add_patch(plt.Rectangle((10, 50), 20, 20, edgecolor="cyan", fill=False, lw=2))
    ax.add_patch(plt.Circle((70, 40), 10, edgecolor="blue", fill=False, lw=2))
    tri = np.array([[10, 10], [20, 10], [15, 25]])
    ax.fill(tri[:, 0], tri[:, 1], edgecolor="green", fill=False, lw=2)

    fig.canvas.draw()
    rgba = np.asarray(fig.canvas.renderer.buffer_rgba())
    plt.close(fig)

    return rgba


def main():
    # ----------------------------------------------------------------------
    rng = random.Random(os.getpid() ^ int(time.time()))

    rgba: ImageRGBA = render_scene()
    bgr:  ImageBGR  = bgr_from_rgba(rgba)
    rgb:  ImageRGB  = rgb_from_bgr(bgr)
    
    demos = {
        "Matplotlib RGBA":               rgba,
        "Roundtrip: RGBA -> BGR -> RGB": rgb,
    }
    
    canvas_bg_idx = rng.randrange(len(PAPER_COLORS))
    plot_bg_idx = rng.randrange(len(PAPER_COLORS))
    demos[
        f"\nRandom: "
        f"Canvas: '{PAPER_COLORS[canvas_bg_idx]}'. Plot - '{PAPER_COLORS[plot_bg_idx]}'"
    ] = render_scene(canvas_bg_idx=canvas_bg_idx, plot_bg_idx=plot_bg_idx)

    for color_idx in range(len(PAPER_COLORS)):
        demos[
            f"Canvas: '{PAPER_COLORS[color_idx]}'. Plot - '{PAPER_COLORS[color_idx]}'"
        ] = render_scene(canvas_bg_idx=color_idx, plot_bg_idx=color_idx)

    show_RGBx_grid(demos)


if __name__ == "__main__":
    main()
``` 
 
===== END mpl_utils.py ===== 
 
===== START spt.py ===== 
```python 
"""
spt.py
-----------
"""

from __future__ import annotations

__all__ = ["SPTPipeline",]

import os
import sys
import json
import time
import random
import logging

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.sep.join(os.path.abspath(__file__).split(os.sep)[:-2]))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from utils.rng import RNG, get_rng
from utils.logging_utils import configure_logging

from mpl_utils import (
    # Conversion helpers
    bgr_from_rgba, rgb_from_bgr,
    # Rendering helpers
    show_RGBx_grid, render_scene,
    # Type aliases
    ImageBGR, ImageRGB, ImageRGBA, ImageRGBx,
    # Constants
    PAPER_COLORS,
)

from spt_texture  import (
    spt_texture, spt_texture_combined, spt_texture_fibers, spt_texture_fold_crease
)
from spt_lighting import spt_lighting
from spt_noise    import spt_noise
from spt_geometry import spt_geometry
from spt_color    import spt_vignette_and_color


class SPTPipeline:
    """High-level orchestrator for synthetic photo tool pipeline."""

    rng: RNG = get_rng(thread_safe=True)  # class-level RNG shared by all instances

    def __init__(self):
        self.pid = os.getpid()
        self.logger = logging.getLogger(self.__class__.__name__)
        if not self.logger.handlers:
            log_path = configure_logging(
                level=logging.DEBUG,
                name=self.__class__.__name__,
                run_prefix=f"{self.__class__.__name__}_{self.pid}"
            )            

    @classmethod
    def reseed(cls, seed: int = None) -> None:
        """Re-seed the internal RNG (for deterministic replay)."""
        cls.rng.seed(seed)

    @classmethod
    def clamped_normal(cls, sigma=1, amp=1):
        return max(-amp, min(amp, cls.rng.normalvariate(0, sigma)))

    @classmethod
    def normal3s(cls, sf=1):
        return sf * max(-1, min(1, cls.rng.normalvariate(0, 1/3)))

    # ---- Stages ----

    def stage1_texture(self, img: ImageBGR, **kwargs) -> tuple[dict, ImageBGR]:
        """Applies paper texture"""
        self.logger.debug(f"Running stage 2: Texture.")
        rng: RNG = self.__class__.rng

        # meta: dict = {
        #     "texture_strength": kwargs.get("texture_strength",
        #                                    abs(self.clamped_normal(0.5, 2))),
        #     "texture_scale"   : kwargs.get("texture_scale",
        #                                    abs(self.clamped_normal(1, 8))),
        # }
        meta_combined = {
            "add_strength"  : kwargs.get("add_strength", abs(self.normal3s(0.5))),
            "mul_strength"  : kwargs.get("mul_strength", abs(self.normal3s(0.5))),
            "n_layers"      : kwargs.get("n_layers", rng.randint(2, 4)),
            "base_radius"   : kwargs.get("base_radius", rng.randint(1, 8)),
        }
        out = spt_texture_combined(img, **meta_combined)

        meta_fibers = None
        if rng.choice((False, True)):
            meta_fibers = {
                "fiber_strength"        : kwargs.get("fiber_strength", abs(self.normal3s(0.4))),
                "fiber_orientation_deg" : kwargs.get("fiber_orientation_deg", rng.randint(-90, 90)),
                "sigma_long"            : kwargs.get("sigma_long", rng.uniform(5, 15)),
                "sigma_short"           : kwargs.get("sigma_short", rng.uniform(0.5, 1.5)),
            }
            out = spt_texture_fibers(out, **meta_fibers)

        meta_crease = None
        if rng.choice((False, True)):
            meta_crease = {
                "amplitude" : kwargs.get("amplitude", rng.uniform(0, 1)),
                "sigma"     : kwargs.get("sigma", rng.uniform(0, 10)),
            }
            out = spt_texture_fold_crease(out, **meta_crease)
        
        meta = {
            "base"   : meta_combined,
            "fibers" : meta_fibers,
            "crease" : meta_crease,
        }

        # return spt_texture(img, **meta), meta
        return out, meta

    def stage2_lighting(self, img: ImageBGR, **kwargs) -> tuple[dict, ImageBGR]:
        """Applies lighting gradient"""
        rng: RNG = self.__class__.rng                
        self.logger.debug(f"Running stage 1: Lighting.")
        delta = 1 + self.clamped_normal(0.25)
        meta: dict = {
            "top_bright":     kwargs.get("top_bright", 0.5 * delta),
            "bottom_dark":    kwargs.get("bottom_dark", -0.5 * delta),
            "lighting_mode":  kwargs.get("lighting_mode",
                                          self.rng.choice(["linear", "radial"])),
            "gradient_angle": kwargs.get("gradient_angle", self.rng.randint(-180, 180)),
            "grad_cx":        kwargs.get("grad_cx", self.clamped_normal(0.4, 1.5)),
            "grad_cy":        kwargs.get("grad_cy", self.clamped_normal(0.4, 1.5)),
            "brightness":     kwargs.get("brightness",
                                          self.clamped_normal(0.2, 0.5 * delta)),
        }
        return spt_lighting(img, **meta), meta

    def stage3_noise(self, img: ImageBGR, **kwargs) -> tuple[dict, ImageBGR]:
        """Applies noise"""
        rng: RNG = self.__class__.rng                
        self.logger.debug(f"Running stage 3: Noise.")
        meta: dict = {
            "poisson":     kwargs.get("poisson", self.rng.choice([False, True])),
            "gaussian":    kwargs.get("gaussian", abs(self.clamped_normal(0.2))),
            "sp_amount":   kwargs.get("sp_amount", abs(self.clamped_normal(0.2))),
            "speckle_var": kwargs.get("speckle_var", abs(self.clamped_normal(0.2))),
            "blur_sigma":  kwargs.get("blur_sigma", abs(self.clamped_normal(0.2))),
        }
        return spt_noise(img, **meta), meta

    def stage4_geometry(self, img: ImageBGR, **kwargs) -> tuple[dict, ImageBGR]:
        """Applies geometric effects."""
        self.logger.debug(f"Running stage 4: Geometry.")
        meta: dict = {
            "tilt_x": kwargs.get("tilt_x", self.clamped_normal(0.25)),
            "tilt_y": kwargs.get("tilt_y", self.clamped_normal(0.25)),
            "k1":     kwargs.get("k1",     self.clamped_normal(0.25)),
            "k2":     kwargs.get("k2",     self.clamped_normal(0.25)),
        }
        return spt_geometry(img, **meta), meta

    def stage5_color(self, img: ImageBGR, **kwargs) -> tuple[dict, ImageBGR]:
        """Applies color effects."""
        self.logger.debug(f"Running stage 5: Color.")
        meta: dict = {
            "vignette_strength": kwargs.get("vignette_strength", 
                                             abs(self.clamped_normal(0.1, 0.5))),
            "warm_strength":     kwargs.get("warm_strength",
                                             abs(self.clamped_normal(0.1, 0.5))),
        }
        return spt_vignette_and_color(img, **meta), meta

    # ---- Pipeline ----
    def run(self, img: ImageBGR = None, **kwargs):
        meta = {}
        runtime = {}
        images = {}
        stages = [
            ("1 - Texture",  self.stage1_texture),
            ("2 - Lighting", self.stage2_lighting),
            ("3 - Noise",    self.stage3_noise),
            ("4 - Geometry", self.stage4_geometry),
            ("5 - Color",    self.stage5_color),
        ]        

        total = 0
        name = "0 - Matplotlib"
        if not img:
            self.logger.warning(f"No Matplotlib RGBA image is provided. Using a dummy generator.")
            t0 = time.perf_counter()
            canvas_bg_idx = self.rng.randrange(len(PAPER_COLORS))
            plot_bg_idx = self.rng.randrange(len(PAPER_COLORS))
            base_rgba = render_scene(canvas_bg_idx=canvas_bg_idx, plot_bg_idx=plot_bg_idx)
            stage0_mpl = bgr_from_rgba(base_rgba)
            elapsed_ms = (time.perf_counter() - t0) * 1000.0
            runtime[name] = round(elapsed_ms, 2)
            total += runtime[name]
            out_img = stage0_mpl
        else:
            out_img = img

        images[name] = rgb_from_bgr(out_img)

        for name, stage_fn in stages:
            t0 = time.perf_counter()
            out_img, stage_meta = stage_fn(out_img, **kwargs)
            elapsed_ms = (time.perf_counter() - t0) * 1000.0

            # Record metadata + timing
            images[name] = rgb_from_bgr(out_img)
            runtime[name] = round(elapsed_ms, 3)
            meta[name] = stage_meta
            total += runtime[name]

        runtime["Total"] = round(total, 3)
        
        if not spt_config.BATCH_MODE:
            summary = [""]
            summary.append("=" * 80)
            summary.append(f"{'PIPELINE PERFORMANCE SUMMARY':^40}")
            summary.append("=" * 40)

            key_width = 20

            summary.append(f"{'Performance Summary':-^35}")

            for k, v in runtime.items():
                summary.append(f"  {k:<{key_width}}: {v:10.3f} ms")

            for name, stage_meta in meta.items():
                summary.append(
                    f"\n{name:-^35}")
                for k, v in stage_meta.items():
                    if isinstance(v, int):
                        val = f"{v:>6}    "
                    elif isinstance(v, float):
                        val = f"{v:10.3f}    "
                    else:
                        val = v
                    summary.append(f"  {k:<{key_width}}: {val}")
            summary.append("=" * 80)
            self.logger.debug('\n'.join(summary))
            show_RGBx_grid(images, n_columns=3)
        
        return out_img, meta


def main():
    pipeline: SPTPipeline = SPTPipeline()
    pipeline.run()


if __name__ == "__main__":
    main()
``` 
 
===== END spt.py ===== 
 
===== START spt_color.py ===== 
```python 
"""
spt_color.py
-----------
"""

from __future__ import annotations

__all__ = ["spt_vignette_and_color",]

import os
import sys
import time
import random
import math
import numpy as np
import matplotlib.pyplot as plt
import cv2

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from mpl_utils import *


def spt_vignette_and_color(img: ImageBGR, vignette_strength: float = 0.35,
                           warm_strength: float = 0.10) -> ImageBGR:
    """
    Apply post-lens vignetting and chromatic channel imbalance.
    
    The algorithm constructs a normalized radial field `r in [0, 1]` measured
    from the optical center and applies two coupled effects:
    
    1. **Vignetting:** A quadratic radial attenuation of luminance simulating
       the optical fall-off toward the image corners. The attenuation mask is
    
           V(r) = 1 - vignette_strength * r^2
    
       where `vignette_strength` controls corner darkening amplitude.
    
    2. **Chromatic warming:** A mild wavelength-dependent gain imbalance that
       increases red-channel intensity and slightly decreases blue toward the
       periphery, approximating lens coatings and sensor color-response drift.
       Channel-specific scaling masks are defined as
    
           warm_mask(r) = 1 + warm_strength * r^1.2   (R channel)
           cool_mask(r) = 1 - 0.5 * warm_strength * r^1.2   (B channel)
    
    These masks are applied multiplicatively to the float32 image in BGR order,
    preserving relative color balance near the center while inducing subtle
    warmth and fall-off toward edges. The result is clipped to [0, 255] and
    quantized back to uint8.
    
    Args:
        img: Input image (uint8, BGR order).
        vignette_strength: Radial brightness fall-off magnitude (0-1).
        warm_strength: Peripheral color warming intensity (0-1).
    
    Returns:
        ImageBGR: Image with vignette and color-shift applied.
    """
    if vignette_strength <= 0 and warm_strength <= 0:
        return img
    
    h, w = img.shape[:2]
    cx, cy = w / 2.0, h / 2.0
    xx, yy = np.meshgrid(np.arange(w, dtype=np.float32),
                         np.arange(h, dtype=np.float32))
    rx = (xx - cx) / cx
    ry = (yy - cy) / cy
    r = np.sqrt(rx * rx + ry * ry)
    r_norm = np.clip(r / (r.max() + 1e-9), 0.0, 1.0)
    
    # --- Radial masks ---
    vignette_mask = 1.0 - vignette_strength * (r_norm ** 2)
    warm_mask = 1.0 + warm_strength * (r_norm ** 1.2)
    cool_mask = 1.0 - 0.5 * warm_strength * (r_norm ** 1.2)
    
    # --- Apply modulation ---
    img_f = img.astype(np.float32)
    img_f *= vignette_mask[..., None]
    img_f[..., 0] *= cool_mask   # B channel
    img_f[..., 2] *= warm_mask   # R channel
    
    return np.clip(img_f, 0, 255).astype(np.uint8)


def main():
    # ----------------------------------------------------------------------
    base_rgba: ImageRGBA = render_scene()
    base_bgr:  ImageBGR  = bgr_from_rgba(base_rgba)
    proc_bgr:  ImageBGR  = spt_vignette_and_color(
                               img=base_bgr,
                               vignette_strength=0.35,
                               warm_strength=0.10
                           )

    rng = random.Random(os.getpid() ^ int(time.time()))
    random_props = {
        "img":            bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "vignette_strength":  abs(max(-0.5, min(0.5, 0.1 * rng.normalvariate(0, 1)))),
        "warm_strength":      abs(max(-0.5, min(0.5, 0.1 * rng.normalvariate(0, 1)))),
    }
    demos = {
        "BASELINE": base_rgba,
        "RANDOM":   rgb_from_bgr(spt_vignette_and_color(**random_props)),
    }

    default_props = {"img": base_bgr,}
    demo_set = [
        {"vignette_strength": 0.00, "warm_strength": 0.00},
        {"vignette_strength": 0.10, "warm_strength": 0.00},
        {"vignette_strength": 0.20, "warm_strength": 0.00},
        {"vignette_strength": 0.30, "warm_strength": 0.00},
        {"vignette_strength": 0.40, "warm_strength": 0.00},
        {"vignette_strength": 0.10, "warm_strength": 0.10},
        {"vignette_strength": 0.10, "warm_strength": 0.20},
    ]
    for custom_props in demo_set:
        title = (
            f"Postoptica vignette x warmth: {float(custom_props['vignette_strength']):.1f} x "
            f"{float(custom_props['warm_strength']):.1f}"
        )
        print(title)
        demos[title] = rgb_from_bgr(
            spt_vignette_and_color(**{**default_props, **custom_props})
        )

    show_RGBx_grid(demos, n_columns=4)


if __name__ == "__main__":
    main()

``` 
 
===== END spt_color.py ===== 
 
===== START spt_config.py ===== 
```python 
# Define flag to control non-interactive execution of matpllotlib
BATCH_MODE = True
``` 
 
===== END spt_config.py ===== 
 
===== START spt_correction_engine.py ===== 
```python 
"""
spt_correction_engine.py
------------------------

Ref: https://chatgpt.com/c/69172a6a-b78c-8326-b080-7b02e61b4730

Camera-Like Correction Engine (Internal RGB-Float ISP Simulator)
===============================================================

This module implements a self-contained, physically-motivated camera
simulation pipeline ("Correction Engine") designed to inject the kinds
of imperfections, artifacts, and statistics that are present in real
laboratory photographs acquired using smartphones or compact cameras.

The engine operates entirely in RGB float32 linear space [0, 1], which
matches the internal domain of real imaging pipelines. The output is
also RGB float32. Only the JPEG simulation temporarily converts to
uint8/BGR for encoding.

The goal is to ensure that synthetic images produced by rendering
systems (e.g., Matplotlib, synthetic textures, geometric overlays) will
exhibit realistic photographic traces - including optical distortions,
CFA/demosaicing artifacts, sensor noise, ISP processing, color
characteristics, tone mapping, and JPEG quantization - so that forensic
tools and ML pipelines cannot easily distinguish real lab photos from
synthetic data.

Pipeline Overview
-----------------

The Correction Engine consists of the following sequential stages:

1. Optical Lens Model
   - Radial distortion (barrel/pincushion)
   - Rolling-shutter geometric skew
   - (Extensible to chromatic aberration or PSF blurring)

2. CFA & Demosaicing Simulation
   - Convert RGB into virtual Bayer RAW (RGGB)
   - Apply bilinear / Bayer demosaicing
   - Introduces zippering, color moire, and channel-correlated artifacts

3. Sensor Pattern Noise (ISO-dependent)
   - PRNU: pixel-level multiplicative gain variations
   - FPN: row/column banding patterns
   - Proper ISO scaling factors

4. Shot Noise + Read Noise
   - Brightness-dependent Poisson-like noise
   - Additive Gaussian read noise
   - Correct linear-RGB distribution

5. ISP Denoising + Sharpening
   - Bilateral denoiser (approximates smartphone denoise)
   - Unsharp mask halo formation (edge overshoot/undershoot)

6. Tone Mapping
   - Global tone-mapping (Reinhard or filmic/Hable)
   - Optional S-curve local contrast "pop"

7. Vignetting & Color Tone
   - Optical falloff simulated via radial mask
   - Mild color warmth/bias (e.g. phone LED tint)

8. JPEG Simulation (optional)
   - Roundtrip through JPEG at configurable quality
   - Introduces DCT blocking, grid patterns, and quantization ghosts

Design Notes
------------

- All steps operate in linear RGB, not sRGB. Real photon noise, PRNU,
  and demosaicing must be applied before gamma/tone curves.

- The engine is parameterized via `CameraProfile`, allowing different
  "personalities": smartphone-like, compact-camera-like, noisy, clean,
  etc.

- Every stage can be disabled by setting its coefficients to zero
  (e.g. vignette_strength=0, tone_strength=0, base_prnu_strength=0,
  or iso_level=0).

- This module is intentionally modular: adding PSF blur, chromatic
  aberration, local tone mapping, or more sophisticated denoisers is
  straightforward.

"""

from __future__ import annotations

__all__ = ["apply_camera_model", "correction_set_factory",]

import os
import sys
import time
from dataclasses import dataclass
from numbers import Real
import random
from types import MappingProxyType
from typing import Literal, Optional

import numpy as np
import cv2
from skimage.util import random_noise

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.sep.join(os.path.abspath(__file__).split(os.sep)[:-2]))

import matplotlib as mpl
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

# ---------------------------------------------------------------------------
# Local imports (type aliases from your mpl_utils)
# ---------------------------------------------------------------------------

from utils.rng import RNG, get_rng
from utils.logging_utils import configure_logging

from mpl_utils import (
    # Conversion helpers
    bgr_from_rgba, rgb_from_bgr, rgbf_from_rgba, rgb_from_rgbf,
    # Rendering helpers
    show_RGBx_grid, render_scene,
    # Type aliases
    ImageBGR, ImageRGB, ImageRGBA, ImageRGBx,
    # Constants
    PAPER_COLORS,
)

# ---------------------------------------------------------------------------
# Constants and type aliases
# ---------------------------------------------------------------------------

EPSILON: float = 1e-8

CameraKind = ["default", "base", "smartphone", "compact"]
ToneMode = ["reinhard", "filmic"]


# ---------------------------------------------------------------------------
# Ranges for all parameters (from the master table)
# ---------------------------------------------------------------------------
PARAM_RANGES = {
    "k1"                 : (-0.20, 0.20),
    "k2"                 : (-0.02, 0.02),
    "rolling_strength"   : (-0.03, 0.03),  

    # Sensor noise
    "base_prnu_strength" : (0, 0.02),
    "base_fpn_row"       : (0, 0.03),
    "base_fpn_col"       : (0, 0.03),
    "base_read_noise"    : (0, 0.002),
    "base_shot_noise"    : (0, 0.02),

    # ISP
    "denoise_strength"   : (0, 1.0),
    "blur_sigma"         : (0, 0.4),
    "sharpening_amount"  : (0, 1.0),

    # Tone
    "tone_strength"      : (0, 0.50),
    "scurve_strength"    : (0, 1.00),

    # Vignette + color
    "vignette_strength"  : (0, 0.50),
    "color_warmth"       : (-0.1, 0.10),

    # JPEG
    "jpeg_quality"       : (70, 100),

    # ISO
    "iso_level"          : (0.5, 2.0),
}


@dataclass
class CameraProfile:
    """Camera-like behavior configuration.

    Attributes:
        kind: Camera category ('smartphone' or 'compact').
        base_prnu_strength: Base multiplicative per-pixel PRNU amplitude.
        base_fpn_row: Row-wise fixed-pattern noise amplitude.
        base_fpn_col: Column-wise fixed-pattern noise amplitude.
        base_read_noise: Additive read noise (std) in linear RGB domain.
        base_shot_noise: Base scale for brightness-dependent shot noise.
        denoise_strength: Scaling factor for strength and smoothness of denoising.
        blur_sigma: Unsharpen radius control.
        sharpening_amount: Unsharp-mask strength for ISP sharpening.
        tone_strength: Base tone-mapping strength (0=off, 1=strong compression).
        scurve_strength: S-curve contrast strength (0=off, 1=strong).
        tone_mode: Tone-mapping mode ('reinhard' or 'filmic').
        vignette_strength: Vignetting strength (center-to-edge).
        color_warmth: Warm bias, positive shifts towards warmer tones.
        jpeg_quality: JPEG quality for optional roundtrip (higher = less compressed).
    """

    kind              : str      = "base"
    base_prnu_strength: float    = 0
    base_fpn_row      : float    = 0
    base_fpn_col      : float    = 0
    base_read_noise   : float    = 0
    base_shot_noise   : float    = 0
    denoise_strength  : float    = 0
    blur_sigma        : float    = 0
    sharpening_amount : float    = 0
    tone_strength     : float    = 0
    scurve_strength   : float    = 0
    tone_mode         : ToneMode = ""
    vignette_strength : float    = 0
    color_warmth      : float    = 0
    jpeg_quality      : int      = 100


DEFAULT_PROFILE: CameraProfile = CameraProfile(
    kind="default",
    base_prnu_strength=0,
    base_fpn_row=0,
    base_fpn_col=0,
    base_read_noise=0, 
    base_shot_noise=0,  
    denoise_strength=0,
    blur_sigma=0,
    sharpening_amount=0,
    tone_strength=0,
    scurve_strength=0,
    tone_mode="",
    vignette_strength=0,
    color_warmth=0,
    jpeg_quality=100,
)

BASE_PROFILE: CameraProfile = CameraProfile(
    kind="base",
    base_prnu_strength=0,
    base_fpn_row=0,
    base_fpn_col=0,
    base_read_noise=0, 
    base_shot_noise=0,  
    denoise_strength=0,
    blur_sigma=0,
    sharpening_amount=0,
    tone_strength=0,
    scurve_strength=0,
    tone_mode="",
    vignette_strength=0,
    color_warmth=0,
    jpeg_quality=100,
)

SMARTPHONE_PROFILE: CameraProfile = CameraProfile(
    kind="smartphone",
    base_prnu_strength=0.003,
    base_fpn_row=0.002,
    base_fpn_col=0.002,
    base_read_noise=0.002,  # low
    base_shot_noise=0.01,  # medium
    denoise_strength=0.6,
    blur_sigma=1,
    sharpening_amount=0.6,
    tone_strength=0.55,
    scurve_strength=0.25,
    tone_mode="filmic",
    vignette_strength=0.3,
    color_warmth=0.1,
    jpeg_quality=88,
)

COMPACT_PROFILE: CameraProfile = CameraProfile(
    kind="compact",
    base_prnu_strength=0.004,
    base_fpn_row=0.003,
    base_fpn_col=0.003,
    base_read_noise=0.003,  # slightly higher
    base_shot_noise=0.012,
    denoise_strength=0.4,
    blur_sigma=1,
    sharpening_amount=0.4,
    tone_strength=0.35,
    scurve_strength=0.15,
    tone_mode="reinhard",
    vignette_strength=0.2,
    color_warmth=0.05,
    jpeg_quality=90,
)

CAMERA_PROFILES: MappingProxyType = MappingProxyType({
    "default"   : DEFAULT_PROFILE,
    "base"      : BASE_PROFILE,
    "smartphone": SMARTPHONE_PROFILE,
    "compact"   : COMPACT_PROFILE,
})


def get_camera_profile(kind: str) -> str:
    """Return camera profile for a given camera kind."""
    key = str(kind).strip().lower()
    camera_profile = CAMERA_PROFILES.get(key)
    if camera_profile is None:
        raise ValueError(f"Unknown camera kind: {kind!r}")
    return camera_profile


# ---------------------------------------------------------------------------
# Utility conversion
# ---------------------------------------------------------------------------

def rescale_imgf(img_f: ImageRGBF, *a, **kw) -> ImageRGBF:
    """Exposure-preserving replacement for np.clip(img, 0.0, 1.0)."""
    mn, mx = float(img_f.min()), float(img_f.max())
    if mn >= 0 and mx <= 1:
        return img_f
    
    if mn < 0 and (mx - mn) <= 1:
        return img_f + mn

    return (img_f + mn) / (mx - mn)


def uint8_from_float32(img_f: ImageRGBF | ImageBGRF) -> ImageRGB | ImageBGR:
    """Convert RGB/BGR float32 in [0, 1] to RGB/BGR uint8 with rounding."""
    return (rescale_imgf(img_f) * 255.0 + 0.5).astype(np.uint8)


def normal3s(sf=1, rng=None):
    if rng is None:
        rng = random.Random()
    return sf * max(-1, min(1, rng.normalvariate(0, 1/3)))


def normal3sp(sf=1, rng=None):
    if rng is None:
        rng = random.Random()
    return sf *  min(1, abs(rng.normalvariate(0, 1/3)))


# ---------------------------------------------------------------------------
# Lens Model Injection: radial distortion + rolling shutter
# ---------------------------------------------------------------------------

def radial_distortion(img: ImageRGBF, k1: float, k2: float = 0.0) -> ImageRGBF:
    """Apply simple radial lens distortion in RGB float space.

    Disable effect by setting k1=0 and k2=0.

    Args:
        img: Input image in RGB float [0, 1], shape (H, W, 3).
        k1: Quadratic radial distortion coefficient.
        k2: Quartic radial distortion coefficient.

    Returns:
        Distorted image, RGB float [0, 1].
    """
    if abs(k1) < EPSILON and abs(k2) < EPSILON:
        return img

    h, w = img.shape[:2]
    yy, xx = np.indices((h, w), dtype=np.float32)
    x = (xx - w / 2.0) / (w / 2.0)
    y = (yy - h / 2.0) / (h / 2.0)
    r2 = x * x + y * y

    radial = 1.0 + k1 * r2 + k2 * r2 * r2
    x_dist = x * radial
    y_dist = y * radial

    map_x = (x_dist * (w / 2.0) + w / 2.0).astype(np.float32)
    map_y = (y_dist * (h / 2.0) + h / 2.0).astype(np.float32)

    warped = cv2.remap(uint8_from_float32(img), map_x, map_y,
                  interpolation=cv2.INTER_LINEAR,
                  borderMode=cv2.BORDER_CONSTANT,
                  borderValue=(255, 255, 255))
    return warped.astype(np.float32) / 255.0


def rolling_shutter_skew(img: ImageRGBF, strength: float = 0.0) -> ImageRGBF:
    """Apply vectorized rolling-shutter-like horizontal skew in RGB float.

    Disable effect by setting strength=0.

    Args:
        img: RGB float image in [0, 1].
        strength: Horizontal skew fraction, e.g. 0.03.
                  Positive -> bottom shifts right, negative -> left.

    Returns:
        Skewed RGB float image.
    """
    if abs(strength) < EPSILON:
        return img

    h, w = img.shape[:2]
    # Per-row fractional shift
    y = np.linspace(0.0, 1.0, h, dtype=np.float32)
    shift_x = (strength * y * w).astype(np.float32)  # shape (H,)

    xx, yy = np.meshgrid(
        np.arange(w, dtype=np.float32),
        np.arange(h, dtype=np.float32),
    )
    map_x = xx + shift_x[:, None]
    map_y = yy

    warped = cv2.remap(uint8_from_float32(img), map_x, map_y,
                 interpolation=cv2.INTER_LINEAR,
                 borderMode=cv2.BORDER_REFLECT,
             )
    return warped.astype(np.float32) / 255.0


# ---------------------------------------------------------------------------
# CFA + Sensor noise: PRNU + FPN + shot/read noise (ISO-dependent) + Demosaicing
# ---------------------------------------------------------------------------
def cfa_sensor_noise_demosaic(
        img: ImageRGBF,
        profile: CameraProfile,
        iso_level: float,
        rng: np.random.Generator,
    ) -> ImageRGBF:
    """
    Simulate realistic Bayer CFA sampling + RAW-domain noise + demosaicing.
    Produces correct chromatic noise, zippering, and color moire.

    Args:
        img: RGB float in [0,1].
        profile: CameraProfile (for PRNU/FPN/shot/read).
        iso_level: numeric ISO factor.
        rng: NumPy Generator.

    Returns:
        Demosaiced RGB float32 in [0,1].
    """
    if profile.kind == "default":
        return img

    # ----------------------------------------------------------------------
    # 0) Convert to uint8 RAW domain
    # ----------------------------------------------------------------------
    img_u8 = uint8_from_float32(img)
    h, w, _ = img_u8.shape

    # Split R,G,B
    R = img_u8[..., 0]
    G = img_u8[..., 1]
    B = img_u8[..., 2]

    # ----------------------------------------------------------------------
    # 1) Create RGGB Bayer pattern
    # ----------------------------------------------------------------------
    mosaic = np.zeros((h, w), dtype=np.float32)

    mosaic[0::2, 0::2] = R[0::2, 0::2]       # R
    mosaic[0::2, 1::2] = G[0::2, 1::2]       # G
    mosaic[1::2, 0::2] = G[1::2, 0::2]       # G
    mosaic[1::2, 1::2] = B[1::2, 1::2]       # B

    # Scale to float32 [0,1] RAW domain
    mosaic = mosaic.astype(np.float32) / 255.0

    # ----------------------------------------------------------------------
    # 2) ISO factor
    # ----------------------------------------------------------------------
    if isinstance(iso_level, Real):
        iso_factor = float(np.clip(abs(iso_level), 0.0, 3.0))
    else:
        iso_factor = 1.0

    # ----------------------------------------------------------------------
    # 3) RAW-domain PRNU (multiplicative per-pixel)
    # ----------------------------------------------------------------------
    if profile.base_prnu_strength > 0:
        sigma = profile.base_prnu_strength * iso_factor
        prnu = 1.0 + rng.normal(loc=0.0, scale=sigma, size=(h, w)).astype(np.float32)
        mosaic *= prnu

    # ----------------------------------------------------------------------
    # 4) RAW-domain FPN (row + column patterns)
    # ----------------------------------------------------------------------
    if profile.base_fpn_row > 0:
        sigma = profile.base_fpn_row * iso_factor
        row_pattern = rng.normal(loc=0.0, scale=sigma, size=(h, 1)).astype(np.float32)
        mosaic *= (1.0 + row_pattern)

    if profile.base_fpn_col > 0:
        sigma = profile.base_fpn_col * iso_factor
        col_pattern = rng.normal(loc=0.0, scale=sigma, size=(1, w)).astype(np.float32)
        mosaic *= (1.0 + col_pattern)

    # ----------------------------------------------------------------------
    # 5) RAW-domain shot noise (Poisson-like)
    # ----------------------------------------------------------------------
    if profile.base_shot_noise > 0:
        sigma = profile.base_shot_noise * iso_factor
        shot_std = sigma * np.sqrt(np.clip(mosaic, 0, 1))
        mosaic += shot_std * rng.normal(0.0, 1.0, size=mosaic.shape).astype(np.float32)

    # ----------------------------------------------------------------------
    # 6) RAW-domain read noise (additive)
    # ----------------------------------------------------------------------
    if profile.base_read_noise > 0:
        sigma = profile.base_read_noise * iso_factor
        mosaic += rng.normal(0.0, sigma, size=mosaic.shape).astype(np.float32)

    # Clamp RAW before demosaic
    # mosaic = np.clip(mosaic, 0.0, 1.0)
    mosaic = rescale_imgf(mosaic)

    # ----------------------------------------------------------------------
    # 7) Demosaic (OpenCV Bayer RGGB -> BGR)
    # ----------------------------------------------------------------------
    mosaic_u8 = (mosaic * 255.0 + 0.5).astype(np.uint8)
        
    # NOTE: cv2.COLOR_BayerRG2BGR returns RGB, not BGR
    rgb = cv2.cvtColor(mosaic_u8, cv2.COLOR_BayerRG2BGR).astype(np.float32) / 255.0
    return rgb


# ---------------------------------------------------------------------------
# CFA & Demosaicing
# ---------------------------------------------------------------------------

def cfa_and_demosaic(img: ImageRGBF) -> ImageRGBF:
    """Simulate Bayer CFA and demosaicing to introduce CFA artifacts.

    Args:
        img: RGB float [0, 1].

    Returns:
        Demosaiced RGB float [0, 1].
    """
    img_u8 = uint8_from_float32(img)

    h, w, _ = img_u8.shape
    R = img_u8[..., 0]
    G = img_u8[..., 1]
    B = img_u8[..., 2]

    # RGGB CFA pattern
    mosaic = np.zeros((h, w), dtype=np.uint8)
    # R at (0,0) modulo 2
    mosaic[0::2, 0::2] = R[0::2, 0::2]
    # G at (0,1) and (1,0)
    mosaic[0::2, 1::2] = G[0::2, 1::2]
    mosaic[1::2, 0::2] = G[1::2, 0::2]
    # B at (1,1)
    mosaic[1::2, 1::2] = B[1::2, 1::2]

    # NOTE: cv2.COLOR_BayerRG2BGR returns RGB, not BGR
    rgb_dm = cv2.cvtColor(mosaic, cv2.COLOR_BayerRG2BGR).astype(np.float32) / 255.0
    return rgb_dm

# ---------------------------------------------------------------------------
# Sensor noise: PRNU + FPN + shot/read noise (ISO-dependent)
# ---------------------------------------------------------------------------

def sensor_noise(
        img: ImageRGBF,
        profile: CameraProfile,
        iso_level: float,
        rng: np.random.Generator,
    ) -> ImageRGBF:
    """Add sensor-like noise (PRNU, FPN, shot, read) in RGB float space."""
    h, w, _ = img.shape
    seed = os.getpid() ^ (time.time_ns() & 0xFFFFFFFF) ^ random.getrandbits(32)
    np.random.seed(seed)

    # ISO scaling factor
    if isinstance(iso_level, Real):
        iso_factor = float(np.clip(abs(iso_level), 0.0, 3.0))

    if iso_factor < EPSILON:
        # All noise effectively off
        return img

    img = rescale_imgf(img.astype(np.float32))

    # ---------------------------------------------------------------
    # PRNU  (multiplicative gain variation)
    # ---------------------------------------------------------------
    base_prnu = profile.base_prnu_strength
    if base_prnu > EPSILON:
        prnu_sigma = base_prnu * iso_factor

        prnu_field = random_noise(
            np.zeros((h, w), dtype=np.float32), mode="gaussian", mean=0.0,
            var=prnu_sigma**2).astype(np.float32)
        # Convert Gaussian(0,sugma) -> multiplicative gain around 1.0
        prnu_map = (1.0 + prnu_field)[..., None]

        # prnu_map = rng.normal(loc=1.0, scale=prnu_sigma, size=(h, w, 1)).astype(np.float32)
    else:
        prnu_map = np.ones((h, w, 1), dtype=np.float32)
    
    # ---------------------------------------------------------------
    # FPN - Row and Column pattern noise (multiplicative)
    # ---------------------------------------------------------------
    base_fpn_row = profile.base_fpn_row
    base_fpn_col = profile.base_fpn_col

    # Row FPN
    if base_fpn_row > EPSILON:
        fpn_row_sigma = base_fpn_row * iso_factor
        row_field = random_noise(
            np.zeros((h, 1), dtype=np.float32), mode="gaussian", mean=0.0,
            var=fpn_row_sigma**2).astype(np.float32)

        # row_pattern = rng.normal(loc=0.0, scale=fpn_row_sigma, size=(h, 1, 1)).astype(np.float32)
    else:
        row_field = np.zeros((h, 1), dtype=np.float32)

    # Column FPN
    if base_fpn_col > EPSILON:
        fpn_col_sigma = base_fpn_col * iso_factor
        col_field = random_noise(
            np.zeros((1, w), dtype=np.float32), mode="gaussian", mean=0.0,
            var=fpn_col_sigma**2).astype(np.float32)

        # col_pattern = rng.normal(loc=0.0, scale=fpn_col_sigma, size=(1, w, 1)).astype(np.float32)
    else:
        col_field = np.zeros((1, w), dtype=np.float32)

    fpn = 1.0 + row_field[:, :, None] + col_field[:, :, None]

    # fpn = 1.0 + row_pattern + col_pattern
    
    # ---------------------------------------------------------------
    # Combine multiplicative effects first
    # ---------------------------------------------------------------
    base = img * prnu_map * fpn

    # ---------------------------------------------------------------
    # Shot noise (brightness-dependent) - additive
    # ---------------------------------------------------------------
    if profile.base_shot_noise > EPSILON:
        shot_sigma = profile.base_shot_noise * iso_factor
 
        shot_stddev = shot_sigma * np.sqrt(rescale_imgf(base))

        shot_field = random_noise(
            np.zeros((h, w), dtype=np.float32), mode="gaussian", mean=0.0, var=1.0
            ).astype(np.float32)
        # Scale Gaussian by per-pixel stddev
        shot_noise = (shot_stddev[..., None] * shot_field[..., None])

        # shot_noise = shot_stddev * rng.normal(loc=0.0, scale=1.0, size=base.shape).astype(np.float32)
    else:
        shot_noise = np.zeros_like(base, dtype=np.float32)

    # ---------------------------------------------------------------
    # Read noise - additive, constant variance
    # ---------------------------------------------------------------
    if profile.base_read_noise > EPSILON:
        read_sigma = profile.base_read_noise * iso_factor

        read_field = random_noise(
            np.zeros((h, w), dtype=np.float32), mode="gaussian", mean=0.0,
            var=read_sigma**2).astype(np.float32)
        read_noise = read_field[..., None]
        
        
        # read_noise = rng.normal(0.0, read_sigma, size=base.shape).astype(np.float32)
    else:
        read_noise = np.zeros_like(base, dtype=np.float32)

    # ---------------------------------------------------------------
    # Combine
    # ---------------------------------------------------------------
    noisy = base + shot_noise + read_noise
    return rescale_imgf(noisy)


# ---------------------------------------------------------------------------
# ISP Denoising & Sharpening
# ---------------------------------------------------------------------------

def isp_denoise_and_sharpen(img: ImageRGBF, profile: CameraProfile) -> ImageRGBF:
    """
    ISP processing stage: denoising (bilateral) + unsharp-mask sharpening.

    Controls:
        denoise_strength: 0..1 - more = stronger noise reduction & smoothing
        blur_sigma:       0.5..3 - radius of unsharp-mask blur kernel
        sharpening_amount:0..1 - strength of sharpening (halos)
    """

    img_u8 = uint8_from_float32(img)

    # ---- 1. Bilateral denoising -------------------------------------------
    ds = profile.denoise_strength
    if ds > EPSILON:
        # Kernel diameter: 5..15 px
        d = int(np.clip(5 + ds * 20, 5, 25))

        # Color sigma: 10..60
        sigmaColor = float(10 + ds * 50)

        # Spatial sigma: 2..14
        sigmaSpace = float(2 + ds * 12)

        den = cv2.bilateralFilter(img_u8, d=d, sigmaColor=sigmaColor,
                                  sigmaSpace=sigmaSpace)
        img_f = den.astype(np.float32) / 255.0
    else:
        img_f = img  # no denoising

    # ---- 2. Sharpening -----------------------------------------------------
    sharp_amt = profile.sharpening_amount
    if sharp_amt < EPSILON:
        return rescale_imgf(img_f)

    # Gaussian blur radius (sigma)
    blur_sigma = max(0.1, float(profile.blur_sigma))

    # Unsharp mask
    blur = cv2.GaussianBlur(img_f, (0, 0), sigmaX=blur_sigma)
    sharp = img_f + sharp_amt * (img_f - blur)

    return rescale_imgf(sharp)


# ---------------------------------------------------------------------------
# Tone Mapping Stage
# ---------------------------------------------------------------------------

def tone_map_reinhard(img: ImageRGBF, strength: float) -> ImageRGBF:
    """Reinhard global tone curve. Strength 0..1."""
    if strength <= EPSILON:
        return img
    tone = img / (1.0 + img)
    return img * (1.0 - strength) + tone * strength


def tone_map_filmic(img: ImageRGBF, strength: float) -> ImageRGBF:
    """Hable filmic operator. Strength 0..1."""
    if strength <= EPSILON:
        return img

    a = 0.22
    b = 0.30
    c = 0.10
    d = 0.20
    e = 0.01
    f = 0.30

    def hable(x: np.ndarray) -> np.ndarray:
        return ((x * (a * x + c * b) + d * e) /
                (x * (a * x + b) + d * f) - e / f)

    tone = hable(img)
    tone = rescale_imgf(tone)
    return img * (1.0 - strength) + tone * strength


def tone_scurve(img: ImageRGBF, strength: float) -> ImageRGBF:
    """Local contrast S-curve using tanh. Gives typical 'HDR' pop."""
    if strength <= EPSILON:
        return img
    x = img * 2.0 - 1.0
    y = np.tanh(x * (1.0 + strength * 2.0))
    return rescale_imgf((y + 1.0) * 0.5)


def tone_mapping(img: ImageRGBF, profile: CameraProfile) -> ImageRGBF:
    """Combined tone-mapping stage."""
    tone_strength = profile.tone_strength
    scurve_strength = profile.scurve_strength
    tone_mode = profile.tone_mode
    if tone_mode == "filmic":
        img = tone_map_filmic(img, tone_strength)
    else:
        img = tone_map_reinhard(img, tone_strength)

    img = tone_scurve(img, scurve_strength)
    return rescale_imgf(img)


# ---------------------------------------------------------------------------
# Vignette + color warmth
# ---------------------------------------------------------------------------

def vignette_and_color(img: ImageRGBF, profile: CameraProfile) -> ImageRGBF:
    """Apply vignetting and mild color bias in RGB float32 [0, 1].

    Assumes:
        - img.dtype is np.float32
        - img values are in [0, 1]
        - channel order is RGB (0=R, 1=G, 2=B)
    """
    vignette_strength = float(profile.vignette_strength)
    warm_strength = float(profile.color_warmth)

    # Nothing to do
    if vignette_strength <= 0.0 and abs(warm_strength) <= 0.0:
        return img

    h, w, _ = img.shape

    # Normalized coordinates in [-1, 1]
    cx = 0.5 * (w - 1)
    cy = 0.5 * (h - 1)
    x = (np.arange(w, dtype=np.float32) - cx) / max(cx, 1.0)
    y = (np.arange(h, dtype=np.float32) - cy) / max(cy, 1.0)
    xx, yy = np.meshgrid(x, y)

    # Radial distance, normalized to [0, 1]
    r = np.sqrt(xx * xx + yy * yy)
    r_max = float(r.max())
    r_norm = r / r_max

    # --- Radial masks (float32) ---
    # Quadratic vignette
    vignette_mask = 1.0 - vignette_strength * (r_norm ** 2)

    # Warm/cool masks (for color_warmth)
    if abs(warm_strength) > EPSILON:
        r_pow = r_norm ** 1.2
        warm_mask = 1.0 + warm_strength * r_pow
        cool_mask = 1.0 - 0.5 * warm_strength * r_pow
    else:
        warm_mask = 1.0
        cool_mask = 1.0

    # --- Apply modulation (RGB order) ---
    out = img * vignette_mask[..., None]

    if abs(warm_strength) > 0.0:
        out[..., 0] *= warm_mask   # R channel
        out[..., 2] *= cool_mask   # B channel

    # Stay in float32, just clamp range
    return rescale_imgf(out)


# ---------------------------------------------------------------------------
# JPEG round-trip - injects realistic DCT/blockiness
# ---------------------------------------------------------------------------

def jpeg_roundtrip(img: ImageRGBF, quality: int) -> ImageRGBF:
    """Run image through JPEG encode/decode to add DCT artifacts.

    Args:
        img: RGB float [0, 1].
        quality: JPEG quality (e.g., 85-95).

    Returns:
        RGB float [0, 1] after JPEG roundtrip.
    """
    if quality is None:
        return img

    if not isinstance(quality, (int, float)):
        raise ValueError(f"quality must be numeric! Received: {type(quality).__name__}")
        
    quality = int(quality)
    if quality == 100:
        return img

    bgr = cv2.cvtColor(uint8_from_float32(img), cv2.COLOR_RGB2BGR)
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), int(quality)]
    ok, buf = cv2.imencode(".jpg", bgr, encode_param)
    if not ok:
        raise RuntimeError(f"JPEG encoding failure")
        # Fallback: return original if encoding fails.
        return img

    bgr_jpeg = cv2.imdecode(buf, cv2.IMREAD_COLOR)
    rgb_jpeg = cv2.cvtColor(bgr_jpeg, cv2.COLOR_BGR2RGB)
    return rgb_jpeg.astype(np.float32) / 255.0


# ---------------------------------------------------------------------------
# Correction Settings Factory
# ---------------------------------------------------------------------------

def correction_set_factory(kind: str = "random", seed: int = None) -> dict:
    """
    Generate a randomized correction parameter set for the camera model.

    Behavior:
        - If kind is "default" or "base", returns a zero-effect profile.
        - If kind is "random" or None, all CameraProfile parameters are
          sampled according to PARAM_RANGES and truncated normal sampling
          rules.

    Sampling rules:
        - Parameters whose range crosses zero (lo < 0 < hi) are sampled
          symmetrically via normal3s(), producing signed values.
        - Parameters whose range is strictly non-negative (lo >= 0) are
          amplitudes and are sampled with normal3sp() (positive only).
        - External parameters (k1, k2, rolling_strength, and iso_level)
          are excluded from CameraProfile sampling.

    Returned dict:
        {
            "correction_profile": CameraProfile(...),
            "iso_level": float,
            "k1": float,
            "k2": float,
            "rolling_strength": float,
        }
    """
    if not isinstance(kind, str):
        raise TypeError(f"kind must be a string. Received {type(kind).__name__}.")

    kind = kind.strip().lower()
    if kind in ("default", "base"):
        return {
            "correction_profile": CameraProfile(kind=kind),
            "iso_level": 1.0,
            "k1": 0.0,
            "k2": 0.0,
            "rolling_strength": 0.0,
        }

    if kind != "random":
        raise ValueError(f"Unsupported correction set kind: '{kind}'.")

    # ------------------------
    # Seed logic
    # ------------------------
    if not isinstance(seed, int):
        seed = os.getpid() ^ (time.time_ns() & 0xFFFFFFFF) ^ random.getrandbits(32)

    rng = random.Random(seed)
    rng_np = np.random.default_rng(seed)

    # ------------------------
    # Terms assigned outside CameraProfile ("jpeg_quality" is temporarily removed)
    # ------------------------
    EXTERNAL = {
        "k1", "k2", "rolling_strength", "iso_level", "jpeg_quality"
    }

    # ------------------------
    # Internal CameraProfile keys
    # ------------------------
    profile_keys = [k for k in PARAM_RANGES.keys() if k not in EXTERNAL]

    # ------------------------
    # Sample internal profile terms
    # ------------------------
    sampled_profile = {}

    for key in profile_keys:
        lo, hi = PARAM_RANGES[key]

        if lo < 0 and hi > 0:
            # symmetric range
            sampled_profile[key] = normal3s(hi, rng=rng)
        else:
            # positive amplitude
            sampled_profile[key] = normal3sp(hi, rng=rng)

    # ------------------------
    # Sample jpeg_quality separately
    # ------------------------
    lo, hi = PARAM_RANGES["jpeg_quality"]
    sampled_profile["jpeg_quality"] = rng.randint(lo, hi)

    # Always set tone_mode
    sampled_profile["tone_mode"] = "reinhard"

    # Build CameraProfile
    profile = CameraProfile(kind="base", **sampled_profile)

    # ------------------------
    # External param sampling
    # ------------------------
    result = {
        "correction_profile": profile,
        "iso_level"         : rng.uniform(*PARAM_RANGES["iso_level"]),
        "k1"                : normal3s(PARAM_RANGES["k1"][1], rng=rng),
        "k2"                : normal3s(PARAM_RANGES["k2"][1], rng=rng),
        "rolling_strength"  : normal3s(PARAM_RANGES["rolling_strength"][1], rng=rng),
    }

    return result


# ---------------------------------------------------------------------------
# Correction Engine
# ---------------------------------------------------------------------------

def apply_camera_model(
        img: ImageRGBF,
        correction_profile: CameraProfile = None,
        camera_kind: str = "default",
        iso_level: float = 1,
        k1: float = -0.15,
        k2: float = 0.02,
        rolling_strength: float = 0.03,
        rng: np.random.Generator = None,
    ) -> ImageRGBF:
    """Camera-like correction engine.

    Args:
        img: Input RGB float image in [0, 1].
        camera_kind: 'smartphone' or 'compact'.
        iso_level: numeric ISO factor in [0, 2].
        k1: Primary radial distortion coefficient.
        k2: Secondary radial distortion coefficient.
        rolling_strength: Skew magnitude, e.g. ~0.02-0.05.
        rng: Optional NumPy Generator. If None, a default RNG is created.

    Returns:
        RGB float image in [0, 1] with camera-like artifacts.
    """
    if rng is None:
        rng = np.random.default_rng()

    if correction_profile is None:
        profile = get_camera_profile(camera_kind)
    else:
        profile = correction_profile

    img = rescale_imgf(img.astype(np.float32))

    # 1) Lens geometry in linear RGB
    img = radial_distortion(img, k1=k1, k2=k2)
    img = rolling_shutter_skew(img, strength=rolling_strength)

    # 2) CFA + raw sensor Noise (PRNU + FPN + shot / read) + demosaic
    img = cfa_sensor_noise_demosaic(img, profile=profile, iso_level=iso_level, rng=rng)
    
    # 3) ISP denoise + sharpening
    img = isp_denoise_and_sharpen(img, profile=profile)

    # 4) Tone mapping
    img = tone_mapping(img, profile)

    # 5) Vignette + color bias
    img = vignette_and_color(img, profile=profile)

    # 6) Optional JPEG roundtrip
    if (isinstance(profile.jpeg_quality, (int, float)) and int(profile.jpeg_quality) < 100):
        img = jpeg_roundtrip(img, quality=profile.jpeg_quality)

    return rescale_imgf(img)


# ---------------------------------------------------------------------------
# Demos
# ---------------------------------------------------------------------------

def round_sig(x, sig=3):
    x = float(x)
    if x == 0:
        return 0.0
    return round(x, sig - int(np.floor(np.log10(abs(x)))) - 1)


def demo():
    # ----------------------------------------------------------------------
    base_rgba: ImageRGBA = render_scene()
    base_rgbf: ImageRGBF = rgbf_from_rgba(base_rgba)

    rng = random.Random(os.getpid() ^ int(time.time()))

    img_rnd = rgbf_from_rgba(render_scene(
                  canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                  plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
              ))
    prof = correction_set_factory()
    img_rnd_proc = rgb_from_rgbf(apply_camera_model(img=img_rnd, **prof))

    random_props = {
        "img":            img_rnd,
    }

    demos = {
        "BASELINE": img_rnd,
        "RANDOM"  : img_rnd_proc,
    }

    default_core = {
        # 2) Sensor noise

        "base_prnu_strength": 0, # [0, 0.01]
        "base_fpn_row"      : 0, # [0, 0.01]
        "base_fpn_col"      : 0, # [0, 0.01]
        "base_read_noise"   : 0, # [0, 0.01]
        "base_shot_noise"   : 0, # [0, 0.03]

        # 3) ISP denoise + sharpen

        "denoise_strength"  : 0, # [0, 1]
        "blur_sigma"        : 0, # [0, 3]
        "sharpening_amount" : 0, # [0, 1]

        # 4) Tone mapping
        
        "tone_strength"     : 0, # [0, 1]
        "scurve_strength"   : 0, # [0, 0.5]

        # 5) Vignette + color warmth

        "vignette_strength" : 0, # [0, 0.5]
        "color_warmth"      : 0, # [0, 0.2]

        # 6) JPEG

        "jpeg_quality"      : 100,

    }

    default_extras = {
        "iso_level"         : 1, # [0, 2]
    
        "rolling_strength"  : 0, # [0, 0.05]

        # 1) Lens geometry

        "k1"                : 0, # [-0.2, 0.2]
        "k2"                : 0, # [-0.02, 0.02]
    }

    noise_medium = {param: PARAM_RANGES[param][1] / 2 for param in
        ["base_prnu_strength", "base_fpn_row", "base_fpn_col",
         "base_read_noise", "base_shot_noise"]}

    denoise_medium = {param: PARAM_RANGES[param][1] / 2 for param in
        ["denoise_strength", "blur_sigma", "sharpening_amount"]}

    tone = {param: PARAM_RANGES[param][1] / 2 for param in
        ["tone_strength", "scurve_strength"]}

    # ---------------------------------------------------------------------------
    # Demo Sets
    # ---------------------------------------------------------------------------

    # 1) Lens geometry
    # ----------------
    stepcount = 7
    var1 = "k1"
    k1 = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_extras_k1 = [
        {var1: k1_val}
        for (k1_val,) in
        zip(k1)
    ]
    
    stepcount = 7
    var1 = "k2"
    k2 = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_extras_k2 = [
        {var1: k2_val}
        for (k2_val,) in
        zip(k2)
    ]

    stepcount = 7
    var1 = "rolling_strength"
    rolling_strength = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_extras_rolling_strength = [
        {var1: rolling_strength_val}
        for (rolling_strength_val,) in
        zip(rolling_strength)
    ]
 
    # 2) CFA + Sensor noise + demosaic
    # --------------------------------
    stepcount = 7
    var1 = "base_prnu_strength"
    base_prnu_strength = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_base_prnu_strength = [
        {var1: base_prnu_strength_val}
        for (base_prnu_strength_val,) in
        zip(base_prnu_strength)
    ]

    stepcount = 7
    var1 = "base_fpn_row"
    base_fpn_row = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]
    var2 = "base_fpn_col"
    base_fpn_col = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var2], stepcount)]

    custom_core_base_fpn = [
        {var1: base_fpn_row_val, var2: base_fpn_col_val}
        for (base_fpn_row_val, base_fpn_col_val,) in
        zip(base_fpn_row, base_fpn_col)
    ]

    stepcount = 7
    var1 = "base_read_noise"
    base_read_noise = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_base_read_noise = [
        {var1: base_read_noise_val}
        for (base_read_noise_val,) in
        zip(base_read_noise)
    ]

    stepcount = 7
    var1 = "base_shot_noise"
    base_shot_noise = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_base_shot_noise = [
        {var1: base_shot_noise_val}
        for (base_shot_noise_val,) in
        zip(base_shot_noise)
    ]

    # 3) ISP denoise + sharpen
    # ------------------------
    stepcount = 7
    var1 = "denoise_strength"
    denoise_strength = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_denoise_strength = [
        {var1: denoise_strength_val}
        for (denoise_strength_val,) in
        zip(denoise_strength)
    ]

    stepcount = 7
    var1 = "blur_sigma"
    blur_sigma = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]
    var2 = "sharpening_amount"
    sharpening_amount = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var2], stepcount)]

    custom_core_sharpening = [
        {var1: blur_sigma_val, var2: sharpening_amount_val}
        for (blur_sigma_val, sharpening_amount_val,) in
        zip(blur_sigma, sharpening_amount)
    ]

    # 4) Tone mapping
    # ---------------

    stepcount = 7
    var1 = "tone_strength"
    tone_strength = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]
    var2 = "scurve_strength"
    scurve_strength = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var2], stepcount)]

    custom_core_tone = [
        {var1: tone_strength_val, var2: scurve_strength_val}
        for (tone_strength_val, scurve_strength_val,) in
        zip(tone_strength, scurve_strength)
    ]

    # 5) Vignette + color warmth
    # --------------------------
    stepcount = 7
    var1 = "vignette_strength"
    vignette_strength = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_vignette_strength = [
        {var1: vignette_strength_val}
        for (vignette_strength_val,) in
        zip(vignette_strength)
    ]

    stepcount = 7
    var1 = "color_warmth"
    color_warmth = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_color_warmth = [
        {var1: color_warmth_val}
        for (color_warmth_val,) in
        zip(color_warmth)
    ]

    # 6) JPEG
    # --------------------------
    stepcount = 7
    var1 = "jpeg_quality"
    jpeg_quality = [round_sig(float(val)) for val in np.linspace(*PARAM_RANGES[var1], stepcount)]

    custom_core_jpeg_quality = [
        {var1: jpeg_quality_val}
        for (jpeg_quality_val,) in
        zip(jpeg_quality)
    ]


    # ---------------------------------------------------------------------------
    # Demo Runner
    # ---------------------------------------------------------------------------

    custom_core    = [{}]
    custom_extras  = [{}]
    custom_core_ex = [
        {},
        noise_medium,
        {**noise_medium, **denoise_medium},
        {**noise_medium, **denoise_medium, **tone},
    ][3]

    custom_core   = [
        [{}],
        custom_core_base_prnu_strength,
        custom_core_base_fpn,
        custom_core_base_read_noise,
        custom_core_base_shot_noise,
        custom_core_denoise_strength,
        custom_core_sharpening,
        custom_core_tone,
        custom_core_vignette_strength,
        custom_core_color_warmth,
        custom_core_jpeg_quality,
    ][10]

    custom_extras = [
        [{}],
        custom_extras_k1,
        custom_extras_k2,
        custom_extras_rolling_strength,
    ][0]
    
    if custom_core[0] and custom_extras[0]:
        raise ValueError(f"Both custom_core and custom_extras have params, but only one should.")

    if len(custom_core[0]) > 0:
        for custom_props in custom_core:
            title = []
            for key, val in custom_props.items():
                title.append(f"{key}: {val:<10}")
            print("".join(title))
            title = "\n".join(title)
            demos[title] = rgb_from_rgbf(apply_camera_model(
                img=img_rnd,
                correction_profile=CameraProfile(**{**default_core, **custom_core_ex, **custom_props}),
                **{**default_extras, **custom_extras[0]}
            ))
    else:
        for custom_props in custom_extras:
            title = []
            for key, val in custom_props.items():
                title.append(f"{key}: {val:<10}")
            print("".join(title))
            title = "\n".join(title)
            demos[title] = rgb_from_rgbf(apply_camera_model(
                img=img_rnd,
                correction_profile=CameraProfile(**{**default_core, **custom_core_ex, **custom_core[0]}),
                **{**default_extras, **custom_props}
            ))

 
    show_RGBx_grid(demos, n_columns=4)


# ---------------------------------------------------------------------------
# Interactive Demo
# ---------------------------------------------------------------------------
if __name__ == "__main__":
    demo()
  
``` 
 
===== END spt_correction_engine.py ===== 
 
===== START spt_correction_engine_random.py ===== 
```python 
"""
spt_correction_engine_random.py
--------------------------------

Ref: https://chatgpt.com/c/69172a6a-b78c-8326-b080-7b02e61b4730

Random Camera Profile Generator + Synthetic Lab Camera Wrapper
==============================================================

This module generates *physically plausible* randomized CameraProfile
objects for use with the spt_correction_engine. All parameters are sampled
within sensible ranges calibrated to real-world smartphones and compact
cameras.

Features:
- Samples *all* optical, sensor, ISP, tone-mapping, and JPEG controls.
- Produces realistic distributions that match real lab-photo statistics.
- Maintains physical interdependencies:
    * High ISO -> more noise, stronger denoise, stronger sharpening + tone
    * High distortion -> slightly stronger vignette
    * High denoise -> reduced sharpening to avoid halos
    * Smartphone profiles tend toward aggressive processing
    * Compact profiles tend toward more neutral rendering
- Enum and boolean values are sampled correctly.
- ISO sampled as continuous float in [0.5, 2.0].

---------------------------------------------------------------------

This module provides two primary high-level APIs:

1. **random_camera_profile()**
   Generates a physically plausible randomized `CameraProfile`, sampling
   all optical, sensor, ISP, tone-mapping, and JPEG parameters from
   calibrated distributions that match real smartphone/compact camera
   behavior.

2. **synthetic_lab_camera()**
   A higher-level wrapper that:
     - Generates a random camera correction_profile
     - Generates random lens parameters (with optional user overrides)
     - Applies the full correction engine (`apply_camera_model`)
     - Returns all metadata as a structured dictionary or JSON

This enables creation of large sets of synthetic laboratory images that
faithfully resemble real captured photographs.

Usage:
    from spt_correction_engine_random import random_camera_profile
    correction_profile = random_camera_profile(kind="smartphone")
"""

from __future__ import annotations
import numpy as np
from dataclasses import dataclass
import random
from numbers import Real
from typing import Literal, Optional

from spt_correction_engine import CameraProfile, ToneMode, CameraKind

__all__ = [
    "random_camera_profile",
    "random_lens_params",
    "synthetic_lab_camera",
]


# ---------------------------------------------------------------------------
# Ranges for all parameters (from the master table)
# ---------------------------------------------------------------------------
PARAM_RANGES = {
    "k1"               : (-0.20, 0.20),
    "k2"               : (-0.02, 0.02),
    "rolling_strength" : (0.0, 0.05),

    # Sensor noise
    "prnu"             : (0.0, 0.010),
    "fpn_row"          : (0.0, 0.010),
    "fpn_col"          : (0.0, 0.010),
    "shot_noise"       : (0.0, 0.030),
    "read_noise"       : (0.0, 0.008),

    # ISP
    "denoise_strength" : (0.0, 1.0),
    "blur_sigma"       : (0.5, 3.0),
    "sharpening_amount": (0.0, 1.0),

    # Tone
    "tone_strength"    : (0.0, 0.80),
    "scurve_strength"  : (0.0, 0.50),

    # Vignette + color
    "vignette_strength": (0.0, 0.50),
    "color_warmth"     : (0.0, 0.20),

    # JPEG
    "jpeg_quality"     : (70, 98),

    # ISO
    "iso_level"        : (0.5, 2.0),
}


# ---------------------------------------------------------------------------
# Physical interaction tuning functions
# ---------------------------------------------------------------------------

def apply_physical_interactions(params, iso: float, k1: float):
    """
    Modify sampled parameters so they exhibit realistic ISP-sensor interactions.
    This ensures distributions match real image statistics.
    """
    if not isinstance(iso, Real):
        raise ValueError(f"Numeric iso must be provided.")
    
    # Noise scales with ISO - commented out as applied by the engine
    # params["base_prnu_strength"] *= iso
    # params["base_fpn_row"] *= iso
    # params["base_fpn_col"] *= iso
    # params["base_shot_noise"] *= iso
    # params["base_read_noise"] *= iso

    # Denoise vs ISO
    params["denoise_strength"] = np.clip(
        params["denoise_strength"] + 0.3 * (iso - 1.0), *PARAM_RANGES["denoise_strength"]
    )

    # Sharpen decreases if denoise is high (avoid watercolor halos)
    ds = params["denoise_strength"]
    params["sharpening_amount"] *= (1.0 - 0.4 * ds)

    # Tone mapping stronger at higher ISO
    params["tone_strength"] = np.clip(
        params["tone_strength"] + 0.2 * (iso - 1.0), *PARAM_RANGES["tone_strength"]
    )

    # S-curve moderate coupling
    params["scurve_strength"] = np.clip(
        params["scurve_strength"] + 0.1 * (iso - 1.0), *PARAM_RANGES["scurve_strength"]
    )

    # Vignette slightly correlates with lens distortion magnitude
    k_norm = min(1.0, abs(k1) / PARAM_RANGES["k1"][1])
    params["vignette_strength"] = np.clip(
        params["vignette_strength"] + 0.05 * k_norm, *PARAM_RANGES["vignette_strength"]
    )

    # Compact cameras tend to be milder overall
    if params["kind"] == "compact":
        params["tone_strength"] *= 0.8
        params["scurve_strength"] *= 0.8
        params["sharpening_amount"] *= 0.7
        params["denoise_strength"] *= 0.9

    return params

# ---------------------------------------------------------------------------
# Main API
# ---------------------------------------------------------------------------

def random_camera_profile(kind: str = None, iso: float = None, k1: float = None,
                          seed: int = None) -> CameraProfile:
    """
    Generate a physically plausible randomized CameraProfile for use with
    apply_camera_model().

    Args:
        kind: "smartphone" or "compact" (random if None).
        seed: Optional RNG seed.

    Returns:
        CameraProfile with randomized parameters.
    """
    rng = random.Random(seed)

    # Pick camera kind
    if kind is None:
        kind = rng.choice(CameraKind)
    else:
        kind = str(kind).lower().strip()

    # Base parameter sampling
    prof_dict = {
        "kind"                : kind,

        # sensor base noise
        "base_prnu_strength"  : rng.uniform(*PARAM_RANGES["prnu"]),
        "base_fpn_row"        : rng.uniform(*PARAM_RANGES["fpn_row"]),
        "base_fpn_col"        : rng.uniform(*PARAM_RANGES["fpn_col"]),
        "base_shot_noise"     : rng.uniform(*PARAM_RANGES["shot_noise"]),
        "base_read_noise"     : rng.uniform(*PARAM_RANGES["read_noise"]),

        # ISP
        "denoise_strength"    : rng.uniform(*PARAM_RANGES["denoise_strength"]),
        "blur_sigma"          : rng.uniform(*PARAM_RANGES["blur_sigma"]),
        "sharpening_amount"   : rng.uniform(*PARAM_RANGES["sharpening_amount"]),

        # tone mapping
        "tone_strength"       : rng.uniform(*PARAM_RANGES["tone_strength"]),
        "scurve_strength"     : rng.uniform(*PARAM_RANGES["scurve_strength"]),
        "tone_mode"           : rng.choice(ToneMode),

        # lens falloff and color
        "vignette_strength"   : rng.uniform(*PARAM_RANGES["vignette_strength"]),
        "color_warmth"        : rng.uniform(*PARAM_RANGES["color_warmth"]),

        # JPEG
        "jpeg_quality"        : rng.randint(*PARAM_RANGES["jpeg_quality"]),
    }

    # Apply physical dependencies
    prof_dict = apply_physical_interactions(prof_dict, iso=iso, k1=k1)

    # Build CameraProfile
    prof = CameraProfile(**prof_dict)
  
    return prof

# ---------------------------------------------------------------------------
# Convenience: generate lens parameters separate from correction_profile
# ---------------------------------------------------------------------------

def random_lens_params(seed: int = None) -> dict:
    rng = random.Random(seed)
    return {
        "k1"              : rng.uniform(*PARAM_RANGES["k1"]),
        "k2"              : rng.uniform(*PARAM_RANGES["k2"]),
        "rolling_strength": rng.uniform(*PARAM_RANGES["rolling_strength"]),
        "iso_level"       : rng.uniform(*PARAM_RANGES["iso_level"]),
    }


# ---------------------------------------------------------------------------
# High-Level Synthetic Lab Camera Wrapper
# ---------------------------------------------------------------------------

# Logging setup
import logging
_logger = logging.getLogger("SPTPipeline")
if not _logger.handlers:
    logging.basicConfig(level=logging.INFO, format="[%(levelname)s] %(message)s")


# ---------------------------------------------------------------------------
# High-Level Synthetic Lab Camera Wrapper
# ---------------------------------------------------------------------------

def synthetic_lab_camera(img, kind: str = None, seed: int = None,
                         rng: np.random.Generator = None,
                         metadata_format: str = "dict",
                         **lens_overrides):
    """
    High-level API: automatically generates a random camera correction_profile,
    lens parameters, and applies the correction engine.

    Args:
        img: RGB float32 image in [0,1].
        kind: Optional camera type ("smartphone" or "compact").
        seed: Optional RNG seed.
        rng: Optional NumPy Generator.
        metadata_format: "dict" (default) or "json".
        **lens_overrides: Optional overrides for k1, k2, rolling_strength.

    Returns:
        Either a dict with structured metadata or JSON string.
    """

    from spt_correction_engine import apply_camera_model

    _logger.info("Generating synthetic camera correction_profile...")

    local_rng = rng if rng is not None else np.random.default_rng(seed)

    lens_params = random_lens_params(seed=seed)
    # Overrides
    for key, val in lens_overrides.items():
        if key in lens_params:
            lens_params[key] = float(val)
    correction_profile = random_camera_profile(
        kind=kind, iso=lens_params["iso_level"], k1=lens_params["k1"], seed=seed)


    _logger.info("Applying camera model...")

    out = apply_camera_model(
        img,
        correction_profile=correction_profile,
        camera_kind=correction_profile.kind,
        iso_level=lens_params["iso_level"],
        k1=lens_params["k1"],
        k2=lens_params["k2"],
        rolling_strength=lens_params["rolling_strength"],
        rng=local_rng,
    )

    meta = {
        "camera_profile": correction_profile.__dict__,
        **lens_params,
    }

    if metadata_format == "json":
        import json
        return out, json.dumps(meta, indent=2)

    return out, meta


if __name__ == "__main__":
    import numpy as _np
    import cv2 as _cv2
    import json as _json
    import time as _time
    from pathlib import Path as _Path

    _outdir = _Path("_sptcam_test")
    _outdir.mkdir(exist_ok=True)

    COLORS = {
        "white": (1.0,1.0,1.0),
        "cornsilk": (1.0,0.972,0.863),
        "ivory": (1.0,1.0,0.941),
        "oldlace": (0.992,0.961,0.902),
        "floralwhite": (1.0,0.98,0.94),
        "whitesmoke": (0.96,0.96,0.96),
    }

    for name, rgb in COLORS.items():
        print(f"\n=== Testing {name} ===")
        dummy = _np.zeros((256,256,3), dtype=_np.float32)
        dummy[...] = rgb

        t0 = _time.time()
        out, meta = synthetic_lab_camera(dummy, seed=123)
        dt = _time.time() - t0
        print(f"Processing time: {dt:.3f}s")

        _cv2.imwrite(str(_outdir/f"{name}_orig.jpg"), (dummy*255).astype(_np.uint8)[:,:,::-1])
        _cv2.imwrite(str(_outdir/f"{name}_proc.jpg"), (out*255).astype(_np.uint8)[:,:,::-1])

        with open(_outdir/f"{name}_meta.json","w") as f:
            _json.dump(meta,f,indent=2)

    print("\nSelf-test completed")

    # --- Forensic analysis report ---
    from fqc import generate_forensic_report  # adjust if needed

    def _patchwise_checks(image):
        H, W, _ = image.shape
        patches = []
        ps = 64
        for y in range(0, H-ps+1, ps):
            for x in range(0, W-ps+1, ps):
                patch = image[y:y+ps, x:x+ps]
                rep_patch = generate_forensic_report(patch)
                m = rep_patch["metrics"]
                patches.append(((y, x), m))
        return patches

    report_path = _outdir / "report.txt"
    with open(report_path, "w") as rep:
        rep.write("Synthetic Camera Forensic Report\n\n")
        for name in COLORS.keys():
            proc_path = _outdir / f"{name}_proc.jpg"
            rep.write(f"=== {name} ===\n")
            try:
                img = _cv2.imread(str(proc_path))[:,:,::-1].astype(_np.float32)/255.0
                rep_dict = generate_forensic_report(img)
                metrics = rep_dict["metrics"]
                rep.write("Full-image metrics:\n")
                for k, v in metrics.items():
                    rep.write(f"  {k}: {v}\n")

                rep.write("\nPatchwise metrics:\n")
                patches = _patchwise_checks(img)
                for (y, x), pm in patches:
                    rep.write(f"  Patch (y={y}, x={x}):\n")
                    for k, v in pm.items():
                        rep.write(f"    {k}: {v}\n")
            except Exception as e:
                rep.write(f"Error: {e}\n")
            rep.write("\n")
``` 
 
===== END spt_correction_engine_random.py ===== 
 
===== START spt_geometry.py ===== 
```python 
"""
spt_geometry.py
-----------
"""

from __future__ import annotations

__all__ = ["spt_geometry",]

import os
import sys
import time
import random
import math
import numpy as np
import cv2
import matplotlib.pyplot as plt

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from mpl_utils import *


def spt_geometry(img: ImageBGR, tilt_x: float = 0.18, tilt_y: float = 0.10,
                 k1: float = -0.25, k2: float = 0.05) -> ImageBGR:
    """
    Apply synthetic camera projection effects: perspective tilt and radial
    lens distortion.
  
    The algorithm simulates two geometric distortions typical of optical imaging
    systems in a simplified pinhole-camera approximation:
  
    1. **Perspective tilt:**  
       A planar projective transform skews the image about its center using
       normalized offsets `tilt_x` and `tilt_y` (fractions of image width and
       height). This emulates off-axis projection or lens-plane tilt, producing
       perspective convergence similar to a tilted camera sensor.
  
    2. **Radial lens distortion:**  
       Each pixel is remapped according to a radial polynomial of normalized
       radius `r` from the optical center:
  
           r' = r * (1 + k1 * r^2 + k2 * r^4)
  
       where negative `k1` values yield barrel (wide-angle) distortion, positive
       values yield pincushion (telephoto) distortion, and `k2` refines the
       curvature roll-off.  
       The normalization ensures that coefficients drawn from a zero-mean normal
       distribution with sigma = 0.25 produce realistic variation magnitudes.
  
    Args:
        img:    Input image (uint8, BGR order).
        tilt_x: Horizontal perspective skew fraction (0 - no tilt).
        tilt_y: Vertical perspective skew fraction (0 - no tilt).
        k1:     Primary radial distortion coefficient.
        k2:     Secondary radial distortion coefficient.
  
    Returns:
        ImageBGR: Image with perspective and lens distortion applied.
    """
    h, w = img.shape[:2]

    # -------------------------------------------------------------
    # 1. Perspective tilt (off-axis projection)
    # -------------------------------------------------------------
    dx, dy = 0.25 * tilt_x * w, 0.25 * tilt_y * h
    src = np.float32([[0, 0], [w, 0], [w, h], [0, h]])
    dst = np.float32([[dx, dy], [w - dx, dy / 2], [w, h], [0, h - dy]])
    H = cv2.getPerspectiveTransform(src, dst)
    persp = cv2.warpPerspective(img, H, (w, h),
                                flags=cv2.INTER_LINEAR,
                                borderMode=cv2.BORDER_CONSTANT,
                                borderValue=(255, 255, 255))

    # -------------------------------------------------------------
    # 2. Radial lens distortion
    # -------------------------------------------------------------
    cx, cy = w / 2.0, h / 2.0
    r_norm = max(w, h)
    xx, yy = np.meshgrid(np.arange(w, dtype=np.float32), np.arange(h, dtype=np.float32))
    x_d, y_d = (xx - cx) / r_norm, (yy - cy) / r_norm
    r2 = x_d * x_d + y_d * y_d
    factor = 1.0 + k1 * r2 + k2 * (r2 ** 2)
    factor = np.where(factor == 0.0, 1.0, factor)  # safety
    x_u, y_u = x_d / factor,  y_d / factor

    map_x = (x_u * r_norm + cx).astype(np.float32)
    map_y = (y_u * r_norm + cy).astype(np.float32)

    distorted = cv2.remap(persp, map_x, map_y,
                          interpolation=cv2.INTER_LINEAR,
                          borderMode=cv2.BORDER_CONSTANT,
                          borderValue=(255, 255, 255))

    return distorted


def main():
    # ----------------------------------------------------------------------
    base_rgba: ImageRGBA = render_scene()
    base_bgr:  ImageBGR  = bgr_from_rgba(base_rgba)
    proc_bgr:  ImageBGR  = spt_geometry(
                               img=base_bgr,
                               tilt_x=0.18,
                               tilt_y=0.10,
                               k1=-0.25,
                               k2=0.05,
                           )

    rng = random.Random(os.getpid() ^ int(time.time()))
    random_props = {
        "img":            bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "tilt_x":         max(-1, min(1, rng.normalvariate(0, 1/3))),
        "tilt_y":         max(-1, min(1, rng.normalvariate(0, 1/3))),
        "k1":             max(-1, min(1, rng.normalvariate(0, 1/3))),
        "k2":             max(-1, min(1, rng.normalvariate(0, 1/3))),
    }
    demos = {
        "BASELINE": base_rgba,
        "RANDOM":   rgb_from_bgr(spt_geometry(**random_props)),
    }

    default_props = {
        "img":            base_bgr,
        "tilt_x":         0,
        "tilt_y":         0,
        "k1":             0,
        "k2":             0,
    }

    demo_set = [
        {"tilt_x":  0.20,  "tilt_y":  0.20},
        {"tilt_x":  0.20,  "tilt_y":  0.40},
        {"tilt_x": -0.80,  "tilt_y":  0.80},
        {"tilt_x":  1.00,  "tilt_y": -1.00},
        {"k1":  0.2,  "k2": 0.05},
        {"k1":  0.5,  "k2": 0.05},
        {"k1":  1.0,  "k2": 0.05},
        {"k1": -0.5,  "k2": 0.05},
        {"k1":  0.1,  "k2": 0.1},
        {"k1":  0.1,  "k2": 0.2},
        {"k1":  0.1,  "k2": 0.5},
        {"k1":  0.1,  "k2": 0.8},
    ]
    for custom_props in demo_set:
        title = ["Optics "]
        for key, val in custom_props.items():
            title.append(f"key: '{key}': val '{val}'")
        title = "".join(title)
        print(title)
        demos[title] = rgb_from_bgr(
            spt_geometry(**{**default_props, **custom_props})
        )

    show_RGBx_grid(demos, n_columns=4)


if __name__ == "__main__":
    main()
``` 
 
===== END spt_geometry.py ===== 
 
===== START spt_lighting.py ===== 
```python 
"""
spt_lighting.py
-----------
"""

from __future__ import annotations

__all__ = ["spt_lighting",]

import os
import sys
import time
import random
import math
import numpy as np

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from mpl_utils import *


def spt_lighting(img: ImageBGR, top_bright: float = 0.0, bottom_dark: float = 0.0,
                 lighting_mode: str = "linear", gradient_angle: float = 90.0,
                 grad_cx: float = 0.0, grad_cy: float = 0.0, brightness: float = 0.0) -> ImageBGR:
    """Apply lighting gradient and global brightness, both symmetric in [-1, 1].
  
    Each parameter uses identical semantics:
        b = -1 -> full black
        b =  0 -> no change
        b = +1  full white

    The gradient linearly interpolates between bottom_dark and top_bright.
    The final global brightness is then applied as a post-bias.

    The algorithm constructs a continuous per-pixel brightness field based on a
    normalized gradient coordinate `u in [0, 1]`, where `u = 0` corresponds to the
    bottom (dark) side and `u = 1` to the top (bright) side of the specified
    lighting direction or radial field. Each endpoint, `bottom_dark` and
    `top_bright`, defines a local brightness bias in the range [-1, 1], interpreted
    symmetrically: negative values darken by scaling the pixel intensity by
    (1 + b), and positive values brighten by linearly reducing the distance to
    white as `I' = I + b * (255 - I)`. The effective local brightness coefficient
    at every pixel is obtained by linear interpolation between these two endpoint
    values, producing a smooth gradient of brightness bias. This field is then
    applied to the input image on a per-pixel basis, and an optional global
    `brightness` adjustment (with identical [-1, 1] semantics) is applied
    afterward to uniformly shift the overall exposure without altering the
    gradient contrast.

    Args:
        img: Input image (uint8, RGB or BGR).
        top_bright: Brightness-style adjustment at gradient top ([-1, 1]).
        bottom_dark: Brightness-style adjustment at gradient bottom ([-1, 1]).
        lighting_mode: "linear" or "radial" gradient pattern.
        gradient_angle: For linear mode, direction in degrees.
        grad_cx, grad_cy: Center offsets (for radial mode).
        brightness: Global brightness adjustment in [-1, 1].
  """
    h, w = img.shape[:2]
    y, x = np.indices((h, w), dtype=np.float32)
    angle_rad = math.radians(gradient_angle)

    # --- Base gradient field u in [0, 1] ---
    if lighting_mode == "linear":
        # "bottom-to-top" convention
        u = (-np.cos(angle_rad) * (x / w) + np.sin(angle_rad) * (y / h))
        u = (u - u.min()) / (u.max() - u.min() + 1e-9)
    else:  # radial
        cx = (0.5 + grad_cx) * w
        cy = (0.5 - grad_cy) * h
        r = np.sqrt((x - cx) ** 2 + (y - cy) ** 2)
        corners = np.array(
            [[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype=np.float32
        )
        r_max = np.max(
            np.sqrt((corners[:, 0] - cx) ** 2 + (corners[:, 1] - cy) ** 2)
        )
        u = np.clip(r / (r_max + 1e-9), 0.0, 1.0)

    # --- Interpolated local brightness adjustment in [-1, 1] ---
    local_brightness = bottom_dark + (top_bright - bottom_dark) * (1 - u)

    img_f = img.astype(np.float32)

    # --- Apply per-pixel brightness (same rule as global brightness) ---
    out = img_f.copy()
    neg_mask = local_brightness < 0
    pos_mask = local_brightness >= 0

    if np.any(neg_mask):
        b_neg = (1.0 + local_brightness[neg_mask])[..., None]
        out[neg_mask] = img_f[neg_mask] * b_neg

    if np.any(pos_mask):
        b_pos = local_brightness[pos_mask][..., None]
        out[pos_mask] = img_f[pos_mask] + b_pos * (255.0 - img_f[pos_mask])

    # --- Global brightness applied after gradient ---
    b = float(np.clip(brightness, -1.0, 1.0))
    if b > 0.0:
        out = out + b * (255.0 - out)
    elif b < 0.0:
        out = out * (1.0 + b)

    return np.clip(out, 0.0, 255.0).astype(np.uint8)


def main():
    # ----------------------------------------------------------------------
    base_rgba: ImageRGBA = render_scene()
    base_bgr:  ImageBGR  = bgr_from_rgba(base_rgba)
    proc_bgr:  ImageBGR  = spt_lighting(
                               img=base_bgr,
                               top_bright=1.1,
                               bottom_dark=0.9,
                               lighting_mode="linear",
                               gradient_angle=90,
                               grad_cx=0,
                               grad_cy=0,
                               brightness=0,
                           )
    rng = random.Random(os.getpid() ^ int(time.time()))
    delta = 1 + max(-1, min(1, 0.25 * rng.normalvariate(0, 1)))
    random_props = {
        "img":            bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "top_bright":     0.5 * delta,
        "bottom_dark":    -0.5 * delta,
        "lighting_mode":  rng.choice(["linear", "radial"]),
        "gradient_angle": rng.randint(-180, 180),
        "grad_cx":        max(-1.5, min(1.5, 0.4 * rng.normalvariate(0, 1))),
        "grad_cy":        max(-1.5, min(1.5, 0.4 * rng.normalvariate(0, 1))),
        "brightness":     max(-0.4 * delta, min(0.4 * delta, 0.2 * rng.normalvariate(0, 1))),
    }
    demos = {
        "BASELINE": base_rgba,
        "RANDOM":   rgb_from_bgr(spt_lighting(**random_props)),
    }

    default_props = {
        "img":            base_bgr,
        "top_bright":     0.0,
        "bottom_dark":    0.0,
        "lighting_mode":  "",
        "gradient_angle": 90,
        "grad_cx":        0,
        "grad_cy":        0,
        "brightness":     0,
    }

    default_props["lighting_mode"] = "linear"    
    demo_set = [
        {"top_bright": +0.0, "bottom_dark": +0.0, "gradient_angle": 90, "brightness": 0.75},
        {"top_bright": +0.1, "bottom_dark": -0.1, "gradient_angle": 90},
        {"top_bright": +0.3, "bottom_dark": -0.7, "gradient_angle": 90},
        {"top_bright": +0.3, "bottom_dark": -0.7, "gradient_angle": 45},
    ]
    for custom_props in demo_set:
        title = (
            f"Linear {int(custom_props['gradient_angle'])}deg x "
            f"{float(custom_props['top_bright']):.1f}x{float(custom_props['bottom_dark']):.1f}"
        )
        print(title)
        demos[title] = rgb_from_bgr(
            spt_lighting(**{**default_props, **custom_props})
        )

    default_props["lighting_mode"] = "radial"
    demo_set = [
        {"top_bright": +0.0, "bottom_dark": +0.0, "grad_cx": 0,   "grad_cy": 0, "brightness": -0.75},
        {"top_bright": +0.5, "bottom_dark": -0.5, "grad_cx": 0,   "grad_cy": 0},
        {"top_bright": +0.5, "bottom_dark": -0.5, "grad_cx": 0.5, "grad_cy": 0.5},
        {"top_bright": +0.5, "bottom_dark": -0.5, "grad_cx": 1,   "grad_cy": 1},
    ]
    for custom_props in demo_set:
        title = (
            f"Radial {float(custom_props['grad_cx']):.1f}x{float(custom_props['grad_cy']):.1f} x "
            f"{float(custom_props['top_bright']):.1f}x{float(custom_props['bottom_dark']):.1f}"
        )
        print(title)
        demos[title] = rgb_from_bgr(
            spt_lighting(**{**default_props, **custom_props})
        )

    show_RGBx_grid(demos, n_columns=4)


if __name__ == "__main__":
    main()
``` 
 
===== END spt_lighting.py ===== 
 
===== START spt_noise.py ===== 
```python 
"""
spt_noise.py
-----------
"""

from __future__ import annotations

__all__ = ["spt_noise",]

import os
import sys
import time
import random
import math
import numpy as np
from skimage import util, exposure, filters
from skimage.util import random_noise

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from mpl_utils import *


def spt_noise(img: ImageBGR,
              poisson: bool = True,      # apply Poisson photon noise
              gaussian: float = 0.2,     # normalized [0-1], - var=(sigma*0.1)^2
              sp_amount: float = 0.0,    # normalized [0-1], - amount=x*0.1
              speckle_var: float = 0.0,  # normalized [0-1], - var=x*0.1
              blur_sigma: float = 0.8,   # normalized [0-1], - sigma=x*10 px
             ) -> ImageBGR:
    """
    Apply combined sensor-domain noise and optical blur models.
    
    The algorithm converts the input image to [0, 1] float and sequentially
    applies several noise processes, each of which can be independently enabled
    or scaled:
    
      - **Poisson (shot noise):** Discrete photon-count fluctuations applied when
        `poisson=True`.
      - **Gaussian (read noise):** Additive white noise with variance
        `(gaussian * 0.1)^2`, giving a practical intensity range of 0-0.05 RMS.
      - **Salt & Pepper:** Impulse noise affecting a random fraction
        `sp_amount * 0.1` of pixels.
      - **Speckle:** Multiplicative noise of variance `speckle_var * 0.1`, modeling
        sensor gain variation.
      - **Blur:** Gaussian blur with sigma = `blur_sigma * 10` pixels applied
        per-channel to simulate optical PSF or focus spread.
    
    All noise operations are performed in the floating [0, 1] domain and the
    result is rescaled and quantized back to uint8 [0, 255].
    
    Args:
        img:         Input image in uint8 BGR format.
        poisson:     Whether to apply photon shot noise.
        gaussian:    Strength of additive white noise (0-1 - var up to 0.01).
        sp_amount:   Fraction of impulse-corrupted pixels (0-1 - up to 0.1).
        speckle_var: Multiplicative noise variance (0-1 - up to 0.1).
        blur_sigma:  Normalized Gaussian blur radius (0-1 - sigma up to 10 px).
    
    Returns:
        ImageBGR: Noisy and blurred image, same shape as input.
    """
    img_f = util.img_as_float(img)
    
    # Sequential noise composition
    if poisson:
        img_f = random_noise(img_f, mode="poisson")
    if gaussian > 0:
        img_f = random_noise(img_f, mode="gaussian", var=(gaussian * 0.1) ** 2)
    if sp_amount > 0:
        img_f = random_noise(img_f, mode="s&p", amount=sp_amount * 0.1)
    if speckle_var > 0:
        img_f = random_noise(img_f, mode="speckle", var=speckle_var * 0.1)
    if blur_sigma > 0:
        img_f = filters.gaussian(img_f, sigma=blur_sigma * 10.0, channel_axis=2)
  
    return util.img_as_ubyte(exposure.rescale_intensity(img_f))


def profile_noise(img: ImageBGR):
    poisson:      bool = True
    gaussian:    float = 0.2
    sp_amount:   float = 0.5
    speckle_var: float = 0.5
    blur_sigma:  float = 0.8

    #        elapsed_ms = (time.perf_counter() - t0) * 1000.0
    t0 = time.perf_counter()
    img_f = util.img_as_float(img)
    t1 = time.perf_counter()
    img_f = random_noise(img_f, mode="poisson")
    t2 = time.perf_counter()
    img_f = random_noise(img_f, mode="gaussian", var=(gaussian * 0.1) ** 2)
    t3 = time.perf_counter()
    img_f = random_noise(img_f, mode="s&p", amount=sp_amount * 0.1)
    t4 = time.perf_counter()
    img_f = random_noise(img_f, mode="speckle", var=speckle_var * 0.1)
    t5 = time.perf_counter()
    img_f = filters.gaussian(img_f, sigma=blur_sigma * 10.0, channel_axis=2)
    t6 = time.perf_counter()

    print(f"To float: {round((t1 - t0) * 1000, 3):6.3f} ms")
    print(f"Poisson:  {round((t2 - t1) * 1000, 3):6.3f} ms")
    print(f"Gaussian: {round((t3 - t2) * 1000, 3):6.3f} ms")
    print(f"S&P:      {round((t4 - t3) * 1000, 3):6.3f} ms")
    print(f"Speckle:  {round((t5 - t4) * 1000, 3):6.3f} ms")
    print(f"Blur:     {round((t6 - t5) * 1000, 3):6.3f} ms")


def main():
    # ----------------------------------------------------------------------
    base_rgba: ImageRGBA = render_scene()
    base_bgr:  ImageBGR  = bgr_from_rgba(base_rgba)
    proc_bgr:  ImageBGR  = spt_noise(
                               img=base_bgr,
                               poisson = True,
                               gaussian = 0.2,
                               sp_amount = 0.0,
                               speckle_var = 0.0,
                               blur_sigma = 0.8,
                           )

    profile_noise(base_bgr)
    
    rng = random.Random(os.getpid() ^ int(time.time()))
    random_props = {
        "img":            bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "poisson":        rng.choice([False, True]),
        "gaussian":       abs(max(-1, min(1, rng.normalvariate(0, 0.2)))),
        "sp_amount":      abs(max(-1, min(1, rng.normalvariate(0, 0.2)))),
        "speckle_var":    abs(max(-1, min(1, rng.normalvariate(0, 0.2)))),
        "blur_sigma":     abs(max(-1, min(1, rng.normalvariate(0, 0.2)))),
    }
    demos = {
        "BASELINE": base_rgba,
        "RANDOM":   rgb_from_bgr(spt_noise(**random_props)),
    }

    noise_off = {
        "img": base_bgr,
        "poisson": False,
        "gaussian": 0,
        "sp_amount": 0,
        "speckle_var": 0,
        "blur_sigma": 0,
    }
    default_props = {
        "img": base_bgr,
        "poisson": True,
        "gaussian": 0.1,
        "sp_amount": 0.1,
        "speckle_var": 0.1,
        "blur_sigma": 0.1,
    }
    dx2 = {
        "img": base_bgr,
        "poisson": True,
        "gaussian": 0.2,
        "sp_amount": 0.2,
        "speckle_var": 0.2,
        "blur_sigma": 0.2,
    }
    dx5 = {
        "img": base_bgr,
        "poisson": True,
        "gaussian": 0.5,
        "sp_amount": 0.5,
        "speckle_var": 0.5,
        "blur_sigma": 0.5,
    }
    demos = {
        **demos,
        "Noise OFF": rgb_from_bgr(spt_noise(**noise_off)),
        "Basic": rgb_from_bgr(spt_noise(**default_props)),
        "dx2": rgb_from_bgr(spt_noise(**dx2)),
        "dx5": rgb_from_bgr(spt_noise(**dx5)),
    }

    show_RGBx_grid(demos, n_columns=4)


if __name__ == "__main__":
    main()
``` 
 
===== END spt_noise.py ===== 
 
===== START spt_pipeline.py ===== 
```python 
"""
spt_pipeline.py
-----------
"""

from __future__ import annotations

import os
import sys
import time
import random

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from mpl_utils import *
from spt_lighting import spt_lighting
from spt_texture  import spt_texture
from spt_noise    import spt_noise
from spt_geometry import spt_geometry
from spt_color    import spt_vignette_and_color


def main():
    clamped_normal = lambda sigma=1, amp=1: max(-amp, min(amp, rng.normalvariate(0, sigma)))
    # ----------------------------------------------------------------------
    # Stage 0. Matplotlib and Background Color
    # ----------------------------------------------------------------------
    rng = random.Random(os.getpid() ^ int(time.time()))
    canvas_bg_idx     = rng.randrange(len(PAPER_COLORS))
    plot_bg_idx       = rng.randrange(len(PAPER_COLORS))
    base_rgba         = render_scene(canvas_bg_idx=canvas_bg_idx, plot_bg_idx=plot_bg_idx)
                      
    stage0_mpl        = bgr_from_rgba(base_rgba)

    # ----------------------------------------------------------------------
    # Stage 1. Lighting
    # ----------------------------------------------------------------------
    delta             = 1 + clamped_normal(0.25)
    top_bright        = 0.5 * delta
    bottom_dark       = -0.5 * delta
    lighting_mode     = rng.choice(["linear", "radial"])
    gradient_angle    = rng.randint(-180, 180)
    grad_cx           = clamped_normal(0.4, 1.5)
    grad_cy           = clamped_normal(0.4, 1.5)
    brightness        = clamped_normal(0.2, 0.5 * delta)
                      
    stage1_lighting   = spt_lighting(stage0_mpl, top_bright, bottom_dark, lighting_mode,
                                     gradient_angle, grad_cx, grad_cy, brightness)

    # ----------------------------------------------------------------------
    # Stage 2. Texture
    # ----------------------------------------------------------------------
    texture_strength  = abs(clamped_normal(0.5, 2))
    texture_scale     = abs(clamped_normal(1.0, 8))
                      
    stage2_texture    = spt_texture(stage1_lighting, texture_strength, texture_scale)

    # ----------------------------------------------------------------------
    # Stage 3. Noise
    # ----------------------------------------------------------------------
    poisson           = rng.choice([False, True])
    gaussian          = abs(clamped_normal(0.2))
    sp_amount         = abs(clamped_normal(0.2))
    speckle_var       = abs(clamped_normal(0.2))
    blur_sigma        = abs(clamped_normal(0.2))
                    
    stage3_noise      = spt_noise(stage2_texture, poisson, gaussian,
                                  sp_amount, speckle_var, blur_sigma)

    # ----------------------------------------------------------------------
    # Stage 4. Geometry
    # ----------------------------------------------------------------------
    tilt_x            = clamped_normal(0.25)
    tilt_y            = clamped_normal(0.25)
    k1                = clamped_normal(0.25)
    k2                = clamped_normal(0.25)
                     
    stage4_geometry   = spt_geometry(stage3_noise, tilt_x, tilt_y, k1, k2)

    # ----------------------------------------------------------------------
    # Stage 5. Color
    # ----------------------------------------------------------------------
    vignette_strength = abs(clamped_normal(0.1, 0.5))
    warm_strength     = abs(clamped_normal(0.1, 0.5))

    stage5_color      = spt_vignette_and_color(stage4_geometry, vignette_strength,
                                               warm_strength)

    demos = {
        "0 - Matplotlib": rgb_from_bgr(stage0_mpl),
        "1 - Lighting":   rgb_from_bgr(stage1_lighting),
        "2 - Texture":    rgb_from_bgr(stage2_texture),
        "3 - Noise":      rgb_from_bgr(stage3_noise),
        "4 - Geometry":   rgb_from_bgr(stage4_geometry),
        "5 - Color":      rgb_from_bgr(stage5_color),
    }

    show_RGBx_grid(demos, n_columns=3)


if __name__ == "__main__":
    main()
``` 
 
===== END spt_pipeline.py ===== 
 
===== START spt_texture.py ===== 
```python 
"""
spt_texture.py
-----------

https://chatgpt.com/c/69120de6-5468-832d-8bff-88120cb94daa
"""

from __future__ import annotations

__all__ = [
    "spt_texture",
    "spt_texture_combined",
    "spt_texture_fibers",
    "spt_texture_fold_crease",
]

import os
import sys
import time
import random
import math
from typing import Union
import numpy as np
# from numba import njit
import cv2

import matplotlib as mpl
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import spt_config
if __name__ == "__main__":
    spt_config.BATCH_MODE = False
else:
    if spt_config.BATCH_MODE:
        # Use a non-interactive backend (safe for multiprocessing workers)
        mpl.use("Agg")
import matplotlib.pyplot as plt

from mpl_utils import *


# ======================================================================
#  Multiplicative "paper texture" modulation with true blur - slow
# ======================================================================
def spt_texture(img: ImageBGR,
                texture_strength: float = 0.12,
                texture_scale: float = 8.0,
               ) -> ImageBGR:
    """
    Apply multiplicative paper-fiber texture modulation before optical effects.
    
    The algorithm generates a smooth random field `N(x, y)` from normally
    distributed noise filtered with a Gaussian kernel of standard deviation
    `texture_scale`. The field is then normalized to [0, 1] and remapped into a
    multiplicative modulation mask:
    
        T(x, y) = 1 + texture_strength * (N(x, y) - 0.5)
    
    where `texture_strength` controls the amplitude of contrast variation and
    `texture_scale` defines the spatial correlation length (fiber coarseness).
    The resulting texture field `T` is applied to the input image
    multiplicatively per pixel and per channel. Values are clipped to the
    [0, 255] range and returned as uint8.
    
    Args:
        img: Input image in uint8 BGR format.
        texture_strength: Amplitude of multiplicative modulation (typ. 0.05-0.3).
        texture_scale: Gaussian blur sigma controlling feature size in pixels.
    
    Returns:
        ImageBGR: Texture-modulated image, same shape as input.
    """
    if texture_strength <= 0 or texture_scale <= 0:
        return img

    h, w = img.shape[:2]

    # --- Generate correlated noise field ---
    noise_field = np.random.randn(h, w).astype(np.float32)
    noise_field = cv2.GaussianBlur(noise_field, (0, 0), texture_scale)

    # --- Normalize to [0, 1] ---
    nf_min, nf_max = float(noise_field.min()), float(noise_field.max())
    noise_norm = (noise_field - nf_min) / (nf_max - nf_min + 1e-9)

    # --- Construct multiplicative texture mask ---
    texture = 1.0 + texture_strength * (noise_norm - 0.5)

    # --- Apply and return ---
    img_f = img.astype(np.float32)
    out = np.clip(img_f * texture[..., None], 0, 255).astype(np.uint8)
    return out


# ======================================================================
#  Box blur - Fast approximation of a 2D blur
# ======================================================================
def _box_blur(img: ImageBGRF, radius: int) -> ImageBGRF:
    """
    Cheap separable box filter using cumulative sums.
    
    Approximates a 2D blur with a box kernel of size (2*radius) in each
    direction, but without explicit convolution loops.

    For a box blur, each pixel is replaced by the average of
    neighbors within +/-radius in x and y. Direct convolution is
    O(H*W*radius^2). Using prefix sums reduces the per-pixel cost
    to O(1) (after one O(H*W) prefix pass).

    """
    if radius <= 0:
        return img

    h, w = img.shape
    pad = radius

    # Horizontal blur
    #   Reflect padding:
    #   tmp shape: (H, W + 2*pad)
    #   Reflect padding means edges reflect the interior, like [3,4] -> [4,3,4,3] etc.
    #   This avoids edge darkening/brightening.
    #
    tmp = np.pad(img, ((0, 0), (pad, pad)), mode="reflect")

    #   Cumulative sum along x:
    #   csum[:, j] = sum of tmp[:, 0..j]
    #   This is the standard trick: you can get the sum over any horizontal
    #   interval [a, b] in O(1) as:
    #   sum[a..b] = csum[b] - csum[a-1]
    #   (basically an integral image along one dimension).
    csum = np.cumsum(tmp, axis=1)

    #   Compute sliding window sums with slicing
    #
    left  = csum[:, :-2 * pad]
    right = csum[:, 2 * pad :]
    horz = (right - left) / (2 * pad)

    #     - csum                is (H, W + 2*pad).
    #     - csum[:, :-2*pad] -> shape (H, W) (all columns except the last 2*pad)
    #     - csum[:, 2*pad:]  -> also shape (H, W) (all columns starting from 2*pad)
    #   
    #   So at column index j (0-based in these slices):
    #     - left[:, j] = csum[:, j]
    #     - right[:, j] = csum[:, j + 2*pad]
    #
    #   Interpretation:
    #   We're looking at a window of width 2*pad between indices (j+1)..(j+2*pad) in tmp.
    #
    #   The average over that window is:
    #     (right - left) / (2 * pad)
    #
    #   So horz is a horizontally blurred version of img (box filter of width 2*pad),
    #   back to shape (H, W).
    #
    #   The "center" alignment is slightly shifted compared to a symmetrical [-pad, +pad]
    #   window, but visually for our use (soft paper noise) that's irrelevant. It's
    #   symmetric enough and cheap.

    # Vertical blur
    tmp = np.pad(horz, ((pad, pad), (0, 0)), mode="reflect")
    csum = np.cumsum(tmp, axis=0)
    top  = csum[:-2 * pad, :]
    bot  = csum[2 * pad :, :]
    vert = (bot - top) / (2 * pad)

    #   Same idea, now vertically:
    #     - horz shape: (H, W)
    #     - Pad vertically: tmp shape (H + 2*pad, W)
    #     - csum over axis=0 (rows)
    #     - top = csum[:-2*pad, :] -> shape (H, W)
    #     - bot = csum[2*pad:, :] -> shape (H, W)
    #   Then:
    #     - vert = (bot - top) / (2 * pad)
    #
    #   For each pixel, this is the average over a vertical window of height 2*pad in
    #   the blurred horizontal image.
    #   Result:
    #     - vert shape (H, W)
    #     - Equivalent to applying a 2D box filter of size (2*pad)x(2*pad) but with:
    #         - Reflect padding
    #         - O(H*W) cost via separable prefix sums
    #   
    #    So _box_blur(img, radius) ~ box_filter(img, kernel_size=2*radius).
    
    return vert


#  Quick preliminary tests did not show any noticable advantage.  
#
#  # ======================================================================  
#  #  Numba - Reflect index i into range [0, n-1] like NumPy 'reflect'.      
#  # ======================================================================  
#  @njit                                                                     
#  def _reflect_index(i: int, n: int) -> int:                                
#      """Reflect index i into range [0, n-1] like NumPy 'reflect'."""       
#      if i < 0:                                                             
#          return -i - 1                                                     
#      if i >= n:                                                            
#          return 2*n - i - 1                                                
#      return i                                                              
#                                                                            
#                                                                            
#  # ======================================================================  
#  #  Numba - Box blur - Fast approximation of a 2D blur                     
#  # ======================================================================  
#  @njit                                                                     
#  def _box_blur_numba(img: np.ndarray, radius: int) -> np.ndarray:          
#      h, w = img.shape                                                      
#      out_h = np.zeros((h, w), dtype=np.float32)                            
#      temp  = np.zeros((h, w), dtype=np.float32)                            
#                                                                            
#      # Horizontal pass                                                     
#      for y in range(h):                                                    
#          for x in range(w):                                                
#              s = 0.0                                                       
#              for k in range(x-radius, x+radius):                           
#                  s += img[y, _reflect_index(k, w)]                         
#              temp[y, x] = s / (2 * radius)                                 
#                                                                            
#      # Vertical pass                                                       
#      for y in range(h):                                                    
#          for x in range(w):                                                
#              s = 0.0                                                       
#              for k in range(y-radius, y+radius):                           
#                  s += temp[_reflect_index(k, h), x]                        
#              out_h[y, x] = s / (2 * radius)                                
#                                                                            
#      return out_h                                                          


# ======================================================================
#  Combined additive + multiplicative paper texture
# ======================================================================
def spt_texture_combined(
        img           : Union[ImageBGR, ImageBGRF],
        *,
        add_strength  : float = 0.04,
        mul_strength  : float = 0.07,
        n_layers      : int   = 3,
        base_radius   : int   = 1,
        seed          : int   = None,
    ) -> [ImageBGR, ImageBGRF]:
    """
    Combined additive + multiplicative paper texture.

    Combined model:
        M(x,y) = mul_strength * N1
        A(x,y) = add_strength  * ADD_SF * N2
        out    = img * (1 + M) + A

    N1, N2 are independent correlated noise fields.
    NOTE: Because practical values are expected to be < 10% / 0.1,
          rescale supplied value by MUL_SF and ADD_SF factors.
    """
    MUL_SF = 0.1
    ADD_SF = 0.1
    if (add_strength <= 0 and mul_strength <= 0) or n_layers <= 0:
        return img

    if img.dtype == np.uint8:
        img_f = img.astype(np.float32) / 255.0
    else:
        img_f = np.clip(img.astype(np.float32), 0, 1)

    h, w = img_f.shape[:2]
    rng = np.random.default_rng(seed)

    # Generate two independent multi-scale noise fields
    def smooth_noise(seed_offset: int):
        acc = np.zeros((h, w), np.float32)
        local_rng = np.random.default_rng(seed + seed_offset if seed is not None else None)
        for i in range(n_layers):
            radius = base_radius * (2 ** i)
            noise = local_rng.normal(0, 1, size=(h, w)).astype(np.float32)
            acc += cv2.GaussianBlur(noise, (0, 0), radius)
            # Note: Quick estimates show now advantage over the library call.
            # acc += _box_blur_numba(noise, radius)
        acc -= acc.mean()
        acc /= (acc.std() or 1.0)
        return acc

    noise_add = smooth_noise(1000)
    noise_mul = smooth_noise(2000)

    # Apply combined texture
    out = img_f
    out = np.clip((out * (1.0 + mul_strength * MUL_SF * noise_mul[..., None])
                              + add_strength * ADD_SF * noise_add[..., None]), 0.0, 1.0)

    if img.dtype == np.uint8:
        return (out * 255).astype(np.uint8)
    else:
        return out


# ======================================================================
#  Paper fiber
# ======================================================================
def spt_texture_fibers(
        img                    : Union[ImageBGR, ImageBGRF],
        *,
        fiber_strength         : float = 0.4,
        fiber_orientation_deg  : float = 0.0,
        sigma_long             : float = 12.0,
        sigma_short            : float = 1.0,
        seed                   : int   = None,
    ) -> Union[ImageBGR, ImageBGRF]:
    """
    Add directional paper fibers via anisotropic blurring of noise.
    
    NOTE: Because practical values are expected to be < 10% / 0.1,
          rescale supplied strength value by FIB_SF factor.    
    """
    FIB_SF = 0.1

    if fiber_strength <= 0:
        return img

    if img.dtype == np.uint8:
        img_f = img.astype(np.float32) / 255.0
    else:
        img_f = img.astype(np.float32)

    h, w = img_f.shape[:2]
    rng = np.random.default_rng(seed)

    # white noise
    noise = rng.normal(0, 1, size=(h, w)).astype(np.float32)

    # Rotate noise so long-blur matches fiber direction
    angle = fiber_orientation_deg
    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
    rot = cv2.warpAffine(noise, M, (w, h), flags=cv2.INTER_LINEAR)

    # Anisotropic blur: long direction + short cross direction
    fib = cv2.GaussianBlur(rot, (0,0), sigmaX=sigma_long, sigmaY=sigma_short)

    # Rotate back
    M2 = cv2.getRotationMatrix2D((w/2, h/2), -angle, 1.0)
    fib = cv2.warpAffine(fib, M2, (w, h), flags=cv2.INTER_LINEAR)

    # Normalize
    fib -= fib.mean()
    fib /= (fib.std() or 1.0)
    fib *= fiber_strength * FIB_SF

    out = img_f + fib[..., None]
    out = np.clip(out, 0.0, 1.0)

    if img.dtype == np.uint8:
        return (out * 255).astype(np.uint8)
    else:
        return out


# ======================================================================
#  Paper fold / crease
# ======================================================================
def spt_texture_fold_crease(
        img       : Union[ImageBGR, ImageBGRF],
        *,
        amplitude : float = 1.0,
        sigma     : float = 12.0,
        seed      : int   = None,
    ) -> Union[ImageBGR, ImageBGRF]:
    """
    Simulate a paper fold by adding a crease line.
    Bright center, slight dark overshoot on sides.
    """
    FOLD_SF = 0.1

    if amplitude <= 0:
        return img

    if img.dtype == np.uint8:
        img_f = img.astype(np.float32) / 255.0
    else:
        img_f = img.astype(np.float32)

    h, w = img_f.shape[:2]
    rng = np.random.default_rng(seed)

    # Random line angle & offset
    angle = rng.uniform(-0.4, 0.4)  # radians
    offset = rng.uniform(-0.3, 0.3)  # relative 0-1

    # Line normal vector pointing left/right
    nx = np.cos(angle)
    ny = np.sin(angle)

    # Coordinates
    y, x = np.mgrid[0:h, 0:w]
    cx, cy = w/2, h/2

    # Distance to crease line
    d = (x - cx) * nx + (y - cy) * ny - offset * max(w, h)

    # Gaussian lobe
    crease = amplitude * FOLD_SF * np.exp(-(d / sigma) ** 2)

    # Slight dark halo beyond the crease
    halo = -0.6 * amplitude * FOLD_SF * np.exp(-((np.abs(d) - sigma*2) / (sigma*3)) ** 2)

    texture = crease + halo
    out = img_f + texture[..., None]
    out = np.clip(out, 0.0, 1.0)

    if img.dtype == np.uint8:
        return (out * 255).astype(np.uint8)
    else:
        return out


# ======================================================================
#  Additive "paper texture" modulation for an existing image
# ======================================================================
def spt_texture_additive(
        img           : Union[ImageBGR, ImageBGRF],
        *,
        add_strength  : float = 0.05,
        n_layers      : int   = 3,
        base_radius   : int   = 1,
        seed          : int   = None,
    ) -> Union[ImageBGR, ImageBGRF]:
    """
    Apply *additive* paper-like brightness texture to an image (OpenCV BGR).

    Employs:
        - Multi-scale multi-radius smooth-noise accumulation
        - Normalization to zero-mean and scaling by add_strength
        - Cumulative-sum box-blur routine
    Adds generated noise field to the input BGR image.

    Args:
        img:
            Input image in BGR uint8 or float32. Value range 0-255 or 0-1.
        add_strength:
            Max absolute additive brightness variation (relative 0-1 scale).
            For uint8 images this corresponds to +/-(255 * add_strength) shifts.
            NOTE: Because practical values are expected to be < 10% / 0.1,
                  rescale supplied value by the ADD_SF factor.
        n_layers:
            Number of noise layers to accumulate (multi-scale).
        base_radius:
            Radius exponent base; actual radii are base_radius * (2**i).
            Example: base_radius=2 -> radii = [2,4,8] for n_layers=3.
        seed:
            RNG seed.

    Returns:
        Image with additive paper modulation, same dtype as input.
    """
    ADD_SF = 0.1
    if add_strength <= 0 or n_layers <= 0:
        return img

    # --- Convert to float in [0,1] -------------------------------------
    if img.dtype == np.uint8:
        img_f = img.astype(np.float32) / 255.0
    else:
        img_f = img.astype(np.float32)
        img_f = np.clip(img_f, 0.0, 1.0)

    h, w = img_f.shape[:2]
    rng = np.random.default_rng(seed)

    # --- Accumulate multi-scale smooth noise field ----------------------
    acc = np.zeros((h, w), dtype=np.float32)

    for i in range(n_layers):
        radius = base_radius * (2 ** i)   # same pattern: 2,4,8,... if base=2
        noise = rng.normal(0.0, 1.0, size=(h, w)).astype(np.float32)
        smooth = _box_blur(noise, radius)
        acc += smooth

    # --- Normalize noise field exactly like generate_paper_texture ------
    acc -= acc.mean()
    acc /= (acc.std() or 1.0)
    acc *= float(add_strength * ADD_SF)

    # --- Apply additive brightness modulation ---------------------------
    # broadcast acc -> (H,W,1), add to all channels
    out = img_f + acc[..., None]
    out = np.clip(out, 0.0, 1.0)

    # --- Convert back to original dtype --------------------------------
    if img.dtype == np.uint8:
        return (out * 255.0).astype(np.uint8)
    else:
        return out


# ======================================================================
#  Multiplicative "paper texture" modulation for an existing image
# ======================================================================
def spt_texture_multiplicative(
        img           : Union[ImageBGR, ImageBGRF],
        *,
        mul_strength  : float = 0.05,
        n_layers      : int   = 3,
        base_radius   : int   = 1,
        seed          : int   = None,
    ) -> Union[ImageBGR, ImageBGRF]:
    """
    Multiplicative texture modulation using the same multi-scale box-blur noise.

    Multiplier field:
        M(x,y) = 1 + mul_strength * MUL_SF * N(x,y)
    where N is zero-mean, std=1 noise after multi-scale smoothing.
    NOTE: Because practical values are expected to be < 10% / 0.1,
          rescale supplied value by the MUL_SF factor.

    Returns same dtype as input.
    """
    MUL_SF = 0.1
    if mul_strength <= 0 or n_layers <= 0:
        return img

    # Convert to float [0,1]
    if img.dtype == np.uint8:
        img_f = img.astype(np.float32) / 255.0
    else:
        img_f = np.clip(img.astype(np.float32), 0.0, 1.0)

    h, w = img_f.shape[:2]
    rng = np.random.default_rng(seed)

    # Generate multi-scale smooth noise
    acc = np.zeros((h, w), np.float32)
    for i in range(n_layers):
        noise = rng.normal(0, 1, size=(h, w)).astype(np.float32)
        radius = base_radius * (2 ** i)
        smooth = _box_blur(noise, radius)
        acc += smooth

    # Normalize and map to multiplicative mask
    acc -= acc.mean()
    acc /= (acc.std() or 1.0)

    M = 1.0 + mul_strength * MUL_SF * acc
    out = img_f * M[..., None]
    out = np.clip(out, 0.0, 1.0)

    # Return original dtype
    if img.dtype == np.uint8:
        return (out * 255).astype(np.uint8)
    else:
        return out


# ======================================================================
#  Parameter sets for combined (add/mult) texture models
# ======================================================================
def spt_texture_presets(name: str) -> dict:
    """
    Return parameter sets for additive/multiplicative texture models.

    Usage:
        cfg = spt_texture_presets("old_paper")
        img2 = spt_texture_combined(img, **cfg)        
    """
    MUL_SF = ADD_SF = 0.1
    P = lambda a, m, nl, br, seed=None: {
        "add_strength" : a / ADD_SF,
        "mul_strength" : m / MUL_SF,
        "n_layers"     : nl,
        "base_radius"  : br,
        "seed"         : seed,
    }

    presets = {
        "old paper"            : P(0.06,  0.10, 4, 3),
        "scanned sheet"        : P(0.02,  0.12, 3, 2),
        "notebook"             : P(0.045, 0.05, 3, 2),
        "blueprint background" : P(0.02,  0.03, 4, 4),
        "default"              : P(0.03,  0.04, 3, 2),
    }    

    return presets.get(name.lower().strip(), presets["default"])


def main():
    # ----------------------------------------------------------------------
    base_rgba: ImageRGBA = render_scene()
    base_bgr:  ImageBGR  = bgr_from_rgba(base_rgba)
    proc_bgr:  ImageBGR  = spt_texture(
                               img=base_bgr,
                               texture_strength=0.12,
                               texture_scale=8.0,
                           )

    rng = random.Random(os.getpid() ^ int(time.time()))
    random_props = {
        "img":            bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "texture_strength":   abs(max(-2, min(2, rng.normalvariate(0, 0.5)))),
        "texture_scale":      abs(max(-5, min(5, rng.normalvariate(0, 1)))),
    }

    demos = {
        "BASELINE": base_rgba,
        "RANDOM"  : rgb_from_bgr(spt_texture(**random_props)),
    }

    default_props = {"img": base_bgr,}
    demo_set = [
        {"texture_strength": 0.1, "texture_scale": 8},
        #{"texture_strength": 0.2, "texture_scale": 8},
        #{"texture_strength": 0.4, "texture_scale": 8},
        #{"texture_strength": 0.8, "texture_scale": 8},
        {"texture_strength": 0.2, "texture_scale": 0.5},
        {"texture_strength": 0.2, "texture_scale": 1},
        #{"texture_strength": 0.2, "texture_scale": 2},
        {"texture_strength": 0.2, "texture_scale": 4},
    ]
    for custom_props in demo_set:
        title = (
            f"Texture strength x scale: {float(custom_props['texture_strength']):.1f} x "
            f"{float(custom_props['texture_scale']):.1f}"
        )
        print(title)
        demos[title] = rgb_from_bgr(
            spt_texture(**{**default_props, **custom_props})
        )

    additive_props = {
        "img"           : bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "add_strength"  : 0.4,
        "n_layers"      : 3,
        "base_radius"   : 2,
    }
    demos["Additive"] = rgb_from_bgr(spt_texture_additive(**additive_props))
    
    multiplicative_props = {
        "img"           : bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "mul_strength"  : 0.7,
        "n_layers"      : 3,
        "base_radius"   : 2,
    }
    demos["Multiplicative"] = rgb_from_bgr(spt_texture_multiplicative(**multiplicative_props))
    
    combined_props = {
        "img"           : bgr_from_rgba(render_scene(
                              canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                              plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                          )),
        "add_strength"  : 0.4,
        "mul_strength"  : 0.5,
        "n_layers"      : 3,
        "base_radius"   : 2,
    }
    demos["Combined"] = rgb_from_bgr(spt_texture_combined(**combined_props))
    
    fiber_props = {
        "img"                   : bgr_from_rgba(render_scene(
                                      canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                                      plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                                  )),
        "fiber_strength"        : 0.3, # 0.3 +/- 0.2 (uniform)
        "fiber_orientation_deg" : 0.0,
        "sigma_long"            : 10,  # 10 +/- 5    (uniform)
        "sigma_short"           : 1,   #  1 +/- 0.5  (uniform)
    }
    demos["Fiber"] = rgb_from_bgr(spt_texture_fibers(**fiber_props))
    
    crease_props = {
        "img"        : bgr_from_rgba(render_scene(
                           canvas_bg_idx = rng.randrange(len(PAPER_COLORS)),
                           plot_bg_idx = rng.randrange(len(PAPER_COLORS)),
                       )),
        "amplitude"  : 0.8,
        "sigma"      : 10,
    }
    demos["Crease"] = rgb_from_bgr(spt_texture_fold_crease(**crease_props))
   
    show_RGBx_grid(demos, n_columns=4)


if __name__ == "__main__":
    main()

``` 
 
===== END spt_texture.py ===== 
 

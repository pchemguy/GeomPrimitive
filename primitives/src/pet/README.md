https://chatgpt.com/c/6915c9bb-ec70-832a-94a1-560ec524b942
https://chatgpt.com/c/691cdce8-39e8-8328-adbf-3693191c7b0a
https://chatgpt.com/c/691ebbed-a008-8327-915a-1a4c652a2eea

# Notes

- WB / exposure correction increase lighting imbalance. Retinex default filter evens lighting. Consider using more aggressive Retinex settings as well.
- Fiji ImageJ - "Plugins -> Integral Image Filters -> Normalize Local Contrast 40x40x5.0" yielded good result in subsequent grid detection on the test image.
- Managed to perform preliminary processing of the identified line segments. However, geometry correction did not manage to get working.

## –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ —Ñ–æ–Ω–µ –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤–æ–π —Å–µ—Ç–∫–∏

### –¶–µ–ª—å ‚Äì –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–ª–æ—â–∞–¥–∏ –æ–±—Ä–∞–∑—Ü–∞.  

–°—Ü–µ–Ω–∞: –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ–±—Ä–∞–∑–µ—Ü –≤—ã—Å–æ–∫–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (—Ç—ë–º–Ω—ã–π) —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Ñ–æ–Ω–µ –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤–æ–π –±—É–º–∞–≥–∏. (–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —Å—Ü–µ–Ω–µ: –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–ª—ë–Ω–∫—É. –õ—É—á—à–µ –≤—Å–µ–≥–æ —Å–¥–µ–ª–∞—Ç—å –§–∞–π–ª —Å —Å–µ—Ç–∫–æ–π, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ —Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å (—Å –æ—Ç—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º) –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–∫–æ–π –ª–∏—Å—Ç. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –±—É–¥–µ—Ç —Ç–∞–∫ –∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å —Ç–æ–ª—â–∏–Ω—ã/—Ü–≤–µ—Ç–∞ –ª–∏–Ω–∏–π, –º–æ–∂–Ω–æ –ø–æ–¥—É–º–∞—Ç—å –æ –¥–æ–ø —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏).
–ó–∞–¥–∞—á–∞ ‚Äì –ø–æ–ª—É—á–∏—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤ –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤–æ–π —Å–µ—Ç–∫–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–ª–æ—â–∞–¥–∏ –æ–±—Ä–∞–∑—Ü–∞.

### –ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Å–∫–∞–∂–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ —Å–µ—Ç–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –ª–∏–Ω–µ–π–Ω—ã—Ö –∏ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π —Ñ–æ—Ç–æ, —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–µ–π. –í –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Ç–∫–∏, —Ç–∞–∫ –∂–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ (—Ä–∞–∑–º–µ—Ä —Å—Ç–æ—Ä–æ–Ω—ã –∫–ª–µ—Ç–∫–∏ 1 —Å–º/–º–º –≤ –ø–∏–∫—Å–µ–ª—è—Ö). –î–ª—è –≤—ã—Å–æ–∫–æ–∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ —Å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–Ω–æ—Ç–∏–ø–Ω–æ–π –∫–æ–º–ø–æ–∑–∏—Ü–∏–µ–π (–æ–±—Ä–∞–∑–µ—Ü –≤ —Å—Ä–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏ —Å–Ω–∏–º–∫–∞, –ø–æ –≤—Å–µ–º —Å—Ç–æ—Ä–æ–Ω–∞–º –º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤–∫–∞) –º–æ–∂–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –æ–±—Ä–∞–∑–µ—Ü, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç –∏ –∞–Ω–∞–ª–∏–∑ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã. –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Ä–µ–±—Ä–∞ —Å–µ—Ç–∫–∏ –≤ –ø–∏–∫—Å–µ–ª—è—Ö –∏ –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –æ–±—Ä–∞–∑—Ü–∞, –ø–ª–æ—â–∞–¥—å –æ–±—Ä–∞–∑—Ü–∞ ‚Äì –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∏–∫—Å–µ–ª–µ–π –æ–±—Ä–∞–∑—Ü–∞ –¥–µ–ª—ë–Ω–Ω–æ—ë –Ω–∞ –∫–≤–∞–¥—Ä–∞—Ç —á–∏—Å–ª—è –ø–∏–∫—Å–µ–ª–µ–π, –ø—Ä–∏—Ö–æ–¥—è—â–∏—Ö—Å—è –Ω–∞ —à–∞–≥ —Å–µ—Ç–∫–∏.

–¶–µ–ª—å—é —è–≤–ª—è–µ—Ç—Å—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –¥–≤—É—Ö —Ç–∏–ø–æ–≤ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π:
	–õ–∏–Ω–µ–π–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è
		–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞
		–ü–æ–ª–æ–∂–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞ –æ–±—ä–µ–∫—Ç–∞
		–¢—Ä–∏ —É–≥–ª–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞ –∫–∞–º–µ—Ä—ã
	–ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è
		–ù–µ–ª–∏–Ω–µ–π–Ω–æ–µ –∏—Å–∫–∞–∂–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º–æ–π (–ª–∏–Ω–∑–∞–º–∏) –∫–∞–º–µ—Ä—ã.
–õ–∏–Ω–µ–π–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è –ø—Ä–∏–≤–æ–¥—è—Ç –∫
	–ø–æ–≤–æ—Ä–æ—Ç—É –ª–∏–Ω–∏–π —Å–µ—Ç–∫–∏ –≤ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ü–∏–∏ (–Ω–∞ —Å–Ω–∏–º–∫–µ) –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª–æ–∂–µ–Ω–∏–π –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ/–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
	–∏—Å–∫–∞–∂–µ–Ω–∏—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–º–∏/–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–º–∏ –ª–∏–Ω–∏—è–º–∏ (–ª–∏–Ω–∏–∏ —Å—Ö–æ–¥—è—Ç—Å—è/—Ä–∞—Å—Ö–æ–¥—è—Ç—Å—è)
	–∏—Å–∫–∞–∂–µ–Ω–∏—é —É–≥–ª–∞ –º–µ–∂–¥—É –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–º–∏/–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –ª–∏–Ω–∏—è–º–∏ (–æ—Ç–ª–∏—á–Ω–æ –æ—Ç 90 –≥—Ä–∞–¥)
–ù–µ–ª–∏–Ω–µ–π–Ω–æ–µ –∏—Å–∫–∞–∂–µ–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –∏—Å–∫—Ä–∏–≤–ª–µ–Ω–∏—é –ª–∏–Ω–∏–π —Å–µ—Ç–∫–∏.

–ü—Ä–∏ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–∞–∂–µ–Ω–∏—è—Ö, –≤ –Ω—É–ª–µ–≤–æ–º –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–∏ –º–æ–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É —Å—Ç–∞–¥–∏–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π. –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, —Ä—É—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π.

–ü–µ—Ä–≤–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ ‚Äì –ø–æ–ª—É—á–∏—Ç—å –≤–∏–¥–∏–º—ã–π —É–≥–æ–ª –º–µ–∂–¥—É –ª–∏–Ω–∏—è–º–∏ —Å–µ—Ç–∫–∏, –ø–æ–≤–æ—Ä–æ—Ç —Å–µ–∫—Ç–∏, –æ—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑–æ–≤–∞—Ç—å –Ω–µ–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å –∏ –∏—Å–∫–∞–∂–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏ –ª–∏–Ω–∏–π –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ª–∏–Ω–µ–π–Ω—ã—Ö –∏ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π.

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–µ–º–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

1. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–æ:
    - –ü–æ–≤—ã—à–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    - –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –æ—Å–≤–µ—â—ë–Ω–Ω–æ—Å—Ç–∏
    - –í–æ–∑–º–æ–∂–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —à—É–º–∞.
2. –ü–µ—Ä–≤–∏—á–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Å–µ—Ç–∫–∏.
3. –ê–Ω–∞–ª–∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–µ—Ç–∫–µ, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –∏—Å–∫–∞–∂–µ–Ω–∏–π –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —à–∞–≥–∞ —Å–µ—Ç–∫–∏.
4. –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π.
5. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –æ–±—Ä–∞–∑—Ü–∞ (–∫–æ–Ω—Ç—Ä–∞—Å—Ç + –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞, –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞) –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∏–∫—Å–µ–ª–µ–π –Ω–∞ –æ–±—Ä–∞–∑–µ—Ü.
6. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ –æ–±—Ä–∞–∑—Ü–∞.

### –†–µ—Å—É—Ä—Å—ã, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã

–•–æ—Ä–æ—à–∏–π —Ä–µ—Å—É—Ä—Å –ø–æ —Ç–µ–º–µ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π: "Basic concepts of the homography explained with code" (https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html)

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –≤ —Å—Ä–µ–¥–µ –ü–∏—Ç–æ–Ω, —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–ª—é—á–µ–≤—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –Ω–∞—É—á–Ω–æ-—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è:

- opencv
- scipy 
- scikit-image
- scikit-learn
- numpy

–¢–∞–∫ –∂–µ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Ü–µ–ª–µ—Å–æ–æ–±—Ä–∞–∑–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–ª–∞–≥–∏–Ω—ã Fiji ImageJ (https://fiji.sc) —á–µ—Ä–µ–∑ –æ–±—ë—Ä—Ç–∫–∏ (–≤–∏–¥–∏–º–æ, —ç—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å) –ª–∏–±–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –Ω–∞ –ü–∏—Ç–æ–Ω–µ –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ö.

## Prompt

I have a set of real lab pictures with millimeter graph paper in background and I want do define and develop enhancement pipeline. Assume the actual background paper has white color and the lighting is suboptimal (not enough light). I need recipes and optimal order for these tasks:

- assess the amounts of various standard noise types and apply automatic denoising
- adust brightness, perhaps curves by setting white point to lighter regions of paper, which also needs to be identified.

Perhaps, a more interesting objective is to assess geometric distortions by looking at the grids. Can I identify grids via fft/wavelet? Can I estimate parameters for reversing rotated camera view (all three axes) and pinhole camera distortions by analyzing spatial grid info?

My guess I will need OpenCV, skimage, what else?

## Response

Below is a **complete, engineer-level recipe** for building an enhancement + camera-geometry assessment pipeline **specifically for real lab photographs with millimeter graph paper**, where **paper is white with faint grid** and **lighting is suboptimal**.

This is written as a **design document** with reasoning, processing order, and concrete algorithms / library choices.

---

# ‚úÖ 0. Recommended Libraries

You'll need:

### **Core**

- **OpenCV** (`cv2`) ‚Üí filtering, geometry, camera models
- **scikit-image** ‚Üí denoising, exposure, FFT tools
- **NumPy**, **SciPy (fft, ndimage)** ‚Üí FFT & correlation
- **OpenCV contrib** (optional) ‚Üí better calibration
- **pywavelets** ‚Üí wavelet-based grid detection

### **Optional / advanced**

- **imreg_dft** ‚Üí robust sub-pixel registration and affine detection via FFT
- **OpenCV ArUco/Charuco** if you add manual calibration markers

---

# ‚úÖ 1. Pipeline Overview (Optimal Order)

This is the recommended full pipeline:

1. **RAW input (BGR/RAW/PNG)**
2. **White region detection ‚Üí estimate ‚Äúpaper whiteness‚Äù**
3. **Exposure correction**
    - White-point correction based on paper
    - Gamma / curve adjustment
4. **Noise estimation (quantify each noise type)**
    - Gaussian, shot noise, salt-pepper
    - Then **auto-denoising** using best model
5. **Grid extraction & enhancement**
    - FFT or wavelets to identify grid frequencies
    - Extract grid lines (major + minor, depending on paper)
6. **Geometric distortion estimation**
    1. **Perspective / camera orientation (3 DOF)**
    2. **Skew / affine distortions**
    3. **Lens distortion params (k‚ÇÅ, k‚ÇÇ, p‚ÇÅ, p‚ÇÇ)**
7. **Back-projective correction**
    - Remove perspective
    - Remove radial distortion
8. **Quality check & refine**

---

# üîß 2. Lighting & Exposure Correction

## **2.1 Detect the ‚Äúwhite paper‚Äù baseline**

Your background graph paper _is_ your calibration target.

### Strategy:

1. Apply a **large Gaussian blur** ‚Üí smooth out grid lines:

```python
blurred = cv2.GaussianBlur(img, (51, 51), 0)
```

2. Compute the **top N% brightest pixels** ‚Üí these approximate paper.    
3. Use **95‚Äì98th percentile** of blurred grayscale as white point estimate.

Or use skimage:

```python
from skimage.filters import threshold_otsu
val = threshold_otsu(blurred_gray)
```

**Result:**  
You get estimated paper white color ‚Üí `(W_R, W_G, W_B)`.

### White-point correction:

Use **Gray World** or **White Patch** algorithm:

```python
scales = target_white / measured_white
img_corr = img * scales
```

### Remove uneven illumination:

Use **Retinex** (skimage works well):

```python
from skimage.restoration import denoise_bilateral
illum = cv2.GaussianBlur(gray, (101,101),0)
corrected = gray / (illum + eps)
```

---

# üîß 3. Noise Estimation + Denoising

## **3.1 Automatically Estimate Noise**

Use:

### Gaussian noise estimate

- skimage: `estimate_sigma(image, multichannel=True)`
- wavelet-based: PyWavelets variance in HH subbands

### Shot noise (Poisson)

- Check relationship between mean and variance locally:  
    If var ‚âà mean ‚Üí Poisson-like.

### Salt & pepper

- Measure pixel impulse proportion using  
    `np.count_nonzero((img < t1) | (img > t2)) / total`.    

---

## **3.2 Apply the right denoiser**

|Noise type|Best denoiser|
|---|---|
|Gaussian|**Non-local Means**, **BM3D**, CV‚Äôs `fastNlMeansDenoisingColored`|
|Poisson|**Wavelet shrinkage**, **Anscombe transform ‚Üí BM3D**|
|Mixed|**skimage ‚Äúdenoise_nl_means‚Äù** or **CV bilateral filter**|

Recommendation:

```python
from skimage.restoration import denoise_nl_means, estimate_sigma
sigma = estimate_sigma(img, channel_axis=-1)
den = denoise_nl_means(img, h=1.2*sigma, patch_size=7, patch_distance=9)
```

---

# üîß 4. Grid Detection (FFT/Wavelet)

Your graph paper is periodic ‚Üí perfect for frequency analysis.

## **4.1 FFT method**

1. Convert to grayscale
2. FFT ‚Üí magnitude spectrum
3. Detect **strong peaks** away from DC.  
    There will be **4 dominant peaks** (two axes √ó ¬±).

Grid frequency `fx, fy` is given by peak locations.

### From FFT peaks you get:

- Grid spacing (mm to pixel scale)
- Rotation angle of camera (2D rotation)
- Perspective shear (peak asymmetry)
- Local warping (if peaks are broadened)

FFT is excellent for:
- Dense minor grids (1 mm)
- Major grids (5‚Äì10 mm)

## **4.2 Wavelet method**

Using 2D wavelet transforms:
- CWT ridge detection ‚Üí grid lines
- Use directional wavelets (Morlet/Pauli) to detect line orientation

Wavelet method is excellent for:
- Uneven lighting
- Partial occlusion
- Low contrast grids

---

# üéØ 5. Geometric Distortion Estimation

This is the key part if you want **camera pose** and **lens distortion**.

## ‚úî 5.1 Perspective + Camera Rotation

Grid lines should be **parallel**, but under perspective they converge.

### How to estimate:

- Extract grid lines via Sobel/Canny ‚Üí Hough transform ‚Üí detect line families
- Two line families ‚Üí compute vanishing points:
    - Intersection of horizontal lines ‚Üí VP‚ÇÅ
    - Intersection of vertical lines ‚Üí VP‚ÇÇ
- Third vanishing point is either inferable (orthogonality assumption) or unnecessary.

### From VPs:

- Recover camera yaw, pitch, roll
- Estimate homography H mapping image ‚Üí canonical grid

OpenCV:

```python
H, _ = cv2.findHomography(src_grid_points, dst_ideal_points)
```

---

## ‚úî 5.2 Radial Lens Distortion (k‚ÇÅ, k‚ÇÇ, p‚ÇÅ, p‚ÇÇ)

Radial distortion makes straight grid lines **curve**.

### Approach:

1. Use extracted grid lines
2. Fit curves (splines)
3. Estimate distortion by matching curved lines to ideal straight lines.

OpenCV supports this:

```python
camera_matrix, dist_coeffs = cv2.calibrateCamera(objpoints, imgpoints, ...)
```

You can provide:

- objpoints: ideal grid (mm scale)
- imgpoints: detected intersections (via FFT/Hough)

Even without calibration pattern, grid lines from paper serve as a _pseudo-calibration target_.

---

## ‚úî 5.3 Correct order:

1. Estimate & remove ISS:
    - Radial distortion first
    - Then perspective (homography)
    - Then affine corrections
2. Confirm grid lines become straight.

---

# üîß 6. Back-Projection & Image Correction

### Step 1: Undistort radial lens

```python
undist = cv2.undistort(img, camera_matrix, dist_coeffs)
```

### Step 2: Perspective correction (rectify the paper)

```python
flat = cv2.warpPerspective(undist, H, output_size)
```

After this the grid should appear straight and equally spaced.

---

# üîç 7. Final enhancements (optional)

- Local contrast enhancement (CLAHE)
- Sharpening only after full denoise/dewarp
- Extract object boundaries on the grid

---

# üß© 8. Practical Notes for Lab Picture Use-Case

### **What the grid gives you:**

- Perfect periodic frequency structure ‚Üí FFT friendly
- Perfect rectilinear geometry ‚Üí camera calibration friendly
- Known metric spacing (1 mm, 5 mm, 10 mm) ‚Üí scale calibration

### **Best feature extractor for intersections**

- Harris with subpixel refinement
- ORB corners (fast)
- Peaks in distance transform from primary grid lines

### **Avoid pitfalls**

- Uneven lighting ‚Üí kills FFT ‚Üí apply illumination correction first
- Over-denoising ‚Üí destroys faint grid lines  
    ‚Üí denoise _after_ exposure correction but _before_ FFT
- Too strong CLAHE ‚Üí will artificially strengthen noise  
    ‚Üí apply conservatively or after rectification

---

# üì¶ 9. Minimal Working Pipeline (Pseudo-Code)

```python
img = load_image()

# 1. White paper detection & brightness correction
white_estimate = estimate_paper_white(img)
img = white_balance(img, white_estimate)
img = illumination_correct(img)

# 2. Noise estimation + denoise
sigma = estimate_sigma(img)
img = denoise_nl_means(img, h=1.2*sigma)

# 3. Extract grid via FFT
fx, fy, angle = detect_grid_fft(img)
grid_lines = extract_grid_lines(img)

# 4. Compute vanishing points & perspective
Vp1, Vp2 = compute_vanishing_points(grid_lines)
H = compute_homography_from_vps(Vp1, Vp2)

# 5. Estimate distortion
camera_matrix, dist_coeffs = estimate_lens_distortion(grid_lines)

# 6. Correct geometry
img = cv2.undistort(img, camera_matrix, dist_coeffs)
img = cv2.warpPerspective(img, H)

# 7. Final enhancement
img = apply_clahe(img)
```

---

# üîÆ 10. If needed, I can deliver:

- Full Python implementation with all steps
- FFT grid detector module
- Lens calibration using arbitrary grid images
- Grid intersection detection
- Path-wise warping correction for your synthetic grid generator
- Or integrate this into your existing **hand-drawn paper** pipeline

---

If you want, I can generate:

‚úÖ **Complete ready-to-run Python module**  
OR  
‚úÖ **Visualization tools to debug grid extraction**  
OR  
‚úÖ **Camera parameter solver from your dataset**

Just tell me which direction to go next.